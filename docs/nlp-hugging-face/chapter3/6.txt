 датасета!"
		},
		{
			text: "Named entity recognition / Распознавание именованных сущностей",
			explain: "Нет, изучите еще раз  датасета!"
		},
        {
			text: "Question answering / Ответы на вопросы",
			explain: "Увы! Неправильный ответ. "
		}
	]}
/>

### 3. В каком формате модель BERT ожидает на вход пару предложений?

 – специальный токен для разделения двух предложений, однако этого недостаточно."
		},
		{
			text: "[CLS] Токены_предложения_1 Токены_предложения_2",
			explain: "Токен  – специальный токен, обозначающий начало последовательнсти, однако этого недостаточно."
		},
		{
			text: "[CLS] Токены_предложения_1 [SEP] Токены_предложения_2 [SEP]",
			explain: "Правильно!",
            correct: true
		},
        {
			text: "[CLS] Токены_предложения_1 [SEP] Токены_предложения_2",
			explain: "Токен  – специальный токен, обозначающий начало последовательнсти,  Токен  – специальный токен для разделения двух предложений. Но это не всё!"
		}
	]}
/>

{#if fw === 'pt'}
### 4. Какие преимущества есть у метода `Dataset.map()?`

."
		},
		{
			text: "Она соединяет вместе все элементы батча.",
			explain: "Верно! Вы можете передать функцию сопоставления в качестве аргумента для . Мы использовали функцию , которая дополняет все элементы в батче до одинаковой длины.",
            correct: true
		},
		{
			text: "Она обрабатывает весь датасет. ",
			explain: "Тогда она называлась быть функцией препроцессинга, а не функцией сопоставления."
		},
        {
			text: "Она обрезает предложения в датасете.",
			explain: "Collate-функция используется для одного батча, а не всего датасета. Если вам необходимо обрезать датасет, вы можете использовать аргумент  в ."
		}
	]}
/>

### 7. Что происходит, когда вы создаете экземпляр одного из классов `AutoModelForXxx` с предварительно обученной языковой моделью (например, `bert-base-uncased`), которая соответствует задаче, отличной от той, для которой она была обучена? 

 с  чекпоинтом, распечатывается предупреждение при инициализации модели. Предобученная «голова» модели не используется для классификации предложений, так что она заменяется другим слоем со случайно инициализированными весами.",
            correct: true
		},
		{
			text: "Последний слой модели игнорируется.",
			explain: "Должно произойти что-то еще! Попробуй еще раз!"
		},
        {
			text: "Ничего, модель по-прежнему можно будет настроить на решение другой задачи.",
			explain: "Последний слой модели был обучен решать другую задачу, значит с ним должно что-то произойти!"
		}
	]}
/>

### 8. Зачем нужен `TrainingArguments`?

",
			explain: "Верно!",
            correct: true
		},
		{
			text: "Задает размер модели.",
			explain: "Размер модели определяется ее структурой, а не классом ."
		},
		{
			text: "Содержит гиперпараметры для этапа валидации модели.",
			explain: "В примере мы задавали, где будут сохраняться модель и её веса. Попробуй еще раз!"
		},
        {
			text: "Он содержит гиперпараметры этапа обучения.",
			explain: "В примере мы использовали , что также влияет на валидацию. Попробуй еще раз!"
		}
	]}
/>

### 9. Зачем нужна библиотека  Accelerate?

, а не  Accelerate. Попробуй еще раз!"
		},
		{
			text: "Позволяет исполнить наш цикл обучения на распределенных системах.",
			explain: "Праивльно! С помощью  Accelerate обучающий цикл будет исполняться на нескольких GPU или TPU.",
            correct: true
		},
        {
			text: "Предоставляет больше оптимизационных функций.",
			explain: "Нет,  Accelerate не предоставляет оптимизационных функций."
		}
	]}
/>

{:else}
### 4. Что происходит, когда вы создаете экземпляр одного из классов `TFAutoModelForXxx` с предварительно обученной языковой моделью (например, `bert-base-uncased`), которая соответствует задаче, отличной от той, для которой она была обучена? 

 с  чекпоинтом, распечатывается предупреждение при инициализации модели. Предобученная «голова» модели не используется для классификации предложений, так что она заменяется другим слоем со случайно инициализированными весами.",
            correct: true
		},
		{
			text: "Последний слой модели игнорируется.",
			explain: "Должно произойти что-то еще! Попробуй еще раз!"
		},
        {
			text: "Ничего, модель по-прежнему можно будет настроить на решение другой задачи.",
			explain: "Последний слой модели был обучен решать другую задачу, значит с ним должно что-то произойти!"
		}
	]}
/>

### 5. TensorFlow-модели из `transformers` уже можно рассматривать как Keras-модели. Какие преимущества это дает?

 (включая инициализацию модели)."
		},
		{
			text: "Вы сможете испольовать существующие методы, такие как ,  и .",
			explain: "Верно! Данные у вас уже есть, дело осталось за малым – обучить модель. ",
            correct: true
		},
		{
			text: "Вы сможете изучить и Keras, и transformers.",
			explain: "Верно! Но ответ все же немного другой :)",
			correct: true
		},
        {
			text: "Вы можете просто вычислить метрики, связанные с датасетом.",
			explain: "Keras помогает в обучении и валидации модели, а не с вычислением метрик."
		}
	]}
/>

### 6. Как мы можем задать собственную метрику?

.",
			explain: "Великолепно!",
			correct: true
		},
		{
			text: "С использованием функционального API Keras.",
			explain: "Try again!"
		},
		{
			text: "С использованием вызываемого модуля .",
			explain: "Верно!",
			correct: true
		},
        {
			text: "Загуглив её!",
			explain: "Это не тот ответ, который мы ожидаем, однако это должно помочь вам!",
			correct: true
		}
	]}
/>

{/if}
