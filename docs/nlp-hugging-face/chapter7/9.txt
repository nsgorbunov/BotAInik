 для обозначения специальных токенов.",
			explain: "Это не относится к классификации токенов - мы всегда используем  в качестве метки для токенов, которые мы хотим игнорировать в потерях."
		},
		{
			text: "При применении усечения/дополнения нам нужно убедиться, что метки имеют тот же размер, что и входные данные.",
			explain: "Действительно! Но это не единственное отличие.",
			correct: true
		}
	]}
/>

### 3. Какая проблема возникает при токенизации слов в проблеме классификации токенов и при необходимости их маркировки?

 и .",
			explain: "Возможно, в будущем мы добавим такой API, но сейчас это невозможно."
		},
		{
			text: "Входные данные и цели должны быть предварительно обработаны в двух раздельных вызовах токенизатора.",
			explain: "Это правда, но неполная. Вам нужно кое-что сделать, чтобы убедиться, что токенизатор правильно обрабатывает оба варианта."
		},
		{
			text: "Как обычно, нам просто нужно выполнить токенизацию входных данных.",
			explain: "Не в проблеме классификации последовательностей; цели - это тексты, которые мы должны преобразовать в числа!"
		},
        {
			text: "Входные данные должны быть переданы токенизатору, и цели тоже, но под управлением специального контекстного менеджера.",
			explain: "Верно, токенизатор должен быть переведен в target режим этим менеджером контекста.",
			correct: true
		}
	]}
/>

{#if fw === 'pt'}

### 8. Почему существует специальный подкласс `Trainer` для проблем преобразования " последовательности-в-последовательность"?

.",
			explain: "Это вовсе не определенные пользователем потери, а то, как потери всегда вычисляются."
		},
		{
			text: "Поскольку проблемы преобразования последовательности-в-последовательность требуют специального цикла оценки",
			explain: "Это верно. Предсказания моделей преобразующих последовательность-в-последовательность часто выполняются с помощью метода .",
			correct: true
		},
		{
			text: "Поскольку целью являются тексты в проблемах преобразования последовательности-в-последовательность",
			explain: " не особо заботится об этом, поскольку они уже были предварительно обработаны."
		},
        {
			text: "Поскольку в проблемах преобразования последовательности-в-последовательность мы используем две модели",
			explain: "В некотором смысле мы используем две модели, энкодер и декодер, но они сгруппированы в одну модель."
		}
	]}
/>

{:else}

### 9. Почему при вызове `compile()` для модели трансформера часто нет необходимости определять потери?



{/if}

### 10. Когда следует проводить предварительное обучение новой модели?



### 11. Почему легко провести предварительное обучение языковой модели на большом количестве текстов?



### 12. Какие основные проблемы возникают при предварительной обработке данных для задачи ответа на вопрос (question answering)?



### 13. Как обычно выполняется постобработка в задаче ответов на вопросы?


