# Освоение NLP[[mastering-nlp]]



Если вы дошли до конца курса, поздравляем - теперь у вас есть все знания и инструменты, необходимые для решения (почти) любой задачи NLP с помощью  Transformers и экосистемы Hugging Face!

Мы видели много разных коллаторов данных, поэтому сделали это небольшое видео, чтобы помочь вам определить, какой из них лучше использовать для каждой задачи:



Пройдя этот молниеносный тур по основным задачам NLP, вы должны:

* Знать, какие архитектуры (кодер, декодер или кодер-декодер) лучше всего подходят для конкретной задачи
* Понимать разницу между предварительным обучением и дообучением языковой модели
* Знать, как обучать модели Transformer, используя либо API `Trainer` и возможности распределенного обучения в  Accelerate, либо TensorFlow и Keras, в зависимости от того, какой путь вы выбрали
* Понимать значение и ограничения таких метрик, как ROUGE и BLEU, для задач генерации текста
* Знать, как взаимодействовать с вашими дообученными моделями, как на Hub, так и с помощью `pipeline` из  Transformers

Несмотря на все эти знания, настанет момент, когда вы столкнетесь с трудной ошибкой в своем коде или у вас возникнет вопрос о том, как решить ту или иную задачу NLP. К счастью, сообщество Hugging Face готово помочь вам! В заключительной главе этой части курса мы рассмотрим, как можно отлаживать свои модели Transformer и эффективно обращаться за помощью.