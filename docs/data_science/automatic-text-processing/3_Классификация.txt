Классификация текстов
Высшая школа цифровой культуры
Университет ИТМО
dc@itmo.ru
______________________
Оглавление
КЛАССИФИКАЦИЯ ТЕКСТОВ 3ОПРЕДЕЛЕНИЕ СПАМА 3АНАЛИЗ ТОНАЛЬНОСТИ 4ОПРЕДЕЛЕНИЕ ТЕМ НОВОСТЕЙ 4ПРИМЕРЫ ЗАДАЧИ КЛАССИФИКАЦИИ 5ФОРМАЛЬНАЯ ПОСТАНОВКА ЗАДАЧИ 5ОДНОЗНАЧНАЯ И МНОГОЗНАЧНАЯ КЛАССИФИКАЦИИ 6
МЕТОДЫ КЛАССИФИКАЦИИ 7ОСНОВНЫЕ ЭТАПЫ РЕШЕНИЯ ЗАДАЧИ КЛАССИФИКАЦИИ 7ИНДЕКСАЦИЯ ДОКУМЕНТОВ 7АЛГОРИТМЫ КЛАССИФИКАЦИИ 8ЛИНЕЙНЫЕ АЛГОРИТМЫ 8ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ 9МЕТОД ОПОРНЫХ ВЕКТОРОВ 10НАИВНЫЙ БАЙЕС 10МЕТРИКИ 11
КЛАССИФИКАЦИЯ ТЕКСТОВ
Однаизключевыхзадачкомпьютернойлингвистикииобработкиестественногоязыка- классификациятекстов.Вобщемвиде,классификациятекстов- этоотнесениеодного документа к одной из нескольких категорий на основании его содержания.Преждечеммыпогрузимсяв деталииподробнеерассмотримподходящиедляеё решенияметоды машинного обучения,давайте посмотрим на примерыклассификации текстов в повседневной жизни.
ОПРЕДЕЛЕНИЕ СПАМА
Каждыйденьмыполучаемдесяткиписем,ноневсе изнихнаминтересны:кроменужныхписемв ящикпопадают сообщенияот мошенниковс фишинговымиссылками, рекламные рассылки, письма счастья.
Как правило,в почтовый сервер интегрирован спам-фильтр, которыйавтоматическисортирует входящиесообщения,и перемещаетв папку Спамвсе те,которые кажутся ему подозрительными. Как это происходит?
Допустим,человекполучаеттакоеписьмо.Опытныйпользовательсразупоймет,что это спам.Нокак?В письмемного подозрительныхособенностей.Во-первых,вписьмемного разупоминаетсяденежное вознаграждениеиливыигрыш:“денежныйсертификат”, “сертификат на сумму75 159руб”.Во-вторых,в текстесодержатсянастойчивыепросьбыбыстрееего получитьи многократныйповторфразы“заберитесвои деньги”.Кроме этого, получателя точно насторожат отсутствиеличногообращения(“Поздравляем”),ссылка и почтовыйадрес подозрительноговида,атакжеточное времяотправкиписьма (“23:00”).Объединиввсе эти признаки,можноклассифицировать письмо как спам.
АНАЛИЗ ТОНАЛЬНОСТИ
Ещёоднапопулярнаязадачаклассификации- анализтональности,определениетого, какуюэмоциональнуюнагрузку несеттекст- положительную,отрицательнуюилинейтральную.Такимитекстамимогутбытьобзорыфильмов,отзывынатоварыилипросто комментарии к новостям на сайте.Например,на этом слайдеприведеныотзывыпользователейна мобильныетелефоны.Сразупонятно,чтопервыйпользовательдоволенпокупкой- ониспользуеттакиеслова и фразыкак“отличный”,“классный”,“работаетшустро”,“современнаяпрошивка”,“наотличномуровне”.Второйотзывточноотрицательный:авторпишет,что никомуне рекомендует телефон,неможетего видеть,и вообщесначалахотел“выбросить в окно”.Задачу сортировкитакихотзывов также можно решитьавтоматически.
ОПРЕДЕЛЕНИЕ ТЕМ НОВОСТЕЙ
Ещёодна областьпримененияклассификациитекстов - определениетемновостей.Давайтепосмотримна этизаголовки.Кажется,человек,которыйвладеетконтекстом,легко определит, ккакойтемеотносятсяновости- кновостямспортаилиновостям рынка криптовалют. Прощевсего ориентироватьсяпоключевымсловам:“фигурное катание”,“болельщики”или“альткоины”.Ключевымисловамимогутбытьнетолько термины,нои названиястран,марокилиименаперсоналий,связанныхстемой(Тарасова,КрейгРайт).Выделениеименованныхсущностей--отдельнаязадача,заслуживающая нескольких лекций.
ПРИМЕРЫ ЗАДАЧИ КЛАССИФИКАЦИИ
Длякакихдругихзадач можноприменятьклассификацию?На самом делеколичество задач в реальнойжизни,которое можнорешатьв реальнойжизни,оченьвелико. В общеми целом,классификация- это определениекатегориитекста поегосодержанию.Можноразделятьтекстыпо авторству (какой пользовательнаписалсообщениенафоруме),либоопределятьвозрастилиполавторатекста.Такжеможноклассифицироватьтекстыпоихязыкуиликодировке.Классификацияприменяетсядляограничениятемпривыдаче в поисковыхсистемах,подбореконтекстнойрекламы,определении сообщений ботов в онлайн-дискуссиях.
ФОРМАЛЬНАЯ ПОСТАНОВКА ЗАДАЧИ
Давайтеопределимзадачуклассификациисточкизрениямашинногообучения.Важнопонимать, что классификациятекстов - это не их кластеризация.Приклассификациитекстов категориидокументов уже заранееопределены(например,темыновостейилитональностьотзывов),в то времякак прикластеризациинетинформациини о возможныхкатегорияхтекстов, а часто и о количестве такихкатегорий.Формальнозадачу можно описать следующимобразом. Естьмножестводокументов D - все текстыв выборке, и множество категорийC - все возможныекатегории,которыеможноприсвоитьдокументу. ЕстьнеизвестнаяцелеваяфункцияФ,котораяпредсказывает категориитекстов. Задача - на основе данныхпостроитьклассификаторФ’,которыйбудетмаксимальноблизокк Фи сможетпрогнозироватькатегории тех текстов, которые модель не видела при обучении.Здесьважноотметить,чтоунаснетникакойинформацииотекстахдокумента,крометой,которуюможноизвлечьизнихсамих:например,определенныесловаилиих частотность.Задачаклассификацииотноситсяк задачамобученияс учителем.Это значит,что дляпостроенияалгоритма имеется подвыборка текстов с уже проставленнымиклассами.Еёиспользуют дляобученияклассификатораиопределенияегопараметров,при которыхклассификатор даст наилучшийрезультат. Системуразделяют наобучающуюи тестовуювыборки:наобучающейвыборке онавырабатываетправила,по которымразделяетдокументына классы,а на тестовой выборке проверяетсякачество разделения.
ОДНОЗНАЧНАЯ И МНОГОЗНАЧНАЯ КЛАССИФИКАЦИИ
Классификацияможет бытьоднозначнойили многозначной.Однозначнаяклассификация- такая,прикоторойодномудокументу можетсоответствоватьтолькоодна категория.Однозначная классификация может бытьмногоклассовой или бинарной.Например,определениеавторства текста, еслиодномутексту можетсоответствоватьтолько один автор, но при этом нужно выбрать из списка возможных авторов.
Ещёодинпримермногоклассовойклассификации- определениекатегорииновостного текста дляраспределениятекстов поразделамна сайте.Прибинарнойклассификацииестьтолько двенепересекающиесякатегории:например,обнаружениеспама или разделение отзывов на положительные или отрицательные.Многозначнаяклассификация- классификация,прикоторойу текста можетбытьсразу несколько меток. Например,определениетемытекста и отображениеконтента в зависимостиот интересовпользователя:новостьобизменениистоимостиавиабилетовможетотобразитьсяитемпользователям,которыеинтересуютсяотдыхомза рубежом, и тем, кто следит за экономикой.
МЕТОДЫ КЛАССИФИКАЦИИ
ОСНОВНЫЕ ЭТАПЫ РЕШЕНИЯ ЗАДАЧИ КЛАССИФИКАЦИИ
Основныеэтапырешениязадачиклассификации:предобработка и индексациядокументов, уменьшениеразмерности пространства, построение и обучениеклассификатора и оценка качества.Опредобработкетекстамыговорилираньше:онавключаетвсебятокенизацию,удалениестоп-слов(слишкомчастотныеслова,частицы,предлоги,союзы),приведениеслов к нормальнойформе. Это позволяет частичносократить размерностьпространства.
ИНДЕКСАЦИЯ ДОКУМЕНТОВ
Индексациейдокументовиногданазывают построениетакойчисловоймодели,с помощью которой текст переводится в удобное для предобработки представление.Одиниз такихметодовмыуже знаем- это bagofwordsилимешокслов.Вектор размером со словарь, ненулевые значения -- частоты термов.Это - одинизсамыхпростыхспособовпредставитьтекств видечисел,новтаком случае полностью теряется информация о порядке слов.Второй способ индексации текстов - н-граммы. В таком случаемыподсчитываемнетолькоотдельностоящиесловаилисимволы,ноиихпары,тройкиитакдалее.Этопозволяет, например,учитыватьпорядоксловилисловочетания,отличая“понравится”от “непонравился”,чего непроисходит, еслимыпредставляемтекстпросто какмешокслов,нопоявляетсядругаяпроблема- еслиучитыватьвсен-грамы,признаковможетбытьслишкоммного.Втакомслучаерекомендуетсяудалитьслишкомчастотныеили,наоборот, слишкомредкиен-грамыи оченьвнимательноотнестиськвыбору N.Есть также и более современныеспособы представления текстов,использующиенейронныесети и предсказательныеметоды дистрибутивнойсемантики. Например, можно упомянуть семейство методов word2vec.
Каждоесловопредставляетсяввидевектора,который,таксказать,кодируетегосмыслна основе информациио его контекстныхсловах. Путёмобъединенияразнымиспособамитакихвекторовдлятекста можнополучитьего представление,у которогонет проблемыс представлениемсинонимови которое неявносодержитв себеинформациюо языке, полученнуюнадругойи, возможно,кудабольшейколлекциитекстов. Обычно это приносит прирост в качестве результатов.Дистрибутивнаясемантика сталаособенноважнав последнеевремяв связисуспехами нейронных сетей, но для нас пока это совсем другая история.
АЛГОРИТМЫ КЛАССИФИКАЦИИ
Существуют разнообразныеметоды классификации:линейные(например,логистическая регрессия),вероятностные(например,наивныйБайес),метрические(метод ближайшихсоседей),логические(например,деревьяпринятиярешений)иметоды,основанныенанейронныхсетях.Мынебудемрассматриватьвсе изних,ноподробнееостановимсяна нескольких- логистическойрегрессии,методе опорныхвекторов и наивном Байесовском классификаторе.
ЛИНЕЙНЫЕ АЛГОРИТМЫ
Рассмотримлинейныеалгоритмы.Общаяидеятакихалгоритмовзаключаетсявтом, что объекты обучающейвыборкипредставляют собойточкимногомерногопространства.Нашацель--построитьтакуюповерхность,котораяотделилабыточкиодного класса от точекдругого класса. Линейныйалгоритмищеттакуюлинейную
разделяющуюгиперплоскость.Вдвумерномслучаегиперплоскостьюявляетсяпрямаялиния.Линейнаяплоскость задается уравнением:скалярное произведениеw на хминусb равнонулю,где икс -- это признаки,а дубльвэи бэ -- настраиваемыепараметры.Далеенужнопонять,где находится точка многомерного пространства,соответствующаяобъекту, относительнолинейнойплоскости. Для этого нужнопосмотретьна знаквыражений,которое располагается слева от равенства. Такимобразом происходитклассификация.Поэтому цельлинейныхметодовсводится кпоиску коэффициентов W и константы b, определяющих гиперплоскость.К однозначнымплюсам линейныхалгоритмовотносятся высокая скоростьобучения,интерпретируемостькоэффициентови высокаяскорость.Ноу нихестьисущественныйнедостаток:есливыборка линейнанеразделима изависимостьответовот признаков сложная, точность алгоритма будет невысокой.
ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ
Однимиз линейныхалгоритмовявляется логистическая регрессия,частныйслучайобобщеннойлинейнойрегрессии.Этот метод хороштем,чтопрогнозируетнепросто ответ “да”или“нет”,нои вероятностьотнесениятекста к определенномуклассу. В логистической регрессиивеса настраиваются припомощиградиентногоспуска.Такимобразомминимизируетсячислоошибокнаобучающейвыборке.Можетполучитьсятак,что числоошибокнаобучающейвыборке будетнебольшим,ноприэтомалгоритмбудетпоказыватьнизкуюточностьнатестовойвыборке.Этозначит, чтоалгоритмпереобучился- оказался не способен показать такой же качественныйрезультат на новыхданных.Чтобы избежать переобучения,к минимизируемойфункциидобавляетсяслагаемое,которое зависиттолько от вектораW. Этослагаемоеназывается регуляризатором и позволяет бороться с переобучением.Плюсом логистической регрессииявляется то, что на выходе мыполучаемоценку вероятностиотнесениядокумента к определенномуклассу. Крометого, этоталгоритмимеетотносительнопростую программнуюреализацию.Недостаткомлогистической регрессии является сложная интерпретируемость алгоритма инеустойчивость по отношению к выбросам в исходных данных.
МЕТОД ОПОРНЫХ ВЕКТОРОВ
Следующийлинейныйалгоритм,которыймырассмотрим- этометодопорныхвекторов,SupportVectorMachine.Метод опорныхвекторов- такой подход кклассификации,прикотором ищется гиперплоскость,котораянаилучшимобразомразделяетклассыв обучающихданных.Алгоритмустроен так:онищетточкинаграфике,которыерасположеныближевсегонепосредственноклинииразделения.Этиточкиназываютсяопорнымивекторами.Затем,алгоритмвычисляетрасстояниемеждуопорнымивекторамии разделяющейплоскостью.Это расстояниекотороеназываетсязазором. Основнаяцельалгоритма — максимизировать расстояниезазора.Лучшейгиперплоскостьюсчитается такая гиперплоскость,длякоторойэтот зазор являетсямаксимально большим.Уметодаопорныхвекторовестькакплюсы,таки минусы.Этот методхороштем,что позволяетработатьс небольшимнаборомданных,идаетприэтомдовольноточныйрезультат. Но у него есть и недостатки.В первуюочередь это сложнаяинтерпретируемость параметровалгоритма. Кроме этого, алгоритмнеустойчивпоотношению к выбросам в исходных данных.Некогда метод опорныхвекторовбыл оченьпопулярени существует исуществует большое количество его расширений,в которыхавторыборются сперечисленныминедостатками.Отдельного упоминаниязаслуживаетKernelTrick-использование ядерных функций для метода опорных векторов.
НАИВНЫЙ БАЙЕС
Последнийметод, которыймырассмотрим- метод наивныйБайес.Еслинамизвестентекст, то задачуможнопоставитькак определениеусловнойвероятностипринадлежности текста к определеннойкатегории при условии,что в нёмприсутствуют выбранныенамипризнаки.Например,с какойвероятностьюписьмопопадетв спам,если в нём присутствует слово “выигрыш”.Такиеусловныевероятности сложно считать напрямую,поэтому используется формула Байеса,которуювы видитена слайде.Поскольку знаменательне зависитот класса Y, покоторомупроисходитоптимизация,егоможноопустить.Формулурасчетавероятностипринадлежноститекста к классу можносвестик болеепростойформе,используягипотезунезависимости.Этозначит, чтомыпредполагаем,чтовсепризнаки(внашемслучае- слова в тексте)независятдругот друга.Информацияо том,что в тексте
встречается определенныйтокен, не влияетна вероятность встретитьдругой.Например,мысчитаем,что, еслимывстретилив письмеслово “выигрыш”,это невлияетна вероятностьвстретитьв том же письмеслово “деньги”.В результатемыполучаемследующуюформулу, которуювывидитенаэкране.Величины,которыевнейучаствуют, настраиваются,основываясьна обучающейвыборке - размеченныхтекстах.ВероятностьклассаYзадаетсяотносительнойчастотойвобучающейвыборке,авероятностьИ-тоготокенаможномоделироватьпо-разному.Всамомпростомслучаевероятность можно задать равной относительной частоте и-того токена в классе Y.Плюсэтого алгоритма в том,что параметрыалгоритмамогутбытьвычисленыпо небольшому количеству обучающихданных.У алгоритма есть достоинства:высокая скорость работы, он не чувствителенк размерамобучающейвыборки,устойчивк переобучению.К недостаткамже относятсяв первуюочередьневысокаяточность классификациии невозможность учитывать зависимость результатов отсочетания различных признаков.
МЕТРИКИ
Рассмотрим на примеребинарнойклассификации,какиеесть подходы кизмерениюкачестваклассификации.Самыйпростойспособ-подсчитатьточностьилиaccuracy. Вэтомслучаемысмотримсоотношениекорректноопределенныхклассовкобщему объектов. Эта метрика очень понятная, но у неё есть свои недостатки.Первая проблема возникает, когдадатасеточеньнесбалансирован.Например,только 10%писемв вашейвыборке являютсяспамом.Тогда90-процентнуюaccuracyдаётконстанта: предсказание,что любое письмонеспам.Сама посебе accuracyкакединственное числодляоценкикачества в этомслучаенампочтиничего нескажет,кроме того, справляемся мы лучше константы или нет.
Втораяпроблема-невозможностьучитыватьразличныеошибки.Например,вамгораздоважнееопределятьспам,и стоимостьложного срабатывания,когданужноеписьмопопаловспам,оченьвысока,аобратнаяситуация,когдаспамнеопределился,ипопалвовходящие,неприятна,нонетаккритична.Приподсчететочностиневозможноразделить такие случаи.Поэтомурассматриваютсядве другиеметрики,точностьилипрецизионность(precision)и полнота (recall). Мыразличаемчетыретипапредсказаний.Первый,truepositives(ИП)-нужныйнамклассправильноопределился.Например,мыхотелинайтиспам,и нашлиего.Второй,falsenegative(ЛО)- спамнеопределилсяипопалвпапку“Входящие”.Третийслучай,falsepositive(ЛП)- наоборот, обычное письмопопаловспам.Truenegatives(ИО)- верноепредсказание,письмо,котороенеявляетсяспамом,не было определено в категорию “спам”.Precision- процентправильноопределенныхписемизвсех,которыесистемапометилакак “Спам”.Эта метрика хорошоотображаетложныесрабатыванияалгоритма. Recallже, наоборот, показывает, сколько писем со спамом из всех,существующихв выборке, моделиудалосьнайти.Такиеметрикиуже гораздолучшеотображают реальность, чем простое измерение точности предсказания.Чтобыпривестиобе метрикик одномучислу, существуетстандартныйметод,которыйназываетсяF1- мера.F1- мера- гармоническое среднееточностии полноты.Если точность или полнота стремятся к нулю, то она также стремится к нулю.
Выбормоделичасто определяется тем,что важнее- точностьилиполнота.Модель,котораяпредсказывает“да”с небольшимуровнемуверенности,будетиметьвысокуюполнотуинизкуюточность,втовремякакмодель,котораябудетдаватьтакоепредсказаниесвысокимуровнемуверенности,будетиметьнизкуюполнотуивысокуюточность.
precisionrecall  f1-score   support
class0 0.888 0.877 0.882 308class1 0.958 0.535 0.687 43class2 0.712 0.806 0.756 175
accuracy 0.825 526macro avg0.853 0.739 0.775 526weighted avg0.835 0.825 0.824 526
Длямногоклассовойклассификацииможновычислятьвсерассмотренныенамиоценкикачества длякаждого класса поотдельности.То естьмыкакбыдлякаждогоклассавсеостальныесваливаемводинклассирассматриваемпредсказаниякакзадачубинарнойклассификации.Так мысможем посмотреть,насколько хорошов планеточности и полноты для каждого класса мы справляемся с задачей.
Есть и другие способы оценкиклассификации,которые также могутпригодитьсяв обработке естественного языка. Более полныйобзор методовклассификации,в томчислетекстов,можнонайтив любомсерьёзномучебникелибокурсе по машинному обучению.
