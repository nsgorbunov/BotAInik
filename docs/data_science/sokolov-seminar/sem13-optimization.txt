Машинное обучение, ФКН ВШЭ
Семинар 13
29 января 2021 г.
1 Оптимизационные задачи и теорема Куна-Т аккера
Рассмотрим задачу минимизации







f0(x) → min
x∈Rd
fi(x) ⩽ 0, i = 1, . . . , m,
hi(x) = 0, i = 1, . . . , p.
(1.1)
Если ограничения в этой задаче отсутствуют , то имеет место необходимое усло-
вие экстремума: если в точке x функция f0 достигает своего минимума, то ее гради-
ент в этой точке равен нулю. Значит , для решения задачи безус ловной оптимизации
f0(x) → min
достаточно найти все решения уравнения
∇f0(x) = 0,
и выбрать то, в котором достигается наименьшее значение. Дл я решения условных
задач оптимизации требуется более сложный подход, который мы сейчас и рассмот-
рим.
§1.1 Лагранжиан
Задача условной оптимизации ( 1.1) эквивалентна следующей безусловной за-
даче:
f0(x) +
m∑
i=1
I−(fi(x)) +
p∑
i=1
I0(hi(x)) → min
x
,
где I−(x) /emdash.cyr индикаторная функция для неположительных чисел:
I−(x) =
{
0, x ⩽ 0
∞, x > 0,
1
2
а I0(x) /emdash.cyr индикаторная функция для нуля:
I0(x) =
{
0, x = 0
∞, x ̸= 0,
Т акая переформулировка, однако, не упрощает задачу /emdash.cyr индикаторные функции
являются кусочно-постоянными и могут быть оптимизированы лишь путем полного
перебора решений.
Заменим теперь индикаторные функции на их линейные аппрокс имации:
L(x, λ, ν ) =f0(x) +
m∑
i=1
λifi(x) +
p∑
i=1
νihi(x),
где λi ⩾ 0. Полученная функция называется лагранжианом задачи ( 1.1). Числа λi
и νi называются множителями Лагранжа или двойственными переменными.
Конечно, линейные аппроксимации являются крайне грубыми, однако их ока-
зывается достаточно, чтобы получить необходимые условия н а решение исходной
задачи.
§1.2 Двойственная функция
Двойственной функцией для задачи ( 1.1) называется функция, получающаяся
при взятии минимума лагранжиана по x:
g(λ, ν ) = inf
x
L(x, λ, ν ).
Можно показать, что данная функция всегда является вогнуто й.
Зачем нужна двойственная функция? Оказывается, она дает ни жнюю оценку
на минимум в исходной оптимизационной задаче. Обозначим ре шение задачи ( 1.1)
через x∗. Пусть x′ /emdash.cyrдопустимая точка, т .е. fi(x′) ⩽ 0, hi(x′) = 0. Пусть также λi > 0.
Т огда
L(x′, λ, ν ) =f0(x′) +
m∑
i=1
λifi(x′) +
p∑
i=1
νihi(x′) ⩽ f0(x′).
Если взять в левой части минимум по всем допустимым x, то неравенство останет-
ся верным; оно останется верным и в случае, если мы возьмем ми нимум по всем
возможным x:
inf
x
L(x, λ, ν ) ⩽ inf
x /emdash.cyr допуст .
L(x, λ, ν ) ⩽ L(x′, λ, ν ).
Итак, получаем
inf
x
L(x, λ, ν ) ⩽ f0(x′).
Поскольку решение задачи x∗ также является допустимой точкой, получаем, что
при λ ⩾ 0 двойственная функция дает нижнюю оценку на минимум:
g(λ, ν ) ⩽ f0(x∗).
3
§1.3 Двойственная задача
Итак, двойственная функция для любой пары (λ, ν ) с λ > 0 дает нижнюю
оценку на минимум в оптимизационной задаче. Попробуем тепе рь найти наилучшую
нижнюю оценку:
{g(λ, ν ) → max
λ,ν
λi ⩾ 0, i = 1, . . . , m.
(1.2)
Данная задача называется двойственной к задаче ( 1.1). Заметим, что функционал
в двойственной задаче всегда является вогнутым.
Разберём несколько примеров построения двойственных зада ч.
Задача 1.1. Постройте двойственную к оптимизационной задаче:
{∥x∥2 → min
x
Ax = b.
Отметим, что это задача поиска решения системы линейных ура внений с наименьшей
нормой.
Решение.Запишем лагранжиан:
L(x, ν ) =∥x∥2 + νT (Ax − b).
Найдем градиент:
∇xL(x, ν ) = 2x + νT A = 2x + AT ν.
Приравняв градиент нулю, найдем минимум лагранжиана при да нном ν:
x = −1
2AT ν.
Значит , двойственная функция равна
g(ν) =L
(
−1
2AT ν, ν
)
= −1
4νT AAT ν − bT ν.
Поскольку ограничений-неравенств в исходной задаче нет , в двойственной задаче не
будет ограничений. Получаем двойственную задачу
−1
4νT AAT ν − bT ν → max
ν
.
■
Задача 1.2. Постройте двойственную к задаче линейного программирован ия в
стандартном виде:





⟨c, x ⟩ → min
x
Ax = b,
x ⩾ 0.
4
Решение. Запишем лагранжиан:
L(x, λ, ν ) =⟨c, x ⟩ − λT x + νT (Ax − b).
Отметим, что ограничения-неравенства вошли с минусом, мы п ривели их к стандарт-
ному виду −x ⩽ 0. Немного преобразуем лагранжиан:
L(x, λ, ν ) =−bT ν + (c + AT ν − λ)T x.
Двойственная функция имеет вид
g(λ, ν ) =−bT ν + inf
x
(c + AT ν − λ)T x.
Заметим, что выражение (c + AT ν − λ)T x линейно по x и не ограничено, если c +
+ AT ν − λ ̸= 0. Т аким образом, условие c + AT ν − λ = 0 является ограничением в
двойственная задаче.
Получаем, что двойственная задача имеет вид





− bT ν → max
ν
c + AT ν − λ = 0,
λ ⩾ 0.
Ограничения можно объединить, избавившись от λ:
{ − bT ν → max
ν
c + AT ν ⩾ 0.
■
§1.4 Сильная и слабая двойственность
Пусть (λ∗, ν ∗) /emdash.cyr решение двойственной задачи. Значение двойственной функции
всегда не превосходит условный минимум исходной задачи:
g(λ∗, ν ∗) ⩽ f0(x∗).
Это свойство называется слабой двойственностью. Разность f0(x∗) − g(λ∗, ν ∗) назы-
вается зазором между решениями прямой и двойственной задач.
Если имеет место равенство
g(λ∗, ν ∗) =f0(x∗),
то говорят о сильной двойственности. Существует много достаточных условий силь-
ной двойственности. Одним из таких условий для выпуклых зад ач является условие
Слейтера. Выпуклой задачей оптимизации называется задача







f0(x) → min
x∈Rd
fi(x) ⩽ 0, i = 1, . . . , m,
Ax = b.
5
где функции f0, f 1, . . . , f m являются выпуклыми. У словие Слейтера требует , чтобы
существовала такая допустимая точка x′, в которой ограничения-неравенства выпол-
нены строго:
{
fi(x) < 0, i = 1, . . . , m,
Ax = b.
У словие Слейтера можно ослабить: достаточно, чтобы ограни чения-неравенства
были строгими только в том случае, если они не являются линей ными (т .е. не имеют
вид Ax − b).
§1.5 Условия Куна-Т аккера
Пусть x∗ и (λ∗, ν ∗) /emdash.cyr решения прямой и двойственной задач. Будем считать,
что имеет место сильная двойственность. Т огда:
f0(x∗) =g(λ∗, ν ∗)
= inf
x
(
f0(x) +
m∑
i=1
λ∗
ifi(x) +
p∑
i=1
ν∗
i hi(x)
)
⩽ f0(x∗) +
m∑
i=1
λ∗
ifi(x∗) +
p∑
i=1
ν∗
i hi(x∗)
⩽ f0(x∗)
Получаем, что все неравенства в этой цепочке выполнены как р авенства. Отсюда
можно сделать несколько выводов.
Во-первых, если подставить в лагранжиан решение двойствен ной зада-
чи (λ∗, ν ∗), то его минимум будет достигаться на решении прямой задачи x∗. Ины-
ми словами, решение исходной задачи (
1.1) эквивалентно минимизации лагранжиа-
на L(x, λ ∗, ν ∗) с подставленным решением двойственной задачи.
Во-вторых, из последнего неравенства получаем, что
m∑
i=1
λ∗
ifi(x∗) = 0.
Каждый член неположителен, поэтому
λ∗
ifi(x∗) = 0, i = 1, . . . , m.
Эти условия называются условиями дополняющей нежесткости. Они говорят , что
множитель Лагранжа при i-м ограничении может быть не равен нулю лишь в том
случае, если ограничение выполнено с равенством (в этом слу чае говорят , что оно
является активным).
6
Итак, мы можем записать условия, которые выполнены для реше ний прямой и
двойственной задач x∗ и (λ∗, ν ∗):





















∇f0(x∗) +
m∑
i=1
λ∗
i∇fi(x∗) +
p∑
i=1
ν∗
i ∇hi(x∗) = 0
fi(x∗) ⩽ 0, i = 1, . . . m
hi(x∗) = 0, i = 1, . . . p
λ∗
i⩾ 0, i = 1, . . . m
λ∗
ifi(x∗) = 0, i = 1, . . . m
(KKT)
Данные условия называются условиями Куна-Таккера (в зарубежной литературе
их принято называть условиями Каруша-Куна-Т аккера) и явля ются необходимыми
условиями экстремума. Их можно сформулировать несколько и наче:
Т еорема 1.1. Пусть x∗ /emdash.cyr решение задачи (
1.1). Т огда найдутся такие векторы λ∗
и ν∗, что выполнены условия (KKT).
Если задача ( 1.1) является выпуклой и удовлетворяет условию Слейтера, то
условия Куна-Т аккера становятся необходимыми и достаточными.
Посмотрим на примере, как из условий Куна-Т аккера можно най ти решение
задачи оптимизации.
Задача 1.3.Решите следующую задачу условной оптимизации:







(x − 4)2 + (y − 4)2 → min
x,y
x + y ⩽ 4,
x + 3y ⩽ 9.
Решение. Выпишем лагранжиан:
L(x, y, λ 1, λ 2) = (x − 4)2 + (y − 4)2 + λ1(x + y − 4) +λ2(x + 3y − 9).
У словия Куна–Т аккера запишутся в виде:









2(x − 4) +λ1 + λ2 = 0,
2(y − 4) +λ1 + 3λ2 = 0,
x + y ⩽ 4, λ 1 ⩾ 0, λ 1(x + y − 4) = 0,
x + 3y ⩽ 9, λ 2 ⩾ 0, λ 2(x + 3y − 9) = 0.
Решая их, рассмотрим 4 случая:
• x + y = 4, x + 3y = 9, λ1 > 0, λ2 > 0.
Два эти уравнения дают (x = 3
2 , y = 5
2 ). После подстановки в первые два урав-
нения условий Куна–Т аккера, получаем
{
2(3
2 − 4) +λ1 + λ2 = 0;
2(5
2 − 4) +λ1 + 3λ2 = 0,
откуда λ2 = −1, что противоречит принятым условиям.
7
• x + y = 4, x + 3y < 9, λ1 > 0, λ2 = 0.
Подстановка λ2 = 0 в первые два уравнения условий Куна–Т аккера вместе
с уравнением x + y = 4 дают решение (x = 2, y = 2, λ 1 = 4, λ 2 = 0). Эти
решения удовлетворяют всем условиям Куна–Т аккера.
• Два оставшихся случая, как и первый, ведут к противоречиям.
Поскольку задача выпуклая и удовлетворяет ослабленным усл овиям Слейтера,
найденная точка является решением.
■
§1.6 Экономическая интерпретация двойственной задачи
Предположим, что мы хотим открыть фирму . В нее мы можем наним ать про-
граммистов и менеджеров /emdash.cyr обозначим их количество черезx1 и x2 соответственно.
При этом каждый программист будет приносить c1 рублей в месяц, а каждый ме-
неджер /emdash.cyrc2 рублей. Труд каждого сотрудника должен оплачиваться. Наша фирма
может платить в двух формах /emdash.cyr акциями и картошкой, причем в месяц каждому
программисту нужно выдать a11 акций и a21 килограммов картошки; для менедже-
ров эти числа обозначим через a12 и a22. Разумеется, наши возможности ограничены:
мы можем тратить не больше b1 акций и b2 килограммов картошки в месяц. Запишем
формально все эти соотношения:











c1x1 + c2x2 → max
x1,x 2
a11x1 + a12x2 ⩽ b1
a21x1 + a22x2 ⩽ b2
x1 ⩾ 0, x 2 ⩾ 0
Это задача линейного программирования, для которой легко н айти двойствен-
ную:











b1y1 + b2y2 → min
y1,y 2
a11y1 + a21y2 ⩾ c1
a12y1 + a22y2 ⩾ c2
y1 ⩾ 0, y 2 ⩾ 0
Двойственную задачу можно проинтерпретировать следующим образом. Допустим,
что у нас появились другие дела, и вместо открытия фирмы мы ре шили продать все
ресурсы (т .е. акции и картошку). Разумеется, наши покупате ли будут стремиться
установить максимально низкую цену /emdash.cyr иными словами, они будут минимизировать
общую сумму сделки b1y1 + b2y2, где через y1 и y2 обозначены цены на одну акцию
и на один килограмм картошки соответственно. При этом у нас е сть ограничение:
мы не хотим продавать ресурсы дешевле, чем могли бы на них зар аботать, если
бы все же открыли фирму . Это означает , что суммарная стоимос ть a11 акций и a21
килограммов картошки (т .е. размер оплаты одного программи ста) не должна быть
меньше, чем доход от одного программиста c1. Это требование, вкупе с аналогичным
8
требованием к размеру оплаты менеджера, как раз соответств ует ограничениям в
двойственной задаче.
Поскольку для данных задач имеет место сильная двойственно сть, их решения
будут совпадать. Это означает , что оптимальная прибыль, ко торую можно получить
при открытии фирмы, совпадает с оптимальной выгодой от прод ажи всех ресурсов.
Список литературы
[1] Boyd, S., Vandenberghe, L. Convex Optimization. // Cambridge University Press,
2004.
