Машинное обучение
Семинар 3
Матрично-векторное дифференцирование
Как правило, дифференцируемые модели обучаются с помощью градиентного
спуска, а для него важно уметь считать градиент функционала ошибки по парамет-
рам модели. Можно считать градиент покоординатно, а потом пристально смотреть
на формулы и пытаться понять, как это может выглядеть в векторной форме. Гораз-
до проще считать градиент напрямую — а для этого поможет знание градиентов для
основных функций и основных правил матрично-векторного дифференцирования.
1 Вывод основных формул
Для начала вспомним определение производной для обычной функции одной
переменной. Говорят, что у функцииf : R → R в точке x есть производная f′(x),
если в этой точке функция представима в следующем виде для всех достаточно
маленьких dx:
f(x + dx) =f(x) +f′(x)dx + o(dx).
То есть производная — это коэффициент, определяющий линейную часть прира-
щения функции. Обобщим это на случай функций, работающих в конечномерных
линейных пространствах с нормами. Говорят, что функцияf : Rn → Rm дифферен-
цируема в точкеx, если существует такой линейный операторL : Rn → Rm, что для
любых достаточно малых по нормеdx ∈ Rn выполнено
f(x + dx) =f(x) +L[dx] +o(∥dx∥).
Можно показать, что если функция дифференцируема в точкеx, то соответствую-
щий линейный оператор определяется единственным образом. Будем обозначать его
как df(x) и называть дифференциалом. Поскольку дифференциал — это линейный
оператор, то в зависимости от размерностей пространств он может быть представ-
лен как скалярное произведение⟨ax, dx⟩, умножение на матрицуAx dx или схожим
образом. Тогда по аналогии с одномерным случаем векторax или матрицаAx явля-
ются «производными» функции в точкеx. Как мы знаем, для них есть специальные
названия: ax называется градиентом,Ax — матрицей Якоби.
Когда мы работали с одномерными функциями, в большинстве случаев для
поиска производных нам хватало небольшой таблицы со стандартными случаями и
пары правил. Для случая векторных и матричных функций все эти правила можно
1
2
обобщить, а таблицы дополнить специфическими функциями вроде определителя.
Удобнее всего оказывается работать в терминах «дифференциала» — с ним можно
не задумываться о промежуточных размерностях, а просто применять стандартные
правила.
Введём некоторые обозначения:
• При отображении вектора в числоf(x) :Rn → R
∇xf(x) =
 ∂f
∂x1
, . . . ,∂f
∂xn
T
• При отображении матрицы в числоf(A) :Rn×m → R
∇Af(A) =
 ∂f
∂Aij
n,m
i,j=1
• При отображении вектора в векторf(x) :Rn → Rm
Jx =
∂fi
∂xj
n,m
i,j=1
Мы хотим оценить, как функция изменяется по каждому из аргументов по
отдельности. Поэтому производной функции по вектору будет вектор, по матрице —
матрица.
Нарисуемтаблицустем,каквыглядятдифференциалыдляразныхслучаев.По
строчкам будем откладывать то, откуда бьёт функция, то есть входы. По столбцам
будем откладывать то, куда бьёт функция, то есть выходы. На пересечении будут
расположены дифференциалы. Для ситуаций, обозначенных прочерками, обобщения
получить не выйдет.
скаляр вектор матрица
скаляр f′(x) dx J dx —
вектор ∇xf(x)T dx J dx —
матрица tr(∇Af(A)T dA) — —
Всегда, когда мы будем сталкиваться с дифференцированием на практике, мы
будем выяснять, к какой из ситуации относится задача, а дальше сводит дифферен-
циал к виду из таблицы выше и вытаскивать из него производную.
1. Для функции, которая бьётиз скаляров в скалярыf(x) :R → R дифферен-
циал выглядит какdf(x) =f′(x) dx.
2. Когда функция бьётиз векторов в скалярыf(x) :Rn → R., мы имеем дело с
функцией нескольких переменных. Нам нужно взять производную по каждой
из них и получить вектор производных, градиент
∇xf =


∂f
∂x1
. . .
∂f
∂xn


3
Если умножить транспонированный градиент на вектор приращений, у нас по-
лучится дифференциал
df(x) =∇xfT dx =

∂f
∂x1
, . . . ,∂f
∂xn



dx1
. . .
dxn

 = ∂f
∂x1
· dx1 + . . .+ ∂f
∂xn
· dxn.
При измененииxi на dxi функция будет при прочих равных меняться пропор-
ционально соответствующей частной производной.
3. Когда функция бьётиз векторов в векторыf(x) :Rn → Rm, мы взаимодей-
ствуем с семейством функций. Например, еслиn = 1то у нас естьm функций,
каждая из которых применяется кx. На выходе получается вектор


f1(x)
f2(x)
. . .
fm(x).


Если мы хотим найти производную, нужно взять частную производную каждой
функции поx и записать в виде вектора. Дифференциал также будет представ-
лять из себя вектор, так как при приращении аргумента на какую-то величину
изменяется каждая из функций
df(x) =


∂f1
∂x∂f2
∂x
. . .
∂fm
∂x

 ·
 
dx

=


∂f1
∂x dx
∂f2
∂x dx
. . .
∂fm
∂x dx

.
Тут мы умножаем каждую строчку из вектора размераn×1 на столбец матри-
цы 1 × 1. Если хочется, можно рассуждать об этом как о поэлементном умно-
жении. Если n > 1, то аргументов на вход в такой вектор из функций идёт
несколько, на выходе получается матрица


f1(x1) f1(x2) . . . f1(xn)
f2(x1) f2(x2) . . . f2(xn)
. . . . . . ... . . .
fm(x1) fm(x2) . . . fm(xn)


Производной такой многомерной функции будет матрица из частных производ-
ных каждой функции по каждому аргументу
4


∂f1
∂x1
∂f1
∂x2
. . .∂f1
∂xn
∂f2
∂x1
∂f2
∂x2
. . .∂f2
∂xn
. . . . . .... . . .
∂fm
∂x1
∂fm
∂x2
. . .∂fm
∂xn

.
Дифференциал снова будет представлять из себя вектор
df(x) =


∂f1
∂x1
∂f1
∂x2
. . .∂f1
∂xn
∂f2
∂x1
∂f2
∂x2
. . .∂f2
∂xn
. . . . . .... . . .
∂fm
∂x1
∂fm
∂x2
. . .∂fm
∂xn

·


dx1
dx2
. . .
dxn

 =


∂f1
∂x1
dx1 + ∂f1
∂x2
dx2 + . . .+ ∂f1
∂xn
dxn
∂f2
∂x1
dx1 + ∂f2
∂x2
dx2 + . . .+ ∂f2
∂xn
dxn
. . .
∂fm
∂x1
dx1 + ∂fm
∂x2
dx2 + . . .+ ∂fm
∂xn
dxn

.
4. Функция бьёт из матриц в скалярыf(A) : Rn×k → R.В таком случае нам
надо найти производную функции по каждому элементу матрицы, то есть диф-
ференциал будет выглядеть как
df(A) = ∂f
∂a11
da11 + . . .+ ∂f
∂ank
dank.
Его можно записать в компактном виде через след матрицы как
df(A) = tr(∇AfT dA),
Вполнеестествененвопрос—апочемуэтоможнозаписатьименнотак?Давайте
попробуем увидеть этот факт на каком-нибудь простом примере. Пусть у нас
есть две матрицы
A[2×3] =
a11 a12 a13
a21 a22 a23

B[2×3] =
b11 b12 b13
b21 b22 b23

.
Посмотрим на то, как выглядитtr(BT dA). Как это ни странно, он совпадает с
дифференциалом
tr(BT dA) = tr




b11 b21
b12 b22
b13 b23


da11 da12 da13
da21 da22 da23

,
при произведении на выходе получаем матрицу размера3 × 3


b11 da11 + b21 da21 b11 da12 + b21 da22 b11 da13 + b21 da23
b12 da11 + b22 da21 b12 da12 + b22 da22 b12 da13 + b22 da23
b13 da11 + b23 da21 b13 da12 + b23 da22 b13 da13 + b23 da23

.
5
Когда мы берём её след, остаётся сумма элементов по диагонали. Это и есть
требуемыйдифференциал.Дальшемыпериодическибудемпользоватьсятаким
приёмом.
Например, величину||X − A||2 = P
i,j(xij − aij)2 можно записать в матричном
виде какtr((X − A)T (X − A)).
5. В таблице осталось ещё несколько ситуаций, которые остались вне поля нашего
зрения. Например, давайте посмотрим на ситуацию когда отображение бьёт из
матриц в векторыf(A) :Rn×k → Rm.
Тогда A матрица, а f(A) вектор. Нам надо найти производную каждого эле-
мента из вектораf(A) по каждому элементу из матрицыA. Получается, что∂f
∂A
— это трёхмерная структура. Мы с такими ситуациями встречаться не будем,
поэтому опустим их.
Свойства матричных дифференциалов очень похожи на свойства обычных. На-
до только не забыть, что мы работаем с матрицами.
d(AB) = dAB + A dB, dAB ̸= B dA
d(αA + βB) =α dA + β dB
d(AT ) = ( dA)T
dC = 0, C − матрица из констант
Чтобы доказать все эти свойства достаточно просто аккуратно расписать их.
Кроме этих правил нам понадобится пара трюков по работе со скалярами. Еслиs —
скаляр размера1 × 1, тогдаsT = s и tr(s) =s.
С помощью этих преобразований мы будем приводить дифференциалы к кано-
ническому виду и вытаскивать из них производные.
Задача 1.1. Пусть a ∈ Rn — вектор параметров, а x ∈ Rn — вектор перемен-
ных. Рассмотрим функцию, которая представляет из себя их скалярное произведение
f(x) =aT x. Нужно найти её производную по вектору переменных∇xf(x).
Решение. Функция f(x) бьёт из векторов в скалярыf(x) :Rn → R. Если мы хотим
найти производную функцииf(x1, x2, . . . , xn), нам надо взять производную по каж-
дому аргументу и выписать градиент. Можно расписать умножение одного вектора
на другой в виде привычной нам формулы
f(x)
[1×1]
= aT
[1×n]
· x
[n×1]
=
 
a1 a2 . . . an

·


x1
x2
. . .
xn

 = a1 · x1 + a2 · x2 + . . .+ an · xn.
Из неё чётко видно, что∂f
∂xi
= ai
∇xf =


∂f
∂x1
∂f
∂x2
. . .
∂f
∂xn

 =


a1
a2
. . .
an

 = a,
6
теперь можно записать дифференциал
df = aT dx = ∂f
∂x1
· dx1 + . . .+ ∂f
∂xn
· dxn = a1 · dx1 + . . .+ an · dxn.
В то же самое время можно было бы просто воспользоваться правилами на-
хождения матричных дифференциалов
df = daT x = aT dx = ∇xfT dx,
откуда ∇xf = a. При таком подходе нам не надо анализировать каждую част-
ную производную по отдельности. Мы находим все производные за раз.
■
7
Задача 1.2. Пусть f(x) = xT Ax, гдеx вектор размера n × 1, A матрица размера
n × n. Найдите производную ∇xf(x).
Решение. Функция бьёт из векторов в скаляры. Попробуем перемножить все мат-
рицы и расписать её в явном виде по аналогии со скалярным произведением
f(x)
[1×1]
= xT
[1×n]
· A
[n×n]
· x
[n×1]
=
nX
i=1
nX
j=1
aij · xi · xj.
Если продолжить в том же духе, мы сможем найти все частные производные, а
потом назад вернём их в матрицу. Однако это неудобно. Всё было записано в краси-
вом компактном матричном виде, а мы это испортили. Более того, если множителей
будет больше, тогда суммы станут совсем громоздкими, и мы легко запутаемся.
При этом, если воспользоваться правилами работы с матричными дифферен-
циалами, мы легко получим ответ
df = dxT Ax = d(xT )Ax + xT d(Ax) = d(xT )Ax + xT d(A)
dA=0
x + xT A d(x).
Заметим, чтоd(xT )Ax это скаляр. Его транспонирование никак не повлияет на
результат
df = d(xT )Ax + xT A d(x) =xT AT dx + xT A dx = xT (AT + A) dx.
Мы нашли матричный дифференциал и свели его к каноничной форме
df = ∇T
x f dx = xT (AT + A) dx
Получается, что искомая производная∇xf = (A + AT )x. Обратите внимание,
что размерности не нарушены, и мы получили столбец из производных, то есть ис-
комый градиент нашей функцииf(x).
■
Задача 1.3. Пусть f(x) =xT Ax, гдеx ∈ Rn, A∈ Rn×n. Найдите вторую производ-
ную поx.
Решение. Чтобы найти вторую производную, надо продифференцировать первую
производную. Первая производная g(x) = (A + AT )x бьёт из векторов в векторы.
Приведём дифференциал к каноническому виду
dg(x) = d(A + AT )x = (A + AT ) dx.
Выходит, что матрица из вторых производных для функцииf(x) выглядит
как A + AT . Обратите внимание, что для этой ситуации в каноническом виде нет
транспонирования.
■
8
Задача 1.4. Пусть f(X) = aT XAXa , где a ∈ Rn, X∈ Rn×n. Необходимо найти
производную ∇Xf.
Решение. Функция бьёт из матриц в скаляры. Дифференциал будет по своей раз-
мерности совпадать со скаляром. Производная будет размера матрицы
df(X) = d(aT XAXa ) =aT d(X)AXa + aT XA d(X)a.
Оба слагаемых, которые мы получаем после перехода к дифференциалу — ска-
ляры. Мы хотим представить дифференциал в видеtr(нечтоdX). След скаляра —
это снова скаляр. Получается, что мы бесплатно можем навесить над правой частью
нашего равенство знак следа и воспользоваться его свойствами
df(X) = d(aT XAXa ) = tr(aT d(X)AXa) + tr(aT XA d(X)a) =
= tr(AXaaT d(X)) + tr(aaT XA d(X)) =
= tr(AXaaT d(X) +aaT XA d(X)) = tr((AXaaT + aaT XA) d(X)).
Производная найдена, оказалось что это
∇Xf = (AXaaT + aaT XA)T = aaT XT AT + AT XT aaT .
■
Задача 1.5. Пусть f(x) =xxT x, гдеx ∈ Rn. Необходимо найти производную∇xf.
Решение. Функция бьёт из векторов в векторы.
f(x)
[n×1]
= x
[n×1]
xT
[1×n]
x
[n×1]
.
Берём дифференциал
df(x) = dxxT x = dxxT x + x dxT x + xxT dx.
В первом слагаемом пользуемся тем, чтоxT x скаляр и его можно вынести перед
дифференциалом. Этот скаляр умножается на каждый элемент вектора. Дальше мы
захотим вынести дифференциал за скобку, чтобы не испортить матричное сложение,
подчеркнём факт этого перемножения на каждый элемент единичной матрицей. Во
втором слагаемом пользуемся тем, чтоdxT x скаляр и транспонируем его
df(x) =xT x
[1×1]
In
[n×n]
dx
[n×1]
+ xxT dx + xxT dx = (xT xIn + 2xxT ) dx.
Обратите внимание, что без единичной матрицы размерности у сложения по-
ломаются. Получается, что наша производная выглядит какJ = xT xIn + 2xxT
■
Найдём несколько табличных производных, которыми мы дальше будем актив-
но пользоваться: производную обратной матрицы, определителя и следа.
9
Задача 1.6. Пусть f(A) =A−1, где A ∈ Rn×n. Необходимо найти∇Af(A).
Решение. Вспомним, что производная константы равна нолю. Обратная матрица
определяется какA−1 · A = In, где In — единичная матрица. Берём дифференциал с
обеих сторон нашего равенства
dA−1A + A−1 dA = dIn = 0,
отсюда получаем чтоdA−1 = −A−1 dAA−1. Везде, где мы будем встречать диф-
ференциал обратной матрицы, мы будем использовать это значение. Обратите вни-
мание, что обратная матрица как функция отображает матрицы в матрицы. Эта
клетка в табличке производных осталась нами незаполненной. Тем не менее мы мо-
жем использовать ту же самую технику с дифференциалами. Если где-то нам надо
будет посчитать дифференциал обратной матрицы, мы будем поставлять туда полу-
ченную выше формулу.
■
Задача 1.7. Пусть A ∈ Rn×n. Необходимо найти∇A det A.
Решение. Определитель — это функция, которая бьёт из матриц в скаляры. Вос-
пользуемся теоремой Лапласа о разложении определителя по строке:
∂
∂Aij
det A = ∂
∂Aij
X
k
(−1)i+kAikMik

= (−1)i+jMij,
где Mik — дополнительный минор матрицыA. Также вспомним формулу для эле-
ментов обратной матрицы
(A−1)ij = 1
det A(−1)i+jMji.
Подставляявыражениедлядополнительногоминора,получаемответ ∇A det A =
= (detA)A−T . При этом, так как функция бьёт из матриц в скаляры дифференциал
можно записать какd detA = tr(det(A)A−1 dA).
■
Задача 1.8. Пусть A ∈ Rn×n. Необходимо найти∇A tr(A).
Решение. По аналогии с определителем след бьёт из пространства матриц в про-
странство скаляров представляет из себя сумму диагональных элементов. Получа-
ется, что d(tr A) = tr(In dA) и ∇A tr A = In.
■
Задача 1.9. Пусть A ∈ Rn×n, B ∈ Rn×n. Необходимо найти∇Atr(AB).
Решение. Воспользовавшись циклическим свойством следа матрицы (для матриц
подходящего размера):
10
tr(ABC) =tr(BCA) =tr(CAB)
получаем
d tr(AB) = tr( dAB) = tr(B dA),
то есть∇Atr(AB) =BT .
■
Задача 1.10. Пусть x ∈ Rn, A∈ Rn×m, y∈ Rm. Необходимо найти∇A tr(xT Ay).
Решение. Воспользовавшись циклическим свойством следа и результатом преды-
дущей задачи, получаем
d tr(xT Ay) = tr( dxT Ay) = tr(yxT dA),
то есть∇A tr(xT Ay) =xyT .
■
Наконец, научимся считать градиенты для сложных функций. Допустим, да-
ны функции f : Rn → Rm и g : Rm → R. Тогда градиент их композиции можно
вычислить как
∇xg (f(x)) =JT
f (x)∇z g(z)|z=f(x) ,
гдеJf (x) =

∂fi(x)
∂xj
m,n
i,j=1
— матрица Якоби для функцииf. Еслиm = 1и функцияg(z)
имеет всего один аргумент, то формула упрощается:
∇xg (f(x)) =g′(f(x))∇xf(x).
Задача 1.11. Вычислите градиент логистической функции потерь для линейной
модели по параметрам этой модели:
∇w log (1 + exp(−y⟨w, x⟩)) .
Решение. Воспользуемся правилом взятия производной сложной функции и произ-
водной скалярного произведение из задачи выше
∇w log (1 + exp(−y⟨w, x⟩)) =
= 1
1 + exp(−y⟨w, x⟩)∇w (1 + exp(−y⟨w, x⟩)) =
= 1
1 + exp(−y⟨w, x⟩) exp(−y⟨w, x⟩)∇w (−y⟨w, x⟩) =
= − 1
1 + exp(−y⟨w, x⟩) exp(−y⟨w, x⟩)yx =
=

σ(z) = 1
1 + exp(−z)

=
= −σ(−y⟨w, x⟩)yx
■
11
§1.1 Решение задачи регрессии для многомерного случая
Вспомним, зачем мы хотели научиться дифференцировать. В общем случае
мы имеем выборку{(xi, yi)}ℓ
i=1, xi ∈ Rd, yi ∈ R i = 1, ℓ, и хотим найти наилучшие
параметры моделиa(x) =⟨w, x⟩ с точки зрения минимизации функции ошибки
Q(w) = (y − Xw)T (y − Xw).
Здесь X ∈ Rℓ×d — матрица «объекты-признаки» для обучающей выборки,
y ∈ Rℓ —векторзначенийцелевойпеременнойнаобучающейвыборке, w ∈ Rd —век-
тор параметров. Выпишем дифференциал функции ошибки поw:
dwQ = dw[(y − Xw)T (y − Xw)] =
= dw[(y − Xw)T ](y − Xw) + (y − Xw)T dw[(y − Xw)] =
= dw[(−Xw)T ](y − Xw) − (y − Xw)T X dw =
= −dwT XT (y − Xw) − (y − Xw)T X dw = −2(y − Xw)T X dw.
Тут мы воспользовались тем, что dwT XT (y − Xw) это скаляр и его можно
транспонировать. Приравняем производную к нулю, чтобы найти минимум дляw.
Получается система уравнений
2XT (y − Xw) = 0 ⇒ XT y = XT Xw ⇒ w = (XT X)−1XT y.
Прирешениисистемымысделалипредположение,чтоматрица XT X обратима.
Это так, если в матрицеX нет линейно зависимых столбцов, а также наблюдений
больше чем переменных.
Заметим, что это общая формула, и нет необходимости выводить формулу для
регрессии вида a(x) = Xw + w0, т.к. мы всегда можем добавить признак (столбец
матрицы X), который всегда будет равен1, и по уже выведенной формуле найдём
параметр w0.
Если бы аналитического решения не существовало, мы могли бы найти точку
оптимума с помощью градиентного спуска. Его шаг выглядел бы как
wt = wt−1 + γ · 2XT (y − Xw), здесь γ — это скорость обучения.
Покажем, почему найденная точка — точка минимума, если матрицаXT X об-
ратима. Из курса математического анализа мы знаем, что если матрица Гессе функ-
ции положительно определёна в точке, градиент которой равен нулю, то эта точка
является локальным минимумом. Найдём вторую производную
dw[−2XT (y − Xw)] = 2XT X dw.
Выходит, что
∇2Q(w) = 2XT X.
12
Необходимо понять, является ли матрицаXT X положительно определённой.
Запишем определение положительной определённости матрицыXT X:
zT XT Xz >0, ∀z ∈ Rd, z̸= 0.
Видим, что тут записан квадрат нормы вектораXz, то есть это выражение бу-
дет не меньше нуля. В случае, если матрицаX имеет «книжную» ориентацию (строк
не меньше, чем столбцов) и имеет полный ранг (нет линейно зависимых столбцов),
то векторXz не может быть нулевым, а значит выполняется
zT XT Xz = ||Xz||2 > 0, ∀z ∈ Rd, z̸= 0.
То естьXT X является положительно определённой матрицей. Также, по кри-
терию Сильвестра, все главные миноры (в том числе и определитель) положительно
определённой матрицы положительны, а, следовательно, матрицаXT X обратима,
и решение существует. Если же строк оказывается меньше, чем столбцов, илиX не
является полноранговой, тоXT X необратима и решениеw определено неоднозначно.
Список литературы
[1] Родоманов А.О. (2017). Матрично-векторное дифференцирование. // http://
www.machinelearning.ru/wiki/images/5/50/MOMO17_Seminar2.pdf.
[2] Kaare B. Petersen, Michael S. Pedersen(2012). The Matrix Cookbook. //https:
//www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf.
