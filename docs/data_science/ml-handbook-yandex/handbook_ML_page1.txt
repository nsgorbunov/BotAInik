Машинное обучение — это наука, изучающая алгоритмы, автоматически улучшающиеся благодаря опыту.
Когда Алан Тьюринг работал над первыми (компьютерами), он пытался расшифровать сообщения немецких военных, закодированные машиной Энигма. Поиск расшифровки требовал перебора массы вариантов. Люди с этой задачей справлялись плохо, зато машина могла решить её сравнительно быстро. Очевидно, далеко не для каждой задачи, с которой люди справляются с трудом, можно написать программу для эффективного поиска решения. Более того, есть целый класс задач (так называемые NP-трудные задачи), которые нельзя решить за разумное время. Можно даже явно доказать, что никакой компьютер здесь чуда тоже не совершит. Самое интересное это то, что бывают и задачи, которые для людей особенного труда не составляют, но которые почему-то крайне трудно запрограммировать, например:


перевести текст с одного языка на другой;


диагностировать болезнь по симптомам;


сравнить, какой из двух документов в интернете лучше подходит под данный поисковый запрос;


сказать, что изображено на картинке;


оценить, по какой цене удастся продать квартиру.


У всех этих задач есть много общего. Во-первых, их решение можно записать как функцию, которая отображает объекты или примеры (samples) в предсказания (targets). Например, больных надо отобразить в диагнозы, а документы в оценку релевантности. Во-вторых, вряд ли у этих задач есть единственно верное, идеальное решение. Даже профессиональные переводчики могут по-разному перевести один и тот же текст, и оба перевода будут верными. Так что лучшее в этих задачах — враг хорошего. В конце концов, и доктора иногда делают ошибки в диагнозах, и вы не всегда можете сказать, что же именно изображено на картинке. В-третьих, у нас есть много примеров правильных ответов (скажем, переводов предложения на другой язык или подписей к заданной картинке), а примеры неправильных ответов (если они нужны), как правило, не составляет труда сконструировать. Мы назовём функцию, отображающую объекты в предсказания, — моделью, а имеющийся у нас набор примеров — обучающей выборкой или датасетом. Обучающая выборка состоит из:


объектов (к примеру, скачанные из интернета картинки, истории больных, активность пользователей сервиса и так далее);


и ответов (подписи к картинкам, диагнозы, информация об уходе пользователей с сервиса), которые мы также будем иногда называть таргетами.


Постановка задачиПостановка задачи
Описанные выше задачи являются примерами задач обучения с учителем (supervised learning), так как правильные ответы для каждого объекта обучающей выборки заранее известны. Задачи обучения с учителем делятся на следующие виды в зависимости от того, каким может быть множество  всех возможных ответов (таргетов):

 или  — регрессия. Примерами задач регрессии является предсказание продолжительности поездки на каршеринге, спрос на конкретный товар в конкретный день или погода в вашем городе на завтра (температура, влажность и давление — это несколько вещественных чисел, которые формируют вектор нашего предсказания).
 — бинарная классификация. Например, мы можем предсказывать, кликнет ли пользователь по рекламному объявлению, вернёт ли клиент кредит в установленный срок, сдаст ли студент сессию, случится ли определённое заболевание у пациента, есть ли на картинке банан.
 — многоклассовая (multiclass) классификация. Например, определение предметной области для научной статьи (математика, биология, психология и т. д.).
 — многоклассовая классификация с пересекающимися классами (multilabel classification). Например, задача автоматического проставления тегов для ресторанов (логично, что ресторан может одновременно иметь несколько тегов).
 — конечное упорядоченное множество — ранжирование. Основным примером является задача ранжирования поисковой выдачи, где для любого запроса нужно отсортировать все возможные документы по релевантности этому запросу; при этом оценка релевантности имеет смысл только в контексте сравнения двух документов между собой, её абсолютное значение информации не несёт.

Ответ может быть и более сложным. Так, в задаче сегментации изображения требуется для каждого пикселя предсказать, к какому объекту или типу объектов он относится, а в задаче машинного перевода мы должны сгенерировать предложение (или целый текст), являющееся переводом исходного. Интерес представляют и задачи порождения новых объектов то есть генерации правдоподобных объектов, из ничего или на основе уже существующих. С помощью такой модели также можно научиться увеличивать разрешение изображения и применять любимые всеми маски в Snapchat или Instagram.
Есть и относительно небольшой класс задач, относящихся к обучению без учителя (unsupervised learning), — это задачи, для которых нам известны только данные, а ответы неизвестны или вообще не существуют. Более того, часто поиск "правильных" ответов не является самоцелью. Классическим примером обучения без учителя является кластеризация — задача разделения объектов на группы, обладающие некоторыми неизвестными нам, но, как мы в глубине души надеемся, интерпретируемыми свойствами. Примером может служить кластеризация документов из электронной библиотеки по темам или кластеризация новостей с целью выделения крупных сюжетов.
Бывают и другие виды (и даже парадигмы) машинного обучения, так что если вы встретите задачу, которую никак не получается отнести к одному из перечисленных выше типов, не расстраивайтесь и знайте, что где-то дальше в учебнике вас ждёт рассказ про такие задачи.
Вопрос на подумать. Определите тип следующих задач. По возможности попробуйте отнести их к более узким видам задач.


Предсказание курса евро к доллару на следующий день.


Стилизация текста. Например, перевод на бюрократический язык: «Пиппина и Мерри похитили!»  «Граждане Тук, Перегрин Паладинович, 2990 года рождения, и Брендибак, Мериадок Сарадокович, 2982 года рождения, были похищены неустановленными лицами».


Детектирование котиков на изображении.


Обучение робокота запрыгивать на стол из произвольной позы.


Поиск наборов товаров, которые посетители супермаркета часто покупают вместе.


Ответ (не открывайте сразу; сначала подумайте сами!)

Это задача регрессии. Модель предсказывает вещественное число пусть и с небольшим количеством знаков после запятой.


Это задача генерации новых объектов на основе уже существующих.


В зависимости от того, для чего мы детектируем котиков, это может быть задача регрессии (предсказание координат вершин прямоугольника, в котором находится котик) или классификации (если нас просто интересует, есть котик или нет).


Эту задачу можно решать по-разному. Например, создав физическую модель движения робокота и рассчитав оптимальную последовательность движений. Если мы всё-таки хотим решать её с помощью машинного обучения, то можно поступить следующим образом. Создадим компьютерную симуляцию (чтобы не ломать настоящего робота) и модель, которая будет в каждый момент на основе конфигурации сочленений, высоты от пола, расстояния до стола, фазы Луны и других важных параметров предсказывать, как нужно дальше поворачивать лапы, изгибать спину кота и так далее. Эту модель будем прогонять в симуляции, так или иначе меняя её в зависимости от того, насколько удачно робот справляется со своей задачей. Такая парадигма называется обучением с подкреплением (reinforcement learning), и о ней мы поговорим в отдельном параграфе.


Вы можете спросить: а почему это не обучение с учителем? Ведь у нас есть объекты — последовательности движений и ответы — запрыгнул кот на стол или нет. Проблема в том, что перебрать кучу траекторий (ввиду сложности задачи — действительно огромную кучу) и для каждой получить ответ — это очень долго и сложно; кроме того, нам хотелось бы иметь фреймворк, в котором можно было бы относительно легко адаптироваться, скажем, к изменению высоты стола.

Это задача обучения без учителя.

Вопрос на подумать. Ранжирование — это задача с таргетом из конечного упорядоченного множества . Казалось бы, её запросто можно было бы рассматривать как задачу классификации на  классов или задачу регрессии. В чём же проблема? Почему так не делают?
Ответ (не открывайте сразу; сначала подумайте сами!)Для решения задач ранжирования обычно строят модель, предсказывающую некоторое вещественное число, по которому затем сортируют объекты, — так почему бы не считать её регрессией? Дело в том, что функции потерь и метрики в этой задаче совсем другие. Нам неважно, какие именно вещественные числа мы предсказываем. Мы просто хотим, чтобы более релевантным объектам сопоставлялись числа побольше.
Задача «предскажите 10 самых релевантных объектов» непохожа на задачу классификации. Мир меняется, появляются новые объекты, и если к нам в руки попадёт объект более релевантный, чем текущий топ-1, все номера позиций поедут, и выученное нами соответствие объектов и номеров можно будет выкидывать на помойку.
Критерии качестваКритерии качества
По обучающей выборке мы хотим построить модель, предсказания которой достаточно хороши. Что вообще значит «достаточно хороши»? Не понимая, чего мы хотим добиться, мы не предложим хорошего решения, поэтому нужно внимательно отнестись к выбору метрик качества.
Возможно, вы уже участвовали в соревнованиях по анализу данных. На таких соревнованиях метрику организатор выбирает за вас, и она, как правило, непосредственным образом связана с результатами предсказаний. Но на практике всё бывает намного сложнее.
Например, мы хотим:

решить, сколько коробок с бананами нужно завтра привезти в конкретный магазин, чтобы минимизировать количество товара, который не будет выкуплен, и минимизировать вероятность того, что покупатель к концу дня не найдёт желаемый продукт на полке;
увеличить счастье пользователей от работы с нашим сервисом, чтобы пользователи стали лояльнее, а сервис мог получать стабильный прогнозируемый доход;
решить, нужно ли направить пациента на дополнительное медицинское обследование.

В каждом конкретном случае может возникать целая иерархия метрик.


Самый верхний уровень – это бизнес-метрики, например, будущий доход сервиса. Их трудно измерить в моменте, они сложным образом зависят от совокупности всех наших усилий, не только связанных с машинным обучением.


Онлайн (online) метрики – это характеристики работающей системы, с помощью которых мы надеемся оценить, что будет с бизнес-метриками. Например, это может быть:
– Медианная длина сессии в онлайн-игре. Можно предположить, что пользователь, который долго сидит в игре – это довольный пользователь.
– Среднее количество бананов на полках во всех магазинах торговой сети в конце дня.


Не всегда плоды наших трудов оцениваются числами. Многое может зависеть от субъективного восприятия людей, и для того, чтобы оценить их реакцию до выпуска в продакшен, применяется оценка специально нанятыми людьми – асессорами. Например, так можно оценивать, получилось ли у нас улучшить качество машинного перевода или релевантность выдачи в поисковой системе.


Офлайн (offline) метрики могут быть измерены до введения модели в эксплуатацию, например, по историческим данным. В задачах, в которых нужно предсказывать какой-то конкретный таргет, офлайн метрики обычно оценивают отклонение предсказаний модели от истинных значений таргета. Например, это может быть точность предсказания, то есть число верно угаданных значений, или среднеквадратичное отклонение.


Асессорскую оценку тоже можно считать офлайн-метрикой
В этой книге речь в основном пойдёт об офлайновых метриках и о функциях потерь. И прежде, чем вы начнёте знакомиться с методами решения задач обучения с учителем, полезно посмотреть, какими бывают метрики качества. Вот несколько примеров:


для задачи постановки диагноза хорошими метриками могут быть, например, доля правильно поставленных диагнозов или доля больных, которым удалось поставить правильный диагноз (а вы поняли разницу?);


для задачи предсказания цены квартиры метрикой качества может быть доля квартир, для которых разница между предсказанным и истинным значением цены не превысила какого-то порога, или средний модуль разницы между предсказанным и истинным значением;


для задачи ранжирования поисковых документов по запросу — доля пар документов, которые мы упорядочили неправильно.


Цель обычно в том, чтобы найти модель, для которой значение метрики будет оптимальным.
Вопрос на подумать. Важно помнить, что разные нужды заказчика могут диктовать самые разные метрики. Вернёмся к задаче постановки диагноза пациентам больницы. Какие метрики вы предложили бы использовать в каждом из следующих случаев:


обычный год в обычном терапевтическом отделении обычной больницы;


определение очень неприятной болезни, которая жутким клеймом падёт на каждого, кому поставили такой диагноз;


определение опасной и очень заразной болезни.


Ответ (не открывайте сразу; сначала подумайте сами!)Конечно, даже в каждом из этих довольно частных случаев могут быть разные ситуации и разные метрики, но вот как, например, можно было бы ответить:


Обычный год в обычном терапевтическом отделении обычной больницы — тогда главного врача вполне устроит, если доля правильно поставленных диагнозов будет высокой (эта метрика называется accuracy).


Определение очень неприятной болезни, которая жутким клеймом падёт на каждого, кому поставили такой диагноз, — тогда нам важно максимизировать долю действительно больных среди тех, кому мы имели несчастье поставить этот диагноз (эта метрика называется точностью, или precision).


Определение опасной и очень заразной болезни — тогда нам важно не пропустить ни одного заражённого, и метрика будет иметь вид доли правильно определённых носителей (эта метрика называется полнотой, или recall).


Разумеется, это самые простые метрики, и в реальной жизни вам придётся работать с более сложной иерархией метрик; немного подробнее мы поговорим об этом в параграфе про измерение качества моделей.
Вопрос на подумать. Рассмотрим задачу детектирования людей на изображении. Чаще всего под детектированием понимают указание местоположения человека на картинке. Например, модель пытается выделить прямоугольник, в котором, по её мнению, есть человеческая фигура. Подумайте, какие метрики можно было бы использовать в различных ситуациях для измерения качества решения этой задачи. Не забудьте, что метрики — это способ численно измерить то, насколько модель помогает нам в жизни, так что важно думать о том, зачем нам вообще детектировать людей.
Ответ (не открывайте сразу; сначала подумайте сами!)Вот несколько вариантов, которые можно было бы придумать:


Мы разрабатываем программу для проведения видеоконференций и хотим добавить эффект, который облачает участника в рыцарские доспехи, — в этом случае нам важно корректно определять местоположение и в качестве метрики мы могли бы брать среднеквадратичное отклонение координат каких-нибудь опорных точек тела от истинных.


Мы строим систему безопасности вокруг какого-то важного объекта, и нам важно обнаруживать вторжение — в этом случае нам не очень принципиально, насколько точно отмечено местоположение человека в кадре, но все люди должны быть обнаружены. Таким образом, в качестве метрики можно рассмотреть полноту: на какой доле кадров, где действительно были люди, наша модель отметила их наличие.


Мы строим систему, определяющую, не превышает ли количество людей в помещении некоторый порог (например, в рамках борьбы с пандемией), — в этом случае метрикой может быть, скажем, среднеквадратичное отклонение числа детектированных моделью людей от истинного их количества.


Критерии качества не всегда сводятся к метрикам. Бизнес или общество могут накладывать и другие требования, например:


Модель может выдавать предсказания в режиме реального времени. Заметим, что это требование не только к модели, но и к её реализации, а также к тому железу или к тем серверам, на которых она работает.


Модель достаточно компактна, чтобы помещаться на мобильном телефоне или другом устройстве.


Можно объяснить, на основании чего модель сделала то или иное предсказание для конкретного объекта. Это может быть важным в случае, если модель решает что-то важное в жизни человека, например, дадут ли кредит или будет ли согласовано дорогостоящее лечение. Такое требование является частным случаем более общего понятия интерпретируемости модели.


Предсказания модели не дискриминируют какую-либо категорию пользователей. Например, если двум людям с одинаковой и достаточно длинной историей просмотров онлайн-кинотеатр рекомендует разные фильмы только из-за того, что у них разный пол, то это не здорово.


ДанныеДанные
Машинное обучение начинается с данных. Важно, чтобы их было достаточно много и чтобы они были достаточно качественными. Некоторые проекты приходится откладывать на неопределённый срок из-за того, что просто невозможно собрать данные.
Чем сложнее задача, тем больше данных нужно, чтобы её решить. Например, существенные успехи в задачах распознавания изображений были достигнуты лишь с появлением очень больших датасетов (и, стоит добавить, вычислительных мощностей). Вычислительные ресурсы продолжают совершенствовать, но во многих ситуациях размеченных данных (то есть объектов, которым кто-то сопоставил ответ) было бы по-прежнему слишком мало: например, для решения задачи аннотирования изображений (image captioning) потребовалось бы огромное количество пар (изображение, описание). В некоторых случаях можно воспользоваться открытыми датасетами. Сейчас их доступно довольно много и некоторые весьма велики, но чаще всего они создаются для довольно простых задач, например, для задачи классификации изображений. Иногда датасет можно купить. Но для каких-то задач вы нигде не найдёте данных. Скажем, авторам неизвестно больших и качественных корпусов телефонных разговоров с расшифровками – в том числе и по причинам конфиденциальности таких данных.
Бороться с проблемой нехватки данных можно двумя способами.
Первый – использование краудсорсинга, то есть привлечение людей, готовых разметить много данных. Во многих ситуациях (например, когда речь заходит об оценке поисковой выдачи) без дополнительной разметки никак не обойтись. Мы расскажем про краудсорсинг подробнее в соответствующем параграфе. Некоторые проекты, в первую очередь научные и социальные, используют также citizen science – разметку данных волонтёрами без какого-либо вознаграждения, просто за чувство причастности к доброму делу исследования животных Африки или формы галактик.
Второй же способ состоит в использовании неразмеченных данных. К примеру, в задаче аннотирования изображений у нас есть огромное количество никак не связанных друг с другом изображений и текстов. Однако, мы можем использовать их для того, чтобы помочь компьютеру понять, какие слова в принципе могут стоять рядом в предложении. Подходы, связанные с использованием неразмеченных данных для решения задач обучения с учителем, объединяются термином self-supervised learning и очень активно используются сейчас. Важной составляющей является обучение представлений (representation learning) — задача построения компактных векторов небольшой размерности из сложных по структуре данных, например, изображений, звука, текстов, графов, так, чтобы близкие по структуре или семантике данные получали метрически близкие представления. Делать это можно разными способами — например, используя фрагменты моделей, обученных для решения какой-либо другой задачи, или строя модель, предсказывающую скрытую часть объекта по оставшейся его части — например, пропущенное слово в предложении. Этому будет посвящен отдельный параграф нашего учебника.
Но кроме количества данных важно ещё и то, насколько они хороши и удобны для анализа. Давайте разберёмся, что это значит и какие с этим бывают проблемы.
Для работы с объектом модель должна опираться на какие-то его свойства, например, доход человека, цвет левого верхнего пикселя на изображении или частоту встречаемости слова «интеграл» в тексте. Эти свойства обычно называются признаками, а совокупность свойств, которые мы выделили у объекта – его признаковым описанием.
Вот несколько простых и распространённых разновидностей признаков:


Численные – например, рост или доход. Иногда отдельно выделяют вещественные и целочисленные признаки.


Категориальные признаки принимают значения из некоторого дискретного множества. Например, профессия человека или день недели.


Бинарные признаки принимают два значения:  и  или «да» и «нет». С ними можно работать и как с численными, и как с категориальными.


Среди категориальных признаков иногда выделяют ординальные. Они принимают значения из некоторого упорядоченного дискретного множества. Например, класс опасности химического вещества (бывает от 1-го до 4-го) или год обучения для студента являются ординальными.


Приходится иметь дело и с более сложно устроенными признаками. Например, описание ресторана может содержать тексты отзывов или фотографии, а профиль человека в социальной сети – список его друзей. Для многих однородных типов данных, таких как изображения, видео, тексты, звук, графы, разработано большое количество методов извлечения признаков – сейчас в первую очередь нейросетевых. О них вы сможете прочитать в разделах про нейросетевые архитектуры для соответствующих типов данных. Если же попадаются какие-то более сложно устроенные данные, могут потребоваться дополнительные усилия для извлечения из них признаков – этот процесс называют feature engineering.
Удобно бывает записать данные в виде таблицы, строки которой соответствуют объектам, а столбцы – признакам. Например:



Объекты
Возраст
Оценка по ML




Наташа
21
отл


Вася
N/A
удовл


Игорь
47
хор



Данные, представленные в таком виде, называются табличными. Табличные данные – один из самых удобных для анализа форматов. Свои успешные пайплайны работы есть также для уже упомянутых текстов, звука, изображений, видео, графов.
Лучше всего, если все признаки являются численными. Тогда с таблицей можно работать как с объектом линейной алгебры – матрицей объекты-признаки.
Создание информативного признакового описания очень важно для дальнейшего анализа. Но нужно также следить за качеством полученных данных. Вам могут встретиться, например, следующие проблемы:


Пропуски (пропущенные значения). Так, в примере табличных данных выше нам неизвестен возраст Васи. Объекты или признаки, в которых есть пропуски, можно удалять из выборки, но если пропусков довольно много, мы можем потерять таким образом слишком много информации. Кроме того, наличие пропуска само по себе может нести информацию: скажем, это может говорить о систематической проблеме в сборе данных для того или иного сегмента выборки. Некоторые модели, например, решающие деревья, обладают собственными средствами для работы с пропусками, другие же – например, линейные модели или нейросети – требуют, чтобы пропуски были вычищены или заменены на что-то.


Выбросы, то есть объекты, которые резко отличаются от большинства остальных. Например, в датасете с информацией о клиентах банка 140-летний человек, очевидно, будет весьма нетипичным. Выбросы могут возникать из-за ошибок при сборе данных или представлять собой реально существующие аномалии. Обычно выбросы лучше удалять, но в некоторых случаях выбросами могут быть важные объекты (например, очень богатые клиенты банка), и тогда их, возможно, стоит отлавливать и обрабатывать отдельно.


Ошибки разметки. Если, например, вы собираете данные с помощью разметчиков-людей, то вы должны быть готовы к тому, что часть таргетов будет отмечена неправильно. Даже если не думать о том, что не все из разметчиков совершенно честные и старательные, задача может оказаться для них сложной.


Data drift. С течением времени данные могут меняться. Например, может измениться схема сбора данных, и они начнут приходить в формате, который вообще не обрабатывается моделью. Или же может поменяться распределение данных: скажем, если вы делали образовательный сервис для студентов, а к вам стали приходить и более зрелые люди. Data drift – это суровая реальность для любой системы, которая решает не сиюминутную задачу, поэтому нужно уметь мониторить распределение данных и, если нужно, обновлять модель.


Встречаются и другие проблемы. Нередко существенную часть данных приходится выкидывать, потому что в процессе сбора что-нибудь сломалось или потому, что полгода назад в сервисе изменили систему логирования и более старые данные невозможно склеить с более новыми.
Модель и алгоритм обученияМодель и алгоритм обучения
Модель — это некоторый способ описания мира. Например, «Земля плоская» — это модель, и не такая плохая, как вам может показаться. Ей активно пользуются, когда всё происходит в масштабах одного города и кривизной поверхности можно пренебрегать. С другой стороны, если мы попробуем рассчитать кратчайший путь из Парижа в Лос-Анджелес, модель плоской Земли выдаст неадекватный ответ, она войдёт в противоречие с имеющимися данными, и её придётся заменить на «Земля круглая», «Земля имеет форму эллипсоида» и так далее — в той мере, в которой нам важна точность и в какой нам это позволяет (не)совершенство измерительной техники. Так, модель «Земля — это похожая на геоид с шершавостями на месте горных хребтов» очень точная и замечательная, но, возможно, будет избыточно сложной для большинства практических задач и при этом слишком тяжёлой в плане вычислений.
В первых параграфах мы будем рассматривать в основном предсказательные модели, то есть модели вида , которые пытаются уловить зависимость между признаковым описанием  объекта и таргетом . Но порой мы будем иметь дело и с моделями данных: например, «такой-то признак имеет нормальное распределение».
Чаще всего предсказательные модели мы будем брать из некоторого параметрического семейства , где  — параметры, которые мы будем подбирать по данным.
Для примера давайте возьмём задачу предсказания цены квартиры. В качестве класса моделей выберем константные функции  (то есть будем для всех квартир предсказывать одно и то же значение цены). Поскольку значение не зависит от , нам не очень важно, в каком виде получено признаковое описание: это может быть набор совершенно любых сведений о квартире. Не забудем зафиксировать метрику качества — среднее абсолютное отклонение (mean absolute error, она же MAE).
где  — это модель (та самая, ),  — обучающие примеры (данные о квартирах, которые мы смогли достать),  — правильные ответы (то есть цены на известные нам квартиры). Чтобы найти минимум MAE, возьмём производную от выражения
и приравняем её к нулю:
Нам подходят точки , для которых число , строго меньших , равно числу , строго больших . Таким образом, нам подходит медиана набора :
Вопрос на подумать. Давайте теперь в задаче предсказания цены квартиры рассмотрим метрику среднеквадратичное отклонение (MSE):
Каким будет оптимальное значение параметра  для константной модели ?
Ответ (не открывайте сразу; сначала подумайте сами!)Это будет среднее значение:
Прекрасно, значит, в классе константных функций мы можем найти оптимальную модель. Может быть, это можно сделать и в каком-нибудь более интересном классе? Этому вопросу и будет посвящена большая часть нашей книги. Классический курс ML состоит из описания классов моделей и способов работы с ними. Несмотря на то что для решения большинства практических задач на сегодня достаточно знать только два типа моделей — градиентный бустинг на решающих деревьях и нейросетевые модели — мы постараемся рассказать и про другие, чтобы развить у вас глубинное понимание предмета и дать возможность не только использовать лучшие сложившиеся практики, но и, при вашем желании, участвовать в проработке новых идей и поиске новых методов — уже в роли исследователя, а не просто инженера.
Кроме выбора модели важен также выбор алгоритма обучения. Алгоритм обучения — это процедура, которая превращает обучающую выборку в обученную модель. Скажем, в примере выше для константной модели мы в качестве алгоритма обучения использовали поиск нуля градиента. Как мы увидим дальше, градиентные методы используются для обучения многих моделей, и это очень богатый класс методов оптимизации, из которого порой не так просто выбрать лучший.
В качестве примера рассмотрим задачу бинарной классификации точек на плоскости, для которой выберем линейную модель:

Метрикой будет accuracy, то есть доля верных предсказаний.
Теперь нам нужно по обучающей выборке подобрать оптимальную разделяющую прямую . Числа  и  являются настраиваемыми (обучаемыми) параметрами модели, именно их будет по выборке восстанавливать алгоритм обучения. Но есть проблема: метрика accuracy не дифференцируема. Поэтому мы должны подобрать другую дифференцируемую функцию , минимизация которой будет более или менее соответствовать оптимизации вероятности. Такая функция называется функцией потерь, лоссом (от слова loss) или лосс-функцией. О том, как могут выглядеть лосс-функции для бинарной линейной классификации, вы можете почитать в параграфе про линейные модели.
В качестве алгоритма обучения мы можем взять теперь градиентный спуск:
где  — шаг оптимизации — коэффициент, влияющий на скорость и устойчивость алгоритма. Отметим, что разный выбор коэффициента , вообще говоря, даёт разные алгоритмы обучения, которые могут приводить к разным результатам: если  слишком мал, то спуск может не дойти до оптимума, а если слишком велик, то алгоритм будет «скакать» вокруг оптимума и никогда туда не попадёт. Мы видим, что важен не только выбор модели, но и выбор алгоритма обучения.
Число  является гиперпараметром алгоритма, то есть задаётся до начала обучения — но его тоже можно подбирать по данным. Более подробно о подборе гиперпараметров вы можете узнать в соответствующем параграфе.
Выбор модели, переобучениеВыбор модели, переобучение
Может показаться, что мы вас обманули, когда пугали сложностями: очевидно, что для любой задачи машинного обучения можно построить идеальную модель, надо всего лишь запомнить всю обучающую выборку с ответами. Такая модель может достичь идеального качества по любой метрике, но радости от неё довольно мало, ведь мы хотим, чтобы она выявила какие-то закономерности в данных и помогла нам с ответами там, где мы их не знаем. Важно понимать, какая у построенной модели обобщающая способность, то есть насколько она способна выучить общие закономерности, присущие не только обучающей выборке, и давать адекватные предсказания на новых данных. Для того чтобы предохранить себя от конфуза, поступают обычно так: делят выборку с данными на две части: обучающую выборку и тестовую выборку (train и test). Обучающую выборку используют для собственно обучения модели, а метрики считают на тестовой.
Такой подход позволяет отделить модели, которые просто удачно подстроились к обучающим данным, от моделей, в которых произошла генерализация (generalization), то есть от таких, которые на самом деле кое-что поняли о том, как устроены данные, и могут выдавать полезные предсказания для объектов, которых не видели.
Например, рассмотрим три модели регрессионной зависимости, построенные на одном и том же синтетическом датасете с одним-единственным признаком. Жёлтым нарисованы точки обучающей выборки. Здесь мы представим, что есть «истинная» закономерность (пунктир), которая искажена шумом (погрешности измерения, влияние других факторов и т.д.).

Левая, линейная модель недостаточно хороша: она сделала, что могла, но плохо приближает зависимость, особенно при маленьких и при больших . Правая «запомнила» всю обучающую выборку (и в самом деле, чтобы вычислить значение этой функции, нам надо знать координаты всех исходных точек) вместо того, чтобы моделировать исходную зависимость. Наконец, центральная, хоть и не проходит через точки обучающей выборки, довольно неплохо моделирует истинную зависимость.
Алгоритм, избыточно подстроившийся под данные, называют переобученным.
С увеличением сложности модели ошибка на обучающей выборке падает. Во многих задачах очень сложная модель будет работать примерно так же, как модель, «просто запомнившая всю обучающую выборку», но с генерализацией всё будет плохо: ведь выученные закономерности будут слишком специфическими, подогнанными под то, что происходит на обучающей выборке. Мы видим это на трёх графиках сверху: линейная функция очень проста, но и закономерность приближает лишь очень грубо; на правом же графике мы видим довольно хитрую функцию, которая точно подобрана под значения из обучающей выборки, но явно слишком эксцентрична, чтобы соответствовать какой-то природной зависимости. Оптимальная же генерализация достигается на модели не слишком сложной и не слишком простой.
В качестве иллюстрации для того же самого датасета рассмотрим модели вида
Ясно, что с ростом  сложность модели растёт, и она достигает всё лучшего качества на обучающей выборке. А что, если у нас есть ещё тестовая выборка? Каким будет качество на ней? Вот так могут выглядеть графики среднеквадратичного отклонения (MSE) для обучающей и тестовой выборок:

Мы видим здесь типичную для классических моделей картину: MSE на обучающей выборке падает (может быть, даже до нуля), а на тестовой сперва падает, а затем начинает снова расти.
Замечание. Для моделей глубинного обучения всё немного интереснее: в некоторых ситуациях есть грань, за которой метрика на тестовой выборке снова начинает падать. Но об этом в своё время. Пока давайте запомним, что слишком сложная модель — это вредно, а переобучение — боль.
Точный способ выбрать алгоритм оптимальной сложности по данной задаче нам пока неизвестен, хотя какую-то теоретическую базу имеющимся философским наблюдениям мы дадим в главе про теорию обучения; при этом есть хорошо продуманная методология сравнения разных моделей и выбора среди них оптимальной — об этом мы обязательно расскажем вам в следующих главах. А пока дадим самый простой и неизменно ценный совет: не забывайте считать метрики на тестовой выборке и никогда не смешивайте её с обучающей!
Вопрос на подумать. Обсуждая переобучение, мы упоминали про сложность модели, но не сказали, что это такое. Как бы вы её определили? Как описать / сравнить сложность моделей для двух приведённых ниже задач? Почему, кстати, мы решили, что средняя модель ОК, а правая переобученная?


Ответ (не открывайте сразу; сначала подумайте сами!)Сложность модели можно очень грубо охарактеризовать числом настраиваемых параметров модели, то есть тех, которые мы можем определить по данным в процессе обучения. Это не имеет никакого математического смысла, и о каких-то более серьёзных оценках мы поговорим в главе про теорию машинного обучения, но никто не бросит в вас камень, если вы скажете, что модель с 10 тысячами параметров сложнее, чем модель с 1000 параметров.
В первой задаче левая модель — это, судя по всему, линейная функция, у неё два параметра, вторая — наверное, квадратичная с тремя параметрами, а правая — многочлен какой-то высокой степени (на самом деле 11-й), у неё параметров намного больше. Центральная модель явно лучше, чем левая, справляется с тем, чтобы приблизить истинную закономерность; правая тоже вроде неплохо справляется с тем, чтобы приблизить её для обучающих данных, но вот два резких провала и крутое пике слева никак не объясняются имеющимися данными, и на двух тестовых точках в районе  модель отчаянно врёт — так что есть причины считать, что она переобучилась.
Со второй задачей ситуация во многом похожая. Центральная модель явно лучше разделяет жёлтые и серые точки. На правой же картинке мы видим довольно неестественные выпячивания жёлтой и серой областей: например, к серой точке в центре картинки (которая наверняка была выбросом) протянулось серое «щупальце», захватившее и несколько тестовых (и даже обучающих) точек другого класса. В целом можно поспорить о том, плох ли правый классификатор, но он явно рисует слишком сложные границы, чтобы можно было поверить, что они отражают что-то из реальной жизни.
После обученияПосле обучения
В момент, когда подобраны все обучаемые параметры и гиперпараметры модели, работа специалиста по машинному обучению не заканчивается.
Во-первых, модель чаще всего создают для того, чтобы она работала в некотором продакшене. И чтобы она там оказалась, нужно эффективно её закодить, научить работать параллельно и подружить с используемыми вами фреймворками. Процесс выкатки в продакшен называется словом деплой или деплоймент (от deploy). После деплоя можно посчитать онлайн-метрики. Также имеет смысл провести АБ-тестирование, то есть сравнение с предыдущей версией модели на случайно выбранных подмножествах пользователей или сессий. Более подробно об АБ-тестировании вы сможете почитать в соответствующем параграфе. Если новая модель работает не очень здорово, должна быть возможность откатиться к старой.
После деплоймента модели важно продолжать дообучать или переобучать её при поступлении новых данных, а также мониторить качество. Мы уже обсуждали data drift, но бывает также и concept drift — изменение зависимости между признаками и таргетом. Например, если вы делаете музыкальные рекомендации, вам нужно будет учитывать и появление новых треков, и изменение вкусов аудитории. О мониторинге качества моделей мы подробнее расскажем в соответствующем параграфе.

Теперь предлагаем вам потренировать изученный материал на практике. Скачайте ноутбук с лабораторной работой. В нём вы найдете описания заданий и дополнительные материалы. Задания из лабораторной прикреплены к этому параграфу в виде задач в системе Яндекс Контест. Чтобы проверить себя, отправляйте решения по соответствующим задачам в систему. Успехов в практике!

