Лекция
/guillemotleft.cyrЗаконы распределения случайных величин/guillemotright.cyr
Санкт-Петербург
2019
Содержание
1 Генеральная совокупность и выборка 2
1.1 Понятие генеральной совокупности и выборки . . . . . . . . . . 2
1.2 Эмпирическое распределение . . . . . . . . . . . . . . . . . . . . 4
2 Основные законы распределения дискретных случайных ве-
личин 6
2.1 Распределение Бернулли . . . . . . . . . . . . . . . . . . . . . . . 6
2.2 Биномиальное распределение . . . . . . . . . . . . . . . . . . . . 7
2.3 Распределение Пуассона . . . . . . . . . . . . . . . . . . . . . . . 10
3 Функция распределения случайной величины 11
3.1 Определение и свойства функции распределения . . . . . . . . . 11
3.2 Плотность распределения непрерывной случайной величины . . 14
4 Числовые характеристики непрерывных случайных величин 16
4.1 Математическое ожидание . . . . . . . . . . . . . . . . . . . . . 16
4.2 Дисперсия непрерывной случайной величины . . . . . . . . . . . 17
5 Основные законы распределения непрерывных случайных
величин 18
5.1 Равномерное распределение . . . . . . . . . . . . . . . . . . . . . 18
5.2 Показательное распределение . . . . . . . . . . . . . . . . . . . . 20
5.3 Нормальное распределение . . . . . . . . . . . . . . . . . . . . . 21
6 Совместное распределение двух случайных величин 24
6.1 Совместное распределение двух дискретных случайных величин 25
6.2 Ковариация. Коэффициент корреляции . . . . . . . . . . . . . . 28
1
1 Генеральная совокупность и выборка
В предыдущей лекции мы рассмотрели такие первостепенные понятия
теории вероятностей, как случайный эксперимент, случайное событие, опре-
делили понятие вероятности события. Кроме того, мы построили несколько
вероятностных моделей, среди которых: классическая вероятностная схема,
схема с неравновозможными исходами, схема с условной вероятностью, гео-
метрическая вероятность и другие.
1.1 Понятие генеральной совокупности и выбор-
ки
В завершении лекции мы познакомились с таким, на первый взгляд, тео-
ретическим понятием, как случайная величина, узнали, как можно найти ее
математическоеожиданиеидисперсию,атакжезачтоотвечаютэтипарамет-
ры. Что же, можно считать, что нам повезло, если мы знаем распределение
случайной величины. Почему повезло? Потому что в жизни, оказывается,
все обстоит несколько иначе: это распределение (или характеристики этого
распределения) как раз-таки и хочется найти. Смотрите.
Обычно исследователь имеет дело с набором данных, который был со-
бран в результате некоторого случайного эксперимента (или процесса): ко-
личество литров бензина, истраченного каждый день в течение месяца, ко-
личество клиентов автомойки за день в течение недели, рост первых100
призывников в военкомате с начала призывной кампании, и так далее. Все
эти данные являются результатом некоторого наблюдения.
При этом крайне важно задаться вопросом: а есть ли какая-то законо-
мерность в этих данных? Скажем, если сравнить рост первых100 призыв-
ников этого года и прошлого, понятно, что точно таких же данных мы не
получим, но будет ли картина похожей? А что изменится, и изменится ли,
если собрать больше наблюдений, скажем,1000 или10000? Очевидно, что во
всех случаях будет наблюдаться относительно небольшое число людей, обла-
дающих очень высоким и очень низким ростом, а большинство наблюдений
будут находиться в некотором /guillemotleft.cyrусловно среднем/guillemotright.cyr диапазоне.
Оказывается, что при решении прикладных задач, при наблюдении тех
или иных явлений, многие закономерности носят вероятностных характер. А
что означает последняя фраза?
Она означает, что изучаемая нами закономерность (явление) случайна
в своих проявлениях и, тем самым, описывается случайной величинойξ, ко-
торая, в свою очередь, имеет вероятностное распределение. Для случая при-
зывников, вероятность иметь рост, мало отличающийся от среднего, высока,
а чем дальше рост от среднего, тем вероятность обладать таким ростом мень-
ше.
2
Зная же распределениеξ, можно вычислять такие полезные параметры,
как: математическое ожиданиеEξ, дисперсиюDξ = E (ξ−Eξ)2, вероятности
попадания в те или иные множества и многое-многое другое. Иными сло-
вами, зная распределение интересующей нас случайной величины, мы сразу
знаем очень много, а также можем получать сразу достаточно большой объем
полезной информации.
Итак, пусть у нас имеетсяn проявлений некоторой вероятностной зако-
номерности. Иными словами, мы наблюдаемnзначений некоторой случайной
величиныξ, называемой еще генеральной совокупностью, имеющей какое-то
(неизвестное нам) распределение. Тогда перед нами обычный числовойn-
мерный векторX = (x1,x2,...,x n) – это выборка после эксперимента. Итак,
Определение 1.1.1Пусть ξ – рассматриваемая нами случайная величи-
на. Выборкой (после эксперимента)X = (x1,x2,...,x n) ∈Rn называетсяn
независимых реализаций случайной величиныξ. Последнюю часто называ-
ют генеральной совокупностью.
Например, пустьξ – это рост случайно взятого человека, тогда
X = (175,182,168,155,192)
это выборка объема5 из генеральной совокупностиξ. Хорошо, допустим те-
перь мы хотим вычислить среднее, а точнее предположить, чему равно ма-
тематическое ожиданиеξ. Как бы это сделать? Вполне логично посчитать
среднее арифметическое, называемое выборочным средним:
X = 175 + 182 + 168 + 155 + 192
5 = 174.4.
Но является ли полученное значение математическим ожиданием гене-
ральной совокупностиξ? Интуитивно понятно, что не является, так как если
выбрать других5 человек, то и среднее значение, скорее всего, поменяет-
ся. Тогда, видимо, правильнее сказать, что выборочное среднееX является
оценкой математического ожидания генеральной совокупностиξ.
Важно еще понимать и вот какой момент, называемый неоднородностью.
Придя в детский сад и померив людей в нем, получим одно число (вероятно,
сравнительно небольшое, даже рост воспитателей и нянечек не поможет),
а измерив рост членов баскетбольной команды – разительно отличающееся.
Дело в том, что выборки-то берутся из разных распределений! Поэтому мы
всегда должны понимать, какое именно распределение мы изучаем по данной
выборке. А то получится вроде ситуации с опросом в интернете с вопросом:
/guillemotleft.cyrПользуетесь ли вы интернетом/guillemotright.cyr?
3
1.2 Эмпирическое распределение
С каждой конкретной выборкой, полученной в результате эксперимента,
то есть с выборкойX = ( x1,x2,...,x n), разумно связать новую случайную
величинуξ∗. Такую, которая каждое значение выборкиxi принимает с веро-
ятностью1
n – у нас же нет любимчиков в выборке. В итоге, можно написать
следующую таблицу
ξ∗ x1 x2 ... xn
˜P 1
n
1
n ... 1
n
.
Кстати, как легко видеть, случайная величина, а точнее ее распределение,
конечно, зависит отn, от объема выборки, но мы не будем наделять ее до-
полнительным индексом.
Так как случайная величинаξ∗не является истинной случайной величи-
нойξ, то вероятность, с которой она принимает те или иные значения, будем
обозначать˜P. Например, имея в результате эксперимента, показывающем ко-
личество голов, забитых в пяти матчах, выборку
X = (1,2,1,3,1)
объема5, соответсвующее распределение новой случайной величиныξ∗запи-
сывается, как
ξ∗ 1 2 3
˜P 3
5
1
5
1
5
.
Оказывается, чтосростомобъема выборкиnраспределениеξ∗вселучше
и лучше приближает истинное (нам неизвестное) распределение генеральной
совокупностиξ.
Наверное, теперь ясна основная идея: может быть, в качестве оцен-
ки некоторой характеристики генеральной совокупностиξ, можно использо-
вать соответствующую характеристикуξ∗, раз распределение последней так
неплохо приближает истинное? Попробуем.
Тогда в качестве оценкиˆEξ математического ожиданияξ логично взять
соответствующее математическое ожидание˜Eξ∗, то есть, по сути, выборочное
среднее:
ˆEξ = ˜Eξ∗= X = 1
n
n∑
i=1
xi.
В качестве оценкиˆDξ дисперсии генеральной совокупностиξ логично взять
дисперсию случайной величиныξ∗, называемую выборочной дисперсией:
ˆDξ = ˜Dξ∗= ˜E(ξ∗−˜Eξ∗)2 = S2 = 1
n
n∑
i=1
(
xi −X
)2
.
4
Замечание 1.2.1В предположении, что с ростом объема выборкиn рас-
пределениеξ∗ все лучше и лучше приближает истинное распределение ге-
неральной совокупностиξ, есть некоторая неточность, которая будет
устранена в следующих лекциях.
Пример 1.2.1Найдем выборочное среднее и выборочную дисперсию для ра-
нее рассмотренной выборки
X = (1,2,1,3,1)
и построенной по ней эмпирической случайной величиныξ∗, распределение
которой задается таблицей:
ξ∗ 1 2 3
˜P 3
5
1
5
1
5
.
Выборочное среднееX находится, как
X = 1 + 2 + 1 + 3 + 1
5 = 8
5 = 1.6 = ˜Eξ∗.
Что это означает? Это означает, что, согласно выборке, стоит ожидать
в среднем1 −2 гола за матч.
Выборочная дисперсия находится, как:
ˆDξ = (1 −1.6)2 + (2 −1.6)2 + (1 −1.6)2 + (3 −1.6)2 + (1 −1.6)2
5 =
= 3 ·(−0.6)2 + 0.42 + 2.42
5 = 0.64 = ˜Dξ∗,
а корень из нее, то есть оценкаˆσ, равен0.8.
Какой можно сделать вывод? Такой, что согласно выборке, наиболее
вероятным стоит ожидать от1.6 −0.8 = 0 .8 до1.6 + 0.8 = 2 .4 голов,
то есть, в среднем,1 −3 гола. Это не значит, что команда не может
забить, скажем,6 голов, или не забить голов вовсе. Просто эти события
имею маленькую вероятность.
Замечание 1.2.2Напомним, что полученные значения являются оценка-
ми истинных значений математического ожидания и дисперсии некоторой
генеральной совокупности (случайной величины)ξ, однако неизбежно воз-
никает вопрос, а насколько хороши эти оценки, и существуют ли какие-то
еще? Мы ответим на этот вопрос в одной из следующих лекций.
5
2 Основные законы распределения дискретных
случайных величин
Мы уже неоднократно говорили, что выборка – это некоторое количе-
ство независимых реализаций генеральной совокупностиξ, то есть какой-то
конечный набор значений, которые приняла эта случайная величина в ре-
зультате эксперимента. Очевидно, что закономерности, проявляющиеся в ре-
зультатах экспериментов, могут описываться случайными величинами с раз-
личными распределениями. Оказывается, множество различных явлений, с
которыми мы сталкиваемся ежедневно, описываются случайными величина-
ми, имеющими достаточно ограниченный набор распределений. Рассмотрим
самые часто используемые.
2.1 Распределение Бернулли
В этом пункте поговорим про так называемое распределение Бернулли.
Начнем с такого примера, навеянного собранной статистикой.
Пример 2.1.1Ученые подсчитали, что на каждые100 девочек рождается
от 104 до107 мальчиков (данные колеблются в зависимости от страны).
Для удобства будем считать, что рождается106 мальчиков. Можно пред-
положить, основываясь на частоте, что вероятность рождения мальчика
равна
P = 106
(100 + 106) ≈0.52.
Пусть в некоторой семье уже есть один ребенок, и это девочка. Тогда, если
родится девочка, родителям не придется тратиться на одежду и игрушки,
так как ими явно поделится старшая сестра. Если же родится мальчик,
то дополнительных трат не избежать. Тогда распределение случайной ве-
личиныξ, показывающей наличие или отсутствие трат на нового ребенка,
можно задать таблицей
ξ 0 1
P 0.52 0.48 .
Оказывается, примеров такого вида существует достаточно большое ко-
личество. Под описываемую нами схему подходит любой эксперимент, кото-
рой завершается одним из двух возможных исходов: (условно) успехом, и ему
ставится в соответствие1, или неудачей, которой ставится в соответствие0:
попал в створ ворот или промахнулся, дали кредит или не дали, сдал экзамен
или не сдал, голоден или нет и так далее.
6
Определение 2.1.1Говорят, что случайная величинаξ имеет распреде-
ление Бернулли с параметромp (пишут ξ ∼ Bp), если ее распределение
задается таблицей
ξ 0 1
P 1 −p p ,
гдеp∈(0,1).
Замечание 2.1.1Величину(1 −p) часто обозначают через (как)q. Кро-
ме того, вероятностьp условно называют /guillemotleft.cyrвероятностью успеха/guillemotright.cyr, аq –
/guillemotleft.cyrвероятностью неудачи/guillemotright.cyr.
Найдем математическое ожидание случайной величиныξ, имеющей рас-
пределение Бернулли. По определению математического ожидания,
Eξ = 0 ·(1 −p) + 1·p= p.
Для нахождения дисперсии, воспользуемся формулой:
Dξ = Eξ2 −(Eξ)2.
Еслиξ ∼Bp, то распределение случайной величиныξ2 задается таблицей
ξ2 0 1
P 1 −p p .
Тогда,
Eξ2 = 0 ·(1 −p) + 1·p= p,
а значит
Dξ = Eξ2 −(Eξ)2 = p−p2 = p(1 −p) = pq.
В итоге, еслиξ ∼Bp, то
Eξ = p, Dξ = p(1 −p) = pq.
2.2 Биномиальное распределение
Рассмотрим закон распределения случайной величины, имеющей непо-
средственное отношение к последовательностям испытаний по схеме Бернул-
ли.
Пусть случайная величинаξ показывает число успехов в серии изn ис-
пытаний по схеме Бернулли с вероятностью успехаpв каждом испытании.
7
Определение 2.2.1Говорят, что случайная величинаξ имеет биноми-
альное распределение, и пишутξ ∼Bin(n,p), p ∈(0,1), n ∈N, если она
принимает значения0,1,2,...,n с вероятностями
P(ξ = k) = Ck
npk(1 −p)n−k, k ∈{0,1,...,n }.
Таблица распределения случайной величины, имеющей биномиальное распре-
деление, имеет вид
ξ 0 1 ... n−1 n
P (1 −p)n C1
np(1 −p)n−1 ... Cn−1
n pn−1(1 −p) pn
Замечание 2.2.1Заметим, что для того, чтобы приведенная таблица за-
давала распределение случайной величиныξ, необходимо, чтобы
n∑
m=0
Cm
n pmqn−m = 1,
то есть чтобы сумма чисел, стоящих во второй строке таблицы, давала
единицу. Последнее следует из формулы бинома Ньютона
(a+ b)n =
n∑
m=0
Cm
n ambn−m,
если положитьa= p, b= 1 −p (в этом случае(a+ b)n = (p+ 1−p)n = 1).
Пример 2.2.1Студент выполняет тест, содержащий8 вопросов с че-
тырьмя вариантами ответа каждый, из которых только один верный. По-
строим ожидаемое распределение количества правильно решенных заданий,
если ответы выбираются наугад.
Ясно, что рассматриваемая случайная величина имеет биномиальное
распределениеBin(8,0.25). Таблица распределения (значения второй строки
которой округлены так, чтобы и правда получилось распределение, то есть
чтобы сумма чисел, стоящих в этой строке, равнялась единице), имеет
следующий вид
ξ 0 1 2 3 4 5 6 7 8
P 0.1 0.267 0.311 0.208 0.087 0.023 0.004 0 0
Вероятности соответствующих значений случайной величины вычисля-
ются по формулам
P (ξ = k) = Ck
8 ·0.25k ·0.758−k, k ∈{0,1,2,..., 8}.
8
Ответим на вопрос: какова вероятность сдать тест, если для этого
необходимо ответить не менее, чем на5 вопросов. Ясно, что
P (ξ ≥5) = P(ξ = 5) + P(ξ = 6) + P(ξ = 7) + P(ξ = 8) =
= 0.023 + 0.004 = 0.027.
Давайте теперь вычислим математическое ожидание случайной величи-
ны ξ, имеющей биномиальное распределение. А для этого рассмотрим слу-
чайные величины:
ξi =
{
1, если вi-том испытании произошел успех
0, если вi-том испытании произошла неудача,
гдеi∈{1,2,...,n }
В наших условиях все эти случайные величиныξi имеют распределение
БернуллиBp с одинаковым параметромp, причем
ξ = ξ1 + ξ2 + ... + ξn,
так как число слагаемых, равных единице, равно количеству успехов вn
испытаниях. Тогда, по свойству математического ожидания,
Eξ = E (ξ1 + ξ2 + ...+ ξn) = Eξ1 + Eξ2 + ...+ Eξn = p+ p+ ...+ p= np.
Для нахождения дисперсии воспользуемся тем, что испытания в схеме
Бернулли независимы, а значит и случайные величиныξi будут независимы,
тогда, по свойствам дисперсии,
Dξ = D
( n∑
i=1
ξi
)
=
n∑
i=1
Dξi =
n∑
i=1
pq= npq.
Пример 2.2.2Продолжим пример про студента, выполняющего тест.
Найдем математическое ожидание и дисперсию. Напомним, что число во-
просов (испытаний)n= 8, вероятность успеха в каждом –p= 0.25, тогда
Eξ = np= 8 ·0.25 = 2,
Dξ = npq= 8 ·0.25 ·0.75 = 1.5.
σ=
√
Dξ =
√
1.5 ≈1.22
Иными словами, в среднем из8 вопросов студент верно ответит на2. При
этом, в среднем, число верных ответов будет колебаться от0.78 до3.22.
9
2.3 Распределение Пуассона
Вэтомпунктесначалавведемформальноеопределение,апотомпоясним
область применения.
Определение 2.3.1Говорят, что случайная величина имеет распределе-
ние Пуассона, и пишутξ ∼ Πλ, λ > 0, если она принимает значения
0,1,2,3,...,n,... с вероятностями
P(ξ = k) = λk
k! e−λ, k ∈{0,1,2,3,...,n,... }.
Проверим, что введенное нами /guillemotleft.cyrраспределение/guillemotright.cyr действительно является рас-
пределением, а именно покажем, что
∞∑
k=0
P(ξ = k) = 1.
Имеем,
∞∑
k=0
P(ξ = k) =
∞∑
k=0
λk
k! e−λ = e−λ
∞∑
k=0
λk
k! = e−λ ·eλ = 1,
так как получившийся ряд – не что иное, как ряд Маклорена для экспоненты
∞∑
k=0
λk
k! = eλ.
Замечание 2.3.1Распределение Пуассона хорошо описывает так называ-
емые /guillemotleft.cyrредкие явления/guillemotright.cyr, когда при достаточно большом числе испытаний,
которое заранее неизвестно, событие наступает редко, то есть имеет ма-
ленькую вероятность. Например, число ДТП в некотором городе относи-
тельно всех поездок всех водителей этого города за год, число рекламных
сообщений, пришедших на телефон, за месяц, относительно всех сообще-
ний, пришедших за этот месяц, число забитых мячей на чемпионате мира,
относительно всех ударов по мячу.
Можно показать, что математическое ожидание и дисперсия распреде-
ления Пуассона одинаковы и равныλ, то есть
Eξ = Dξ = λ.
Доказательство этого утверждения в рамках данного курса мы рассматри-
вать не будем.
10
Пример 2.3.1Менеджер телекоммуникационной компании решил рассчи-
тать вероятность того, что в некотором небольшом городе в течение
пяти минут поступят0,1,2,... звонков. Он выбрал случайные интервалы
в5 минут и подсчитал число вызовов в каждом их из них. Оказалось, что
в среднем поступало4.3 звонка. Давайте вычислим вероятность того, что
в течение пяти минут поступит ровно7 звонков:
P(ξ = 7) = 4.37
7! ·e−4.3 ≈0.073.
Вероятность такого события мала, а значит менеджер может пока не
заботиться о расширении компании, или покупке нового оборудования.
3 Функция распределения случайной величины
3.1 Определение и свойства функции распреде-
ления
Как мы уже неоднократно сказали, распределение дискретной случай-
ной величины может быть задано таблицей, то есть перечислением значений
случайной величины и вероятностей, с которыми эти значения принимаются.
Однако, случайные величины, которые не являются дискретными, принци-
пиально невозможно задать аналогичным образом. Существует общий способ
задания распределения любой случайной величины. Этот способ опирается
на задание так называемой функции распределения.
Определение 3.1.1Функцией распределения случайной величиныξ назы-
вается функция
Fξ(x) = P(ξ <x), x ∈R.
Итак, функция распределения случайной величиныξ в точкеx показывает
вероятность события, чтоξ ∈(−∞,x).
Функция распределенияFξ(x) случайной величиныξ обладает следую-
щими свойствами, которые интуитивно совершенно понятны:
1. Fξ(x) ∈[0,1]
2. Fξ(x) не убывает, то есть
еслиx1 <x2, то Fξ(x1) ≤Fξ(x2).
3. lim
x→−∞
Fξ(x) = 0.
11
4. lim
x→+∞
Fξ(x) = 1.
Первое свойство следует из того, что функция распределения – это неко-
торая вероятность, и, так как вероятность находится в диапазоне от0 до1,
то и значения функции распределения лежат там же. Второе свойство – это
следствие монотонности вероятности, ведь приx1 < x2 событие{ξ < x1}
влечет событие{ξ < x2}. Последние два свойства опираются на то, чтоξ
– это случайная величина, то есть функция, а значит ее значения лежат в
множествеR = ( −∞,+∞). Так, третье свойство, грубо говоря, означает,
что мы вычисляем вероятность события{ξ <−∞}, что, конечно, событие
невозможное, и его вероятность равна нулю. В последнем свойстве, наоборот,
мы вычисляем вероятность события{ξ <+∞}, что является достоверным
событием, а значит и его вероятность равна1.
Чем же нам помогает функция распределения?
Замечание 3.1.1Оказывается, что знание функции распределения позво-
ляет найти вероятность попадания значений случайной величины в задан-
ный промежуток, а именно:
P(a≤ξ <b) = Fξ(b) −Fξ(a),
P(a<ξ ≤b) = Fξ(b+ 0) −Fξ(a+ 0),
P(a≤ξ ≤b) = Fξ(b+ 0) −Fξ(a),
P(a<ξ <b ) = Fξ(b) −Fξ(a+ 0),
где в формулахFξ(x+ 0) означает предел функцииFξ в точкеx справа. В
качествеa,b могут выступать и бесконечности (соответствующих зна-
ков).
Рассмотрим пример, в котором построим функцию распределения и вычис-
лим с ее помощью интересующую нас вероятность.
Пример 3.1.1В лотерее на каждые100 билетов в среднем приходится15
выигрышных. Данные о количестве билетов и размере выигрышей (в руб-
лях) приведены в таблице
размер выигрыша 0 100 500 2000
количество билетов85 10 4 1 .
Пусть ξ – случайная величина, показывающая размер выигрыша на один
случайно выбранный билет. Тогда ее распределение задается следующей
таблицей
ξ 0 100 500 2000
P 0.85 0.1 0.04 0.01 .
12
Построим функцию распределенияFξ(x) = P (ξ <x) данной случайной
величины. Ясно, что ключевыми точками построения являются точки-
значения случайной величины:0, 100, 500, 2000. Тогда
Fξ(x) =



0, x ≤0
0.85, 0 <x ≤100
0.95, 100 <x ≤500
0.99, 500 <x ≤2000
1, x> 2000
.
График функции распределения представлен на рисунке 1. Как получилась
Рис. 1: Функция распределенияFξ(t)
такая функция распределения? Ну смотрите, что происходит приx ≤0?
Нас интересует вероятность события, что случайная величина меньше,
чемx. Но наша случайная величинаξ не принимает отрицательных зна-
чений, а значит вероятность события{ξ < x, x≤0}равна0, тогда и
значение функции распределения равно0.
Теперь рассмотрим промежуток0 <x ≤100. При каждомxиз такого
промежутка событие{ξ <x}состоит ровно из одного значения случайной
величины, нулевого, его вероятность равна0.85, что и записано в функции
распределения.
В заключении ответим на вопрос: какова вероятность события, что
13
случайный билет принесет выигрыш более100 рублей?
P (ξ >100) =
∑
i: ai>100
P(ξ = ai)
Так как значения случайной величины, превышающие100 – это500 и 2000,
то последняя сумма состоит из двух слагаемых:
P (ξ >100) = P (ξ = 500) + P (ξ = 2000) = 0.04 + 0.01 = 0.05.
Значит, искомая вероятность равна0.05.
Используя функцию распределения, ту же самую вероятность можно
вычислить, как
P(ξ >100) = P(ξ ∈(100,+∞)) = Fξ(+∞) −Fξ(100 + 0) = 1−0.95 = 0.05.
3.2 Плотность распределения непрерывной слу-
чайной величины
До сих пор мы рассматривали исключительно дискретные случайные ве-
личины, и у слушателя может возникнуть неверное представление о том, что
других распределений в природе нет. На самом деле, дискретное распределе-
ние – это одна из двух крайностей в распределениях. Другая крайность – это
так называемое непрерывное распределение, которое мы и рассмотрим.
Определение 3.2.1Говорят, что случайная величинаξ имеет непре-
рывное распределение, если существует такая неотрицательная функция
fξ(x) : R →R, что
Fξ(x) = P(ξ <x) =
x∫
−∞
fξ(t)dt.
Определение 3.2.2Функцияfξ(x) называется плотностью вероятности
случайной величиныξ.
Проведем аналогию со случаем дискретной случайной величины. Ясно, что
непрерывная величина получена в некотором смысле /guillemotleft.cyrпредельным перехо-
дом/guillemotright.cyr от дискретной, что особенно хорошо видно из рассмотрения пары соот-
ношений (сумма меняется на интеграл):
Fξ(x) = P(ξ <x) =
x∫
−∞
fξ(t)dt ↔ Fξ(x) = P(ξ <x) =
∑
i: ai<x
P(ξ = ai).
14
Кроме того, так какlim
x→+∞
Fξ(x) = 1 , то
+∞∫
−∞
fξ(t)dt = 1. В дискретном слу-
чае было равенство вида∑
i
P(ξ = ai) = 1 . Тем самым, мы получаем пару
/guillemotleft.cyrсвязанных/guillemotright.cyr соотношений
+∞∫
−∞
fξ(t)dt= 1 ↔
∑
i
P(ξ = ai) = 1.
Геометрический смысл плотности заключается в следующем: пустьfξ – плот-
ность некоторой случайной величиныξ(рисунок 2). Вся площадь под графи-
ком, как мы уже отметили выше, равна
+∞∫
−∞
fξ(t)dt= 1. Так как геометриче-
ский смысл определенного интеграла на промежуткуI от неотрицательной
функции – это площадь под графиком этой функции над промежуткомI, то
ясно, что
P(a≤ξ <b) =
b∫
a
fξ(t)dt= S1,
P(ξ <c) =
c∫
−∞
fξ(t)dt= S2.
Итак, у непрерывной случайной величины вероятность попасть в некоторое
множествоA ⊂R – это площадь под графиком плотности над множеством
A.
Рис. 2: Геометрический смысл плотности распределения
15
4 Числовые характеристики непрерывных случайных
величин
Числовые характеристики дискретных случайных величин мы уже рас-
сматривали. Введём теперь эти характеристики для непрерывных случайных
величин.
4.1 Математическое ожидание
Определение 4.1.1Пусть случайная величинаξ имеет непрерывное рас-
пределение с плотностьюfξ(x). Математическим ожиданием случайной
величиныξ называется число
Eξ =
+∞∫
−∞
xfξ(x)dx
при условии, что написанный интеграл сходится абсолютно (то есть ес-
ли существуетE|ξ|). Иначе говорят, что математического ожидания не
существует.
Пример 4.1.1Пусть плотность случайной величиныξ имеет вид:
fξ(t) =



0, t ≤0
t
2 , 0 <t ≤2
0, t> 2
.
Вычислим математическое ожидание, используя определение:
Eξ =
+∞∫
−∞
t·fξ(t)dt=
0∫
−∞
t·0dt+
2∫
0
1
2t2dt+
+∞∫
2
t·0dt= 1
2 ·23
3 = 4
3.
Оказывается, для математического ожидания справедливо свойство, ко-
торое будет очень полезно в дальнейшем.
Пустьg(ξ) – случайная величина, построенная по случайной величинеξ.
Тогда еслиξ имеет непрерывное распределение, а математическое ожидание
g(ξ) определено, то
E(g(ξ)) =
+∞∫
−∞
g(x)fξ(x)dx.
16
4.2 Дисперсия непрерывной случайной величи-
ны
Дисперсия любой случайной величины (в том числе непрерывной), со-
гласно определению, равна
Dξ = E(ξ−Eξ)2,
если существуетEξ2.Как уже ранее отмечалось, зачастую дисперсию удобнее
вычислять, используя формулу
Dξ = Eξ2 −(Eξ)2 .
Это соотношение немедленно следует из свойств математического ожидания,
а именно
E (ξ−Eξ)2 = E
(
ξ2 −2ξEξ+ (Eξ)2
)
= Eξ2 −2 (Eξ)2 + (Eξ)2 = Eξ2 −(Eξ)2 ,
так как математическое ожидание линейно,Eξ – константа, константа вы-
носится за знак математического ожидания, а значитE (2ξEξ) = 2 EξEξ =
2 (Eξ)2 и E (Eξ)2 = (Eξ)2 .
С учетом сделанного выше утверждения о вычислении математическо-
го ожидания функции от случайной величины, дисперсия непрерывной слу-
чайной величины (если она существует) будет выражаться через плотность
распределения следующим образом:
Dξ =
+∞∫
−∞
x2fξ(x)dx−


+∞∫
−∞
xfξ(x)dx


2
.
Замечание 4.2.1Для непрерывной случайной величины математическое
ожидание и дисперсия обладают теми же свойствами, что и для дискрет-
ной случайной величины.
Пример 4.2.1Рассмотрим случайную величинуξ из предыдущего приме-
ра:
fξ(t) =



0, t ≤0
t
2 , 0 <t ≤2
0, t> 2
.
Мы уже нашли ее математическое ожиданиеEξ = 4
3 . Найдем ее дисперсию.
Eξ2 =
+∞∫
−∞
t2fξ(t)dt=
0∫
−∞
t2 ·0dt+
2∫
0
t2 ·t
2dt+
+∞∫
2
t2 ·0dt= 1
2 ·24
4 = 2.
17
Тогда
Dξ = Eξ2 −(Eξ)2 = 2 −
(4
3
)2
= 2
9.
5 Основные законы распределения непрерывных
случайных величин
Аналогично тому, как было сделано в дискретном случае, рассмотрим
наиболее часто встречающиеся непрерывные распределения.
5.1 Равномерное распределение
Определение 5.1.1Говорят, что случайная величинаξ имеет равномер-
ное распределение на отрезке[a,b] и пишут ξ ∼Ua,b, если ее плотность
имеет вид
fξ(x) =
{
1
b−a, x ∈[a,b]
0, x / ∈[a,b]
График плотности представлен на рисунке 3.
Рис. 3: Функция распределения случайной величины, имеющей равномерное
распределение
Если говорить о смысле такого распределения, то можно считать, что
рассматриваемая случайная величина есть не что иное, как координата точ-
18
ки, случайно брошенной на отрезок[a,b]. Плотность такой величины оди-
наково /guillemotleft.cyrразмазана/guillemotright.cyr по отрезку, поэтому и попадание в любую точку этого
отрезка /guillemotleft.cyrравновозможно/guillemotright.cyr.
График функции распределения показан на рисунке 4.
Рис. 4: Функция распределения случайной величины, имеющей равномерное
распределение
Замечание 5.1.1Можно провести аналогию рассматриваемого распреде-
ления и геометрической вероятности. Если случайная величинаξ равно-
мерно распределена на отрезке[a,b], то вероятность попасть в интервал
A= (c,d) ⊂[a,b] пропорциональна длине этого интервала, и равна
P(·∈ A) = λ(A)
λ([a,b]) = d−c
b−a.
Пример 5.1.1Однородную нить длиной1 метр тянут за концы, и проис-
ходит разрыв в случайной точкеξ ∈[0,1]. Найти вероятность того, что
разрыв произойдет в интервале от10 до12 см. Так как нить однородная,
можно считать, что случайная величинаξ имеет равномерное распреде-
ление на отрезке[0,1]. В данном случаеa = 0, b = 1, c = 0.1 и d = 0.12.
Тогда
P(ξ ∈(0.1,0.12)) = d−c
b−a = 0.12 −0.1
1 = 0.02.
19
Математическое ожидание равномерно распределенной величиныξ рав-
но
Eξ =
+∞∫
−∞
xfξ(x)dx=
b∫
a
x
b−adx= b2 −a2
2(b−a) = a+ b
2
Для вычисления дисперсии найдемEξ2.
Eξ2 =
+∞∫
−∞
x2fξ(x)dx=
b∫
a
x2
b−adx= b2 + ab+ a2
3 .
Учитывая, чтоEξ = a+b
2 , получим:
Dξ = Eξ2 −(Eξ)2 = b2 + ab+ a2
3 −(a+ b)2
4 = (b−a)2
12 .
5.2 Показательное распределение
Следующее распределение в некоторым смысле является непрерывным
аналогом распределения Пуассона.
Определение 5.2.1Говорят, что случайная величинаξ имеет показа-
тельное распределение с параметромλ > 0 и пишут ξ ∼ Expλ, если ее
плотность имеет вид
fξ(x) =
{
0, x< 0
λe−λx, x ≥0
График плотности показательного распределения представлен на рисунке 5.
Функция распределения случайной величиныξ легко вычисляется и за-
дается соотношением
Fξ(x) =
{
0, x ≤0
1 −e−λx, x> 0 .
График последней функции представлен на рисунке 6. Оказывается, что дли-
тельности телефонных разговоров, промежутки времени между последова-
тельными приходами клиентов на обслуживание, длительности обслужива-
ния клиентов, время безотказной работы прибора и многое другое имеют
показательное распределение.
Для случайной величиныξ ∼Expλ можно показать, что
Eξ = 1
λ, Dξ = 1
λ2 .
20
Рис. 5: Плотность случайной величины, имеющей показательное распределе-
ние
Пример 5.2.1Пусть ξ – случайная величина, показывающая время обслу-
живания (в минутах) покупателя в магазине, имеющая показательное рас-
пределение. Какова вероятность, что время, затраченное на обслуживание
покупателя, будет находиться в интервале от2 до4 минут, если среднее
время обслуживания составляет2 минуты? Исходя из условия задачи:
Eξ = 1
λ = 2 ⇒λ= 1
2.
Функция распределения случайно величиныξ ∼Exp1
2
для всехx ≥0 имеет
вид:
Fξ(x) = 1 −e−x
2 ,
тогда
P(2 ≤ξ ≤4) = Fξ(4) −Fξ(2) = 1 −e−2 −
(
1 −e−1)
= e−1 −e−2 ≈0.23
5.3 Нормальное распределение
Следующий пример распределения является одним из важнейших.
Определение 5.3.1Говорят, что случайная величинаξ имеет нормаль-
ное (гауссовское) распределение с параметрамиa ∈R, σ2, и пишут ξ ∼
21
Рис. 6: Функция распределения случайной величины, имеющей показатель-
ное распределение
Na,σ2 , если ее плотность имеет вид
fξ(x) = 1√
2πσe−(x−a)2
2σ2 .
График плотности нормального распределения при разных значенияхa,σ2
представлен на рисунке 7. Нормальное распределение используется очень ча-
сто – в нашем мире очень многое /guillemotleft.cyrнормально/guillemotright.cyr.
Определение 5.3.2Нормальное распределение с параметрамиa= 0, σ2 =
1, то есть распределениеN0,1, называют стандартным нормальным.
Ясно, что плотность стандартного нормального распределения имеет вид
fξ(x) = 1√
2πe−x2
2 .
Функция распределения нормального распределения, ввиду важности
последнего, обозначается особым образом:
Fξ(x) = Φa,σ2 = 1
σ
√
2π
x∫
−∞
e−(t−a)2
2σ2 dt,
22
Рис. 7: Плотность случайной величины, имеющей нормальное распределение
не выражается в элементарных функциях и затабулирована (ее значения
можно найти в таблицах). Точнее, затабулирована функция распределения
стандартного нормального распределения, но с помощью замены переменной
в интеграле легко убедиться, что
Φa,σ2 (x) = Φ0,1
(x−a
σ
)
.
График функции распределения нормального закона представлен на рисунке
8. Отметим несколько важных свойств функции распределения
Лемма 5.3.1Функция распределения стандартного нормального распреде-
ления обладает следующими свойствами:
1. Φ0,1(0) = 1
2 ;
2. Φ0,1(−x) = 1 −Φ0,1(x);
Как и в случае с показательным распределением примем без доказатель-
ства тот факт, что еслиξ ∼Na,σ2 , то
Eξ = a, Dξ = σ2.
Пример 5.3.1Случайная величинаξ распределена по нормальному закону
с параметрамиa= 2.5, σ= 2. ОпределитьP(|ξ|≤ 3).
23
Рис. 8: Функция распределения случайной величины, имеющей стандартное
нормальное распределение
Вероятность попадания случайной величины в отрезок[−3,3] можно
найти следующим образом:
P(|ξ|≤ 3) = P(−3 ≤ξ ≤3) =
= Φ0,1
(3 −2.5
2
)
−Φ0,1
(−3 −2.5
2
)
=
= Φ0,1 (0.25) −Φ0,1 (−2.75) ≈0.596.
Для случайной величиныξ, имеющей нормальное распределениеNa,σ2 ,
справедливо так называемое правило3σ, которое гласит, что
P(|ξ−a|<3σ) = P(ξ ∈(a−3σ,a + 3σ)) = 0.9972.
Конкретное значение помнить не обязательно, но важно понимать, что в слу-
чае, когда случайная величина имеет нормальное распределениеNa,σ2 , /guillemotleft.cyrпрак-
тически вся плотность/guillemotright.cyr расположена от среднегоaна расстоянии3σ.
6 Совместное распределение двух случайных величин
В реальных задачах часто приходится рассматривать не одну, а несколь-
ко случайных величин. Достаточно естественно, что распределение одной из
24
них как правило зависит от распределения других. В этом разделе мы изучим
вопросы, связанные с законом распределения векторных случайных величин,
обсудим характер возможной зависимости координат случайного вектора, а
также способы определения меры этой зависимости. В рамках нашего курса
мы будем рассматривать только двумерные дискретные величины.
6.1 Совместное распределение двух дискретных
случайных величин
Определение 6.1.1Совместным распределением случайных величинξ1 и
ξ2 называется набор вероятностейP(ξ1 = a,ξ2 = b), где числаa пробега-
ют всевозможные значенияa1,...,a n случайной величиныξ1, а числаb –
всевозможные значенияb1,...,b k случайной величиныξ2, причем
n∑
i=1
k∑
j=1
P(ξ1 = ai,ξ2 = bj) = 1.
Пустьслучайнаявеличинаξ1 принимаетзначенияa1,...,a n,аслучайнаявели-
чинаξ2 принимает значенияb1,...,b k. Совместное распределение случайных
величин часто записывают в виде таблицы
ξ1 \ξ2 b1 b2 ... bk
a1 P(ξ1 = a1,ξ2 = b1) P(ξ1 = a1,ξ2 = b2) ... P(ξ1 = a1,ξ2 = bk)
a2 P(ξ1 = a2,ξ2 = b1) P(ξ1 = a2,ξ2 = b2) ... P(ξ1 = a2,ξ2 = bk)
... ... ... ... ...
an P(ξ1 = an,ξ2 = b1) P(ξ1 = an,ξ2 = b2) ... P(ξ1 = an,ξ2 = bk)
Зная совместное распределение, можно восстановить так называемые
маргинальные (они же – просто обычные одномерные) распределения слу-
чайных величинξ1 и ξ2 по правилам
P(ξ1 = ai) =
k∑
j=1
P(ξ1 = ai,ξ2 = bj), i∈{1,...,n },
P(ξ2 = bj) =
n∑
i=1
P(ξ1 = ai,ξ2 = bj), j∈{1,...,k }.
Пример 6.1.1Дана таблица совместного распределения двух случайных
величинξ1 и ξ2:
ξ2\ξ1 −1 −2 5
3 0.2 0.2 0
5 0.1 0.05 0.05
7 0.05 0.1 0.25
25
Составим таблицы маргинальных распределений.
Для нахождения маргинальных распределений просуммируем вероят-
ности по столбцам для случайной величиныξ1, и по строкам для случайной
величиныξ2. Например, дляξ1 = −1 сложим вероятности, находящиеся в
столбце, отвечающем значению−1 случайной величиныξ1 и получим
0.2 + 0.1 + 0.05 = 0.35.
Для ξ2 = 7 произведем аналогичную процедуру, но со строкой:
0.05 + 0.1 + 0.25 = 0.4.
Произведя такие операции со строками и столбцами, получим маргиналь-
ные распределения, задаваемые следующими таблицами:
ξ1 −1 −2 5
P 0.35 0.35 0.3 ,
ξ2 3 5 7
P 0.4 0.2 0.4 .
Совместное распределение как раз-таки и помогает понять: зависимы
случайные величины или нет, ведь именно благодаря ему можно определить
выполняется равенство
P(ξ1 = a,ξ2 = b) = P(ξ1 = a)P(ξ2 = b),
или нет.
Пример 6.1.2Проверим, являются ли независимыми случайные величины
ξ1 и ξ2 из предыдущего примера. Независимость устанавливается в том
случае, если равенство
P(ξ1 = a,ξ2 = b) = P(ξ1 = a)P(ξ2 = b),
выполняется для всехaи b. В противном случае случайные величины зави-
симы.
Таблицы совместного и маргинальных распределений имеют вид:
ξ2\ξ1 −1 −2 5
3 0.2 0.2 0
5 0.1 0.05 0.05
7 0.05 0.1 0.25
,
26
ξ1 −1 −2 5
P 0.35 0.35 0.3 ,
ξ2 3 5 7
P 0.4 0.2 0.4 .
Тогда
P(ξ1 = −2,ξ2 = 7) = 0.1.
С другой стороны
P(ξ1 = −2)P(ξ2 = 7) = 0.35 ·0.4 = 0.14.
Так как0.1 ̸= 0.14, можно сделать вывод, что случайные величины зависи-
мы.
Отметим еще одну важную роль совместного распределения. Зная сов-
местное распределение случайных величин, мы можем написать распределе-
ние различных функций от этих случайных величин, в частности распределе-
ниесуммы,разностиилипроизведения.Знаниемаргинальныхраспределений
не позволяет этого сделать, как показывает следующий пример.
Пример 6.1.3Пусть задано совместное распределение случайных величин
ξ1 и ξ2 следующей таблицей (r∈[0,0.5])
ξ1 \ξ2 0 1
0 r 1
2 −r
1 1
2 −r r
.
Маргинальные распределения у случайных величинξ1 и ξ2 одинаковы и не
зависят отr:
ξ1 0 1
P 1
2
1
2
.
ξ2 0 1
P 1
2
1
2
.
Найдем распределение случайной величиныξ1 +ξ2. Ясно, что сумма может
принимать значения0,1,2, причем
P(ξ1 + ξ2 = 0) = P(ξ1 = 0,ξ2 = 0) = r,
P(ξ1 + ξ2 = 1) = P((ξ1 = 1,ξ2 = 0) ∪(ξ1 = 0,ξ2 = 1)) =
27
P(ξ1 = 1,ξ2 = 0) + P(ξ1 = 0,ξ2 = 1) = 1 −2r
и
P(ξ1 + ξ2 = 2) = P(ξ1 = 1,ξ2 = 1) = r.
Тем самым,
ξ1 + ξ2 0 1 2
P r 1 −2r r .
Видно, что распределение зависит отrпри неизменных маргинальных рас-
пределениях.
6.2 Ковариация. Коэффициент корреляции
Обычно у рассматриваемого явления есть не один, а несколько призна-
ков. Например, у человека есть рост, вес, возраст, уровень дохода, регион
проживания и пр. У автомобиля максимальная скорость, пробег, объем дви-
гателя и пр. В таком случае может возникнуть вопрос – есть ли какая-то
связь между величинами? То есть можем ли мы сказать, что изменение од-
ного признака скорее всего повлечет изменение другого? Например, если мы
будем съедать по пять сдобных круассанов в день, то наш вес наверняка
увеличится. Или стал расти курс доллара – жди изменений цены на евро.
Снизилась ставка ипотечного кредитования – повысился спрос на квартиры.
Когда мы рассматриваем математические функции, то наблюдаем пря-
мую зависимость значения функции от аргумента. Например,y = 2 x+ 3.
Тут каждому значениюx соответствует одно строго определенное значение
y. Оперируя со случайными величинами, чаще всего такую прямую функци-
ональную зависимость построить не удается. Мы можем рассмотреть корре-
ляционную зависимость - это вероятностная зависимость между величинами,
которая возникает тогда, когда одна из величин зависит не только от задан-
ной второй величины, но, возможно, и еще от других случайных условий.
Зададимся подробнее математическим вопросом о зависимости или неза-
висимости двух случайных величин. Пустьξ1 и ξ2 – дискретные случайные
величины со значениямиa1,...,a n и b1,...,b k, соответсвенно, и известно их
совместное распределение, тогда
E(ξ1ξ2) =
n∑
i=1
k∑
j=1
aibjP(ξ1 = ai,ξ2 = bj).
Если предположить, чтоξ1 и ξ2 независимы, то
P(ξ1 = ai,ξ2 = bj) = P(ξ1 = ai)P(ξ2 = bj),
28
а значит
E(ξ1ξ2) =
n∑
i=1
k∑
j=1
aibjP(ξ1 = ai,ξ2 = bj) =
n∑
i=1
k∑
j=1
aibkP(ξ1 = ai)P(ξ2 = bj) =
=
n∑
i=1
aiP(ξ1 = ai) ·
k∑
j=1
bjP(ξ2 = bj) = Eξ1 ·Eξ2.
Итого оказывается, что если случайные величиныξ1 иξ2 независимы, то
это отражается в том алгебраическом свойстве, что
E(ξ1ξ2) = Eξ1Eξ2,
а если это равенство не выполнено, то величины оказываются заведомо за-
висимыми.
Определение 6.2.1ВеличинаE(ξ1ξ2) −Eξ1Eξ2 называется ковариацией
случайных величинξ1 и ξ2 и обозначаетсяcov(ξ1,ξ2).
С ковариацией есть одна проблема – она измеряется в квадратах единиц
измерения случайных величинξ1 и ξ2. Это плохо, ведь увеличение значений
одной случайной величины в, скажем,100 раз, влечет и увеличение ковариа-
ции в такое же количество раз, однако /guillemotleft.cyrсила/guillemotright.cyr зависимости не меняется. Тут
приходит на помощь коэффициент корреляции.
Определение 6.2.2Коэффициентом корреляции двух величинξ1 иξ2 с от-
личными от нуля дисперсиями, называется величина
ρ(ξ1,ξ2) = cov(ξ1,ξ2)√Dξ1
√Dξ2
= cov(ξ1,ξ2)
σξ1 σξ2
Коэффициент корреляции обладает следующими свойствами:
1. Егоабсолютноезначениенепревосходитединицы,тоесть|ρ(ξ1,ξ2)|≤ 1;
2. Еслиξ1,ξ2 – независимы, тоρ(ξ1,ξ2) = 0;
3. |ρ(ξ1,ξ2)| = 1 тогда и только тогда, когдаξ1 = aξ2 + b, причемa ·
ρ(ξ1,ξ2) >0.
Отметим, что коэффициент корреляции показывает степень линейной зави-
симости случайных величин. Чем он ближе по модулю к единице, тем более
зависимость близка к линейной.
29
Так, если он равен1, то увеличение значений одной случайной величины
гарантированно влечет увеличение другой, а если−1, то увеличение одной
влечет уменьшение другой.
В то же время к трактовке /guillemotleft.cyrзависимости/guillemotright.cyr двух случайных величин в
статистике, когда корреляция не равна единице, нужно подходить с большой
осторожностью. Предположим, что у нас есть данные о силе наводнения и ко-
личестве привлеченных спасателей службы МЧС. Ясно, что эти показатели
коррелируют, причем коэффициент корреляции положительный. Однако из
этого вовсе не следует, что увеличение числа привлеченных спасателей сви-
детельствует о каком-то ужасном бедствии. И уж тем более это не значит, что
увольнение всех спасателей приведет к отсутствию наводнений и бедствий, с
ними связанных.
Кроме того, равенство нулю корреляции не свидетельствует об отсут-
ствии зависимости.
Пример 6.2.1Покажем, что условие
E(ξ1ξ2) = Eξ1Eξ2
не является достаточным для независимости случайных величин. Для
этого предположим, что пространство элементарных исходовΩ имеет
видΩ = {−π
2 ,0,π
2 }, и на нем заданы две заведомо зависимые случайные ве-
личиныξ1 = sin ω и ξ2 = cos ω. Запишем законы распределения случайных
величин:
ξ1 −1 0 1
P 1
3
1
3
1
3
ξ2 0 1
P 2
3
1
3
Ясно, чтоEξ1 = 0, Eξ2 = 1
3 , значитEξ1Eξ2 = 0. Кроме того, на рассматри-
ваемом пространствеΩ всегдаξ1ξ2 = 0, значит иE(ξ1ξ2) = 0. Тем самым
условие
E(ξ1ξ2) = Eξ1Eξ2
выполнено, но величины зависимы.
Пример 6.2.2Случайные величиныξ1 и ξ2 заданы таблицей совместного
распределения. Определить ковариацию и коэффициент корреляции. Ответ
округлить до сотых.
ξ2\ξ1 2 3 5
−1 0.1 0.3 0.2
1 0.1 0.05 0
4 0 0.15 0.1
30
Ковариация двух случайных величин находится как:
cov(ξ1,ξ2) = E(ξ1ξ2) −Eξ1Eξ2.
Составим таблицу распределения для случайной величиныξ1ξ2. Для этого
необходимо рассмотреть все возможные произведения значений случайных
величин. Вероятность произведения для конкретного случая будет нахо-
диться на пересечении соответствующего столбца и строки. Если значе-
ния произведения получаются одинаковыми (в нашем случае такого нет),
то необходимо сложить соответствующие вероятности. Значения, для
которых вероятность равна0, в таблицу можно не заносить
ξ1ξ2 −5 −3 −2 2 3 12 20
P 0.2 0.3 0.1 0.1 0.05 0.15 0.1
.
Составим таблицы маргинальных распределенийξ1 и ξ2.
ξ1 2 3 5
P 0.2 0.5 0.3
,
ξ2 −1 1 4
P 0.6 0.15 0.25
Найдем соответствующие математические ожидания:
E(ξ1ξ2) = 2.05
Eξ1 = 3.4
Eξ2 = 0.55
Тогда
cov(ξ1,ξ2) = 2.05 −3.4 ·0.55 = 0.18
Найдем коэффициент корреляцииρ для наших случайных величин. На-
помним, что
ρ(ξ1,ξ2) = cov(ξ1,ξ2)√Dξ1 ·√Dξ2
Найдем соответствующие дисперсииξ1 и ξ2 и подставим в выражение для
ρ:
ρ(ξ1,ξ2) = 0.18√
1.24 ·
√
4.4475 ≈0.08
Как видно, коэффициент корреляции отличен от0, значит зависимость
есть (мы это уже показывали в примере 6.1.2), при этом она достаточно
далека от линейной.
31
Замечание 6.2.1Помимо дискретного совместного распределения случай-
ных величины, в жизни очень часто встречаются и непрерывные совмест-
ные распределения случайных величин. Работа с последними требует более
серьезной математической подготовки, поэтому в рамках данного курса
рассматриваться не будет. Отметим лишь, что для двумерных непрерыв-
ных случайных величин сохраняются данные ранее определения, а также
свойства ковариации и коэффициента корреляции.
32
