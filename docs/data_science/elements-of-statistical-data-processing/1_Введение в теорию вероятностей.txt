Лекция
/guillemotleft.cyrВведение в теорию вероятностей/guillemotright.cyr
Санкт-Петербург
2019
Содержание
1 Введение в теорию вероятностей 2
1.1 Случайный эксперимент. Пространство элементарных событий.
Случайные события. . . . . . . . . . . . . . . . . . . . . . . . . . 2
1.2 Операции над событиями . . . . . . . . . . . . . . . . . . . . . . 4
1.3 Полная группа событий . . . . . . . . . . . . . . . . . . . . . . . 8
2 Вероятность. Различные определения. Свойства вероятно-
стей 9
2.1 Классическое определение вероятности . . . . . . . . . . . . . . 9
2.2 Свойства вероятностей . . . . . . . . . . . . . . . . . . . . . . . . 10
2.3 Определение вероятности для случая конечного числа нерав-
новозможных исходов . . . . . . . . . . . . . . . . . . . . . . . . 13
2.4 Геометрическое определение вероятности . . . . . . . . . . . . . 14
2.5 Условные вероятности и формула Байеса . . . . . . . . . . . . . 16
2.6 Вычисление условной вероятности в случае классического
определения . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
2.7 Независимые события . . . . . . . . . . . . . . . . . . . . . . . . 18
2.8 Формула полной вероятности . . . . . . . . . . . . . . . . . . . . 19
2.9 Схема и формула Бернулли . . . . . . . . . . . . . . . . . . . . . 21
3 Случайные величины 23
3.1 Понятие дискретной случайной величины . . . . . . . . . . . . . 23
3.2 Распределение случайной величины . . . . . . . . . . . . . . . . 23
3.3 Распределение функции от дискретной случайной величины . . 25
3.4 Независимость двух дискретных случайных величин . . . . . . 26
3.5 Числовые характеристики дискретных случайных величин . . . 26
3.5.1 Математическое ожидание . . . . . . . . . . . . . . . . . 27
3.5.2 Свойства математического ожидания . . . . . . . . . . . 29
3.5.3 Дисперсия . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
3.5.4 Свойства дисперсии . . . . . . . . . . . . . . . . . . . . . 31
1
1 Введение в теорию вероятностей
Жизнью правит случай. Это известное философское по своей сути изре-
чение является результатом размышлений многих поколений над случайны-
ми событиями и явлениями, которые окружают нас повсюду. Как жить и вы-
жить в мире, наполненном случайностями? Можно ли найти закономерности
в случайном? Если да, то как их разумно использовать? Эти вопросы моти-
вировали людей наблюдать происходящее и накапливать знания о случайных
событиях и об их шансах на реализацию, иначе говоря, об их вероятностях.
Познакомимся с основными понятиями и идеями математической моде-
ли, которую наука под названием /guillemotleft.cyrТеория вероятностей/guillemotright.cyr в настоящее время
использует для изучения случайных явлений. Именно эта модель позволяет
грамотно анализировать и обобщать данные, собранные в результате наблю-
дений. Как это принято в математике, введём основные понятия с помощью
строгих определений. При этом хочется обратить Ваше внимание на есте-
ственность этих определений.
1.1 Случайный эксперимент. Пространство эле-
ментарных событий. Случайные события.
Определение 1.1.1Случайный эксперимент – это эксперимент, который
может закончиться одним из совокупности известных результатов, но до
осуществления эксперимента неизвестно, каким именно.
Определение 1.1.2Различные взаимно исключающие (то есть такие, ко-
торые не могут произойти одновременно) результаты эксперимента на-
зывают элементарными событиями или исходами данного эксперимента
Определение 1.1.3Множество всех исходов эксперимента называется
пространством элементарных событий данного эксперимента. Простран-
ство элементарных событий обозначаетсяΩ.
Примеры случайных экспериментов и их пространств элементарных со-
бытий:
1. Подбрасывание монеты:Ω = {Г,Р}, где Г = {выпал герб}, Р=
{выпала решка} – исходы эксперимента.
2. Бросание игральной костиΩ = {1,2,3,4,5,6}, исходы здесь /emdash.cyr количе-
ство очков, выпавшее на верхней грани.
3. Сдача экзамена:Ω = {2,3,4,5}, исход /emdash.cyr это оценка, полученная на нём.
2
Понятно, что примеров такого рода можно привести множество. Их об-
щая черта – конечное число исходов. Однако, это не всегда так. Приведём
классический пример бесконечного пространства элементарных событий.
Нить длиной в1 метр тянут за концы до её разрыва в случайной точке.
Здесь точка разрываx∈[0,1] и соответственноΩ – это промежуток[0,1], то
есть бесконечное множество.
Определение 1.1.4Случайным событием назовём любое подмножество
пространства элементарных событий.
Иначеговоря,случайноесобытие–этолюбоемножествоисходовданного
эксперимента.
События, как правило, обозначаются заглавными латинскими буквами:
A,B,C,... и если нужно, то записываются словами.
Определение 1.1.5Говорят, что событиеA наступило (произошло), ес-
ли в результате эксперимента осуществился исход, принадлежащий собы-
тию A.
Пример 1.1.1Эксперимент: бросание игральной кости. Тогда простран-
ство элементарных исходовΩ = {1,2,3,4,5,6}. Событие A =
{выпадение нечетного числа}, то есть A = {1,3,5}. Событие B =
{выпадение числа2}, то естьB = {2}.
Предположим, в результате эксперимента выпадает1. Тогда событие
A наступило, так как1 ∈A, а событиеB не наступило, так как1 /∈B.
Предположим теперь, что выпало2. Тогда событиеB наступило, аA
не наступило.
Определение 1.1.6СобытиеΩ состоящее из всех элементарных исходов
эксперимента, называется достоверным событием.
Достоверное событие в результате данного эксперимента обязательно на-
ступает.
Определение 1.1.7Невозможным событием называется событие, кото-
рому не принадлежит ни один из исходов (пустое множество исходов).
Такое событие никогда не наступает в результате данного эксперимента.
Невозможное событие обозначается∅, что совпадает с обозначением пустого
множества.
Пример 1.1.2Бросают игральную кость. Событие
{число очков меньше7} = {1,2,3,4,5,6} = Ω – достоверное событие,
а{выпадение числа, большего или равного7}= ∅ – невозможное событие.
3
Определение 1.1.8Пусть A ⊂Ω,B ⊂Ω (то есть эти события связаны
с одним и тем же экспериментом). Говорят, что чтоA– частный случай
B, еслиA⊂B.
В этом случае говорят также, что /guillemotleft.cyrA влечетB/guillemotright.cyr. Смысл таков: еслиA
наступило, тоB наступило тоже. Графическая иллюстрация соотношения
событийAи B приведена на рисунке 1.
Рис. 1:A– подмножествоB
Пример 1.1.3Бросают игральную кость. Есть следующие три собы-
тия: A = {выпадение1}, B = {выпадение нечётного числа}, C =
{выпадение3 или5}. Очевидно, чтоA⊂B, иC ⊂B.
1.2 Операции над событиями
Далее рассмотрим операции над событиями, которые позволят нам из
простых событий составлять сложные, с тем чтобы впоследствии по опреде-
лённым правилам вычислять вероятности этих сложных событий через веро-
ятности простых.
Определение 1.2.1Сумма (объединение) событийA и B – это событие,
состоящее из всех исходов, принадлежащих хотя бы одному из событийA,
B.
Для суммы событий используется обозначениеA+ B. Графическая ил-
люстрация приведена на рисунке 2.
СобытиеA+ B наступает тогда и только тогда, когда наступает либо
только событиеA, либо только событиеB, либо они наступают одновременно
(то есть наступает хотя бы одно из этих событий).
4
Рис. 2: Сумма событийAи B
Определение 1.2.2Произведение (пересечение) событийA и B – это со-
бытие, состоящее из всех исходов, которые принадлежат одновременно и
A, иB.
Для произведения событий используется обозначениеABилиA·B. Гра-
фическая иллюстрация приведена на рисунке 3.
Рис. 3: Произведение событийAи B
СобытиеAB наступает тогда и только тогда, когда наступают одновре-
менно и событиеA, и событиеB.
5
Определение 1.2.3События A и B называются несовместными, если
они не могут произойти одновременно, то естьAB = ∅.
Графическая иллюстрация несовместных событий приведена на рисунке 4.
Рис. 4: Несовместные событияAи B
Определение 1.2.4Разность событийA и B /emdash.cyr это событие, состоящее
из всех исходов, которые принадлежатA, но не принадлежатB.
Для разности событий используется обозначениеA\B. Графическая ил-
люстрация приведена на рисунке 5.
СобытиеA\B происходит тогда и только тогда, когда событиеAпроис-
ходит, а событиеB при этом не происходит.
Определение 1.2.5Событие, противоположное событиюA (дополнение
событияA) /emdash.cyr это событие, состоящее из всех исходов, которые не при-
надлежат A.
Для противоположного события используется обозначениеA. Графиче-
ская иллюстрация приведена на рисунке 6.
СобытиеAпроисходит тогда и только тогда, когда событиеAне проис-
ходит, то естьA= Ω\A.
Пример 1.2.1Бросаем игральную кость. События:A = {выпадение1},
B = {выпадение нечётного числа}, C = {выпадение3 или5}. D =
{выпадение четного числа}.
6
Рис. 5: Разность событийAи B
1. Найдем суммы событий:
A+ B = B,
A+ C = B,
A+ D= {1,2,4,6},
B+ D= Ω (достоверное событие).
2. Найдем произведения событий:
AB = A,
AC = ∅ (A и C – несовместные события),
AD= ∅ (A и D – несовместные события),
BC = C.
3. Найдем разности событий:
A\B = ∅,
A\C = A,
A\D= A,
B\A= C,
C\A= C.
7
Рис. 6: Дополнение событияA
4. Найдём противоположные события:
A= {выпадение любого числа кроме1}= {2,3,4,5,6},
B = D,
C = {выпадение либо 1, либо чётного числа}= {1,2,4,6},
D= B.
1.3 Полная группа событий
В завершении этого раздела введём важное для дальнейшего понятие
полной группы событий.
Определение 1.3.1H1,H2,...,H n ⊂ Ω. Говорят, что события
H1,H2,...,H n образуют полную группу событий, если в результате
эксперимента происходит одно и только одно из этих событий (либоH1,
либоH2, ... , либоHn)
Графическая иллюстрация полной группы событий дляn= 5 приведена
на рисунке 7.
Иначе говоря,
H1 + H2 + ... + Hn = Ω
и
Hi ·Hj = ∅,i ̸= j.
8
Рис. 7: Полная группа событий
Пример 1.3.1Бросаем игральную кость. События:A = {выпадение1},
B = {выпадение нечётного числа}, C = {выпадение3 или5}. D =
{выпадение четного числа}.
1. События B и D образуют полную группу, так как всегда выпадает
либо четное, либо нечетное число.
2. СобытияA, C, Dтакже являются полной группой событий, посколь-
ку они попарно несовместны иA+ C+ D= Ω.
2 Вероятность. Различные определения. Свойства
вероятностей
Вероятность события – это количественная оценка возможности появле-
ния этого события. Дадим определение вероятности, которое позволяет мо-
делировать большое число случайных явлений.
2.1 Классическое определение вероятности
Рассмотрим случайный эксперимент с конечным числом исходов равным
n.Предположим,всеисходыравновозможны,тоестьимеютодинаковыешан-
сы для появления.
Определение 2.1.1Пусть, событиеAсостоит изmисходов. Этиmис-
ходов называются благоприятствующими событиюA.
9
Определение 2.1.2ВероятностьюP(A) событияA назовём отношение
числа равновозможных исходов, благоприятствующих событиюA, к числу
всех возможных исходов.
P(A) = m
n.
Пример 2.1.1Бросаем игральную кость. ЗдесьΩ = {1,2,3,4,5,6}и, сле-
довательно,n = 6. Если предположить, что кость правильная, то исхо-
ды естественно считать равновозможными. Найдём вероятность того,
что выпадет нечётное число очков. Обозначим это событие черезA. Тогда
A = {1,3,5}и число благоприятных исходовm = 3. Найдем вероятность
событияA:
P(A) = 3
6 = 0.5.
Пример 2.1.2В итоговом контрольном задании было предусмотрено40
вариантов задания с использованием линейной нормировки показателей и
60 – с использованием экспоненциальной. Случайным образом (наудачу) вы-
бирается один из вариантов. Какова вероятность получить задание c ли-
нейной нормировкой? Какова вероятность получить задание c экспоненци-
альной нормировкой?
Рассмотрим события:A= {выбран вариант с линейной нормировкой},
B = {выбран вариант с экспоненциальной нормировкой}. Количество всех
возможных исходов эксперимента:
n= 40 + 60 = 100.
Событию A благоприятствуют40 исходов, событиюB –60 исходов. Сле-
довательно,
P(A) = 40
100 = 0.4,
P(B) = 60
100 = 0.6.
2.2 Свойства вероятностей
Вероятностьобладаетрядомсвойств,которыеоказываютсячрезвычайно
полезными при решении многих практических задач. Рассмотрим эти свой-
ства. Сформулируем их в следующей последовательности: сначала три основ-
ные, а потом остальные, которые легко доказываются на основании первых
трёх.
ПустьΩ – пространство элементарных событий некоторого эксперимен-
та,A⊂Ω, B ⊂Ω.
10
1. Вероятность достоверного события равна1.
P(Ω) = 1.
2. Вероятность любого события неотрицательна.
P(A) ≥0.
3. ЕслиA и B несовместны (A·B = ∅), то вероятность их суммы равна
сумме их вероятностей.
P(A+ B) = P(A) + P(B).
Доказательство этих свойств непосредственно следует из данного выше
определения вероятности.
Сформулируем теперь остальные свойства:
4. Если событиеA влечетB (A ⊂B), то вероятностьA не превосходит
вероятностиA.
P(A) ≤P(B).
5. Границы возможных значений вероятностей могут изменяться от0 до
1 включительно.
0 ≤P(A) ≤1.
6. Вероятность события, противоположного событиюAравна1 минус ве-
роятность событияA.
P(A) = 1 −P(A).
7. Вероятность невозможного события равна нулю
P(∅) = 0.
8. Для любыхAиB (возможно совместных) вероятность их суммы равна
сумме их вероятностей событий минус вероятность их произведения.
P(A+ B) = P(A) + P(B) −P(AB).
Последнее утверждение часто называют теоремой сложения вероятно-
стей. Легко видеть, что это обобщение третьего из основных свойств вероят-
ности.
Сделаем важное замечание.
11
Замечание 2.2.1Так как события полной группы попарно несовместны и
их сумма равна достоверному событию, то сумма вероятностей всех со-
бытий полной группы всегда равна единице. Это позволяет в принципе рас-
сматривать события из полной группы как элементарные (вспомним, что
в результате эксперимента всегда происходит одно и только одно событие
из полной группы).
Рассмотрим несколько практических задач, решение которых базируют-
ся на свойствах вероятности.
Пример 2.2.1В книжном шкафу на полке стоят6 книг по программи-
рованию и10 по статистике. Среди них7 книг по статистике и4 по
программированию – на русском языке (остальные – на английском языке).
Язык: русскийЯзык: английскийВсего
Статистика 7 3 10
Программирование 4 2 6
Всего 11 5 16
Какова вероятность того, что случайно выбранная книга окажется
книгой по статистике или книгой на английском языке?
Пусть A = {выбрана книга по статистике}, B =
{выбрана книга на английском языке}. В задаче требуется найти ве-
роятность суммы этих событий. События в задаче явно являются
совместными, так как среди книг на английском есть книги по ста-
тистике. Поэтому для них будем использовать теорему сложения
вероятностей:
P(A+ B) = P(A) + P(B) −P(AB).
Все вероятности в правой части формулы находятся по классическому
определению на основе приведённой таблицы. Общее число исходов в экспе-
рименте равно количеству книг, то есть16. Благоприятных исходов для
книг по статистике –10, для книг на английском языке –5, а для книг на
английском языке по статистике –3. Итого, получаем:
P(A+ B) = P(A) + P(B) −P(AB) = 10
16 + 5
16 − 3
16 = 12
16 = 0.75.
Итак, вероятность того, что случайно выбранная книга окажется книгой
по статистике или книгой на английском языке равна0.75
12
2.3 Определение вероятности для случая конеч-
ного числа неравновозможных исходов
Естественно, что при всей своей популярности, классическая модель при-
мениманевсегда.Например,крайненеразумносчитатьравнымивероятности
встретить слона на Невском и не встретить его там же. Уберём требование
равновозможности элементарных исходов, которое является необходимым в
классическом определении.
Рассмотрим случайный эксперимент сnисходами и пространством эле-
ментарных событийΩ = {ω1,ω2,...,ω n}. Предположим, что для каждогоωi
исходя из каких либо соображений задана его вероятностьP(ωi). То есть для
всехi= 1,2,...,n заданы неотрицательные числаP(ωi), такие, что
n∑
i=1
P(ωi) = 1.
Определение 2.3.1Вероятностью событияAназовём числоP(A), равное
сумме вероятностей всех исходов, принадлежащих событиюA.
P(A) =
∑
ωi∈A
P (ωi) .
Легко проверить, что три основных свойства вероятности в этом случае
выполнены, а значит, выполнены и все остальные.
Пример 2.3.1Студент сдает экзамен. Возможные исходы – это отмет-
ки, которые может получить студент, то естьΩ = {ω1,ω2,ω3,ω4} =
{2,3,4,5}. Студент учится не первый год и по истории его предыдущих
отметок уже можно сделать какие-то вероятностные предположения о
том, как он сдаст экзамен. Предположим, что для данного студента из-
вестны следующие вероятности элементарных исходов:P (ω1) = P(2) =
0.02, P (ω2) = P(3) = 0.08, P (ω3) = P(4) = 0.2, P (ω4) = P(5) = 0.7.
Требуется определить вероятности следующих событий: студент
сдаст экзамен на4 или5; студент сдаст экзамен.
Рассмотрим события:A = {студент сдаст экзамен на 4 или 5} =
{ω3,ω4}, B = {студент сдаст экзамен}= {ω2,ω3,ω4}. По данному выше
определению вероятности:
P(A) = P (ω3) + P (ω4) = 0.2 + 0.7 = 0.9,
P(B) = P (ω2) + P (ω3) + P (ω4) = 0.08 + 0.2 + 0.7 = 0.98.
13
2.4 Геометрическое определение вероятности
Рассмотренныеранееопределениявероятностипредполагаликонечность
пространства элементарных событий. Обобщим понятие вероятности на тот
случай, когда пространство элементарных событий представляет собой огра-
ниченную область, на которой определена некоторая мера. В качестве меры,
к примеру, может выступать длина (на прямой), площадь (на плоскости),
объем (в пространстве). Результатом эксперимента будет случайный выбор
той или иной точки этой области. События в этом случае – это множества
точек данной области.
Заметим, что такая геометрическая интерпретация позволяет иллюстри-
ровать операции над событиями при помощи диаграмм Венна (что мы и де-
лали в самом начале курса несколько забегая вперёд).
По аналогии с классической схемой будем считать, что выбор любой точ-
кивзаданнойобластиравновозможен.Сгеометрическойточкизренияравно-
возможность будем интерпретировать так: шансы выбрать точки из областей
одинаковой меры равны. Поскольку случайное событие – это подмножество
пространства элементарных событий (имеющее меру), естественно требовать,
чтобы это подмножество также имело соответствующую меру. Приведем кон-
кретные примеры.
Пример 2.4.1На координатной плоскости наудачу выбираем точку с ко-
ординатамиx и y из квадрата[−1,1] ×[−1,1]. Рассматриваем событие
A= {выбор точки, для которой выполнено:x2 +y2 ≤1}. В данном примере
пространство элементарных событийΩ – это множество точек квадрата
[−1,1] ×[−1,1], а его мера – площадь квадрата, то есть
S(Ω) = 22 = 4.
Мера событияA – площадь вписанного круга единичного радиуса (рисунок
8)
S(A) = πr2 ≈3.14.
Чтобы не обозначать на прямой меру (длину) множестваA, какl(A),
на плоскости меру (площадь) множества , какS(A), а в пространстве меру
(объем) множестваA, какV(A), будем писать всегдаλ(A).
Итак, пусть пространство элементарных событийΩ – это ограниченная
область,λ(Ω) – ее мера. Мы рассматриваем эксперимент, который заклю-
чается в случайном выборе точки изΩ. Определим вероятность случайного
событияA⊂Ω, которое произойдёт в результате данного опыта, если наугад
выбрана точкаω∈A. Предположим, что это событиеA, имеет соответству-
ющую меру:λ(A).
14
Рис. 8: Геометрическая вероятность
Определение 2.4.1ВероятностьюP(A) событияA называется отноше-
ние меры событияA к мере пространства элементарных событийΩ:
P(A) = λ(A)
λ(Ω).
Такое определение называют геометрическим определением вероятно-
сти. Вычислим геометрическую вероятность события, описанного в приве-
денном выше примере:
P(A) = λ(A)
λ(Ω) = π
4 ≈0.785.
Из свойств меры (возьмём в качестве примера меры площадь) и данного
определения ясно, что во первых,P(Ω) = 1, во-вторыхP(A) ≥0, так как от-
ношение площадей не бывает отрицательным, и в третьих, для несовместных
(непересекающихся)A,B верно:
15
P(A+ B) = λ(A+ B)
λ(Ω) = λ(A) + λ(B)
λ(Ω) = λ(A)
λ(Ω) + λ(B)
λ(Ω) = P(A) + P(B).
Итак, первые три свойства вероятности выполняются. Как уже говорилось,
это означает и выполнение остальных свойств.
С помощью геометрической вероятности могут быть решены задачи са-
мого разнообразного содержания, важно лишь правильно построить геомет-
рическую модель. Приведем пример, который является, вариацией на тему
достаточно известной задачи о встрече.
Пример 2.4.2Лиза и Андрей договорились о встрече в определенном ме-
сте между17-ю и18-ю часами (и сотовая связь отсутствует!). Каждый
из них приходит к месту встречи в случайный момент времени из ука-
занного временного интервала и ждет другого30 минут, в любом случае
покидая место встречи в18 : 00 . Чему равна вероятность, что встреча
состоится?
Пустьx– время прихода Лизы, аy– время прихода Андрея. Если нача-
ло координат поместить в точку(17,17) то пространство элементарных
событий можно описать так:
Ω = {(x,y) : 0 ≤x ≤1,0 ≤y ≤1}= [0,1] ×[0,1].
Тогда событиеA = {встреча состоялась}– это множество точек изΩ,
координаты которых(x,y) удовлетворяют условию|x−y|≤ 1/2. С гео-
метрической точки зрения, это те точки квадрата[0,1] ×[0,1], которые
лежат между прямыми y = x+ 1/2 и y = x−1/2. Площадь области, со-
ответствующей событиюA, будет равна разности между площадью квад-
рата (сторона квадрата равна1) и суммой площадей двух прямоугольных
треугольников с катетами по0.5. Так какλ(Ω) = 1, то
λ(A) = 1 −2 ·0.5 ·0.5
2 = 1 −0.25 = 0.75.
Итак, искомая вероятностьP(A) = 0.75.
2.5 Условные вероятности и формула Байеса
Иногда приходится рассматривать вероятности событий, исходя не из
всего пространства элементарных событий, а только из некоторой его части.
Эта ситуация возникает в том случае, когда есть дополнительная информа-
ция о том, что некоторое событие уже произошло. Из-за этого изменяются
16
условия следующего эксперимента, а следовательно, его пространство эле-
ментарных событий. Например, если из урны с разноцветными шарами из-
влечь шар определённо цвета, то изменится и число шаров в урне и их цвето-
вой состав. Поэтому следующий шар будут извлекать уже в новых условиях.
Определение 2.5.1Пусть B – некоторое событие, причемP(B) ̸= 0 .
Условная вероятность событияA при условииB, обозначаемаяP(A|B),
определяется формулой:
P(A|B) = P(AB)
P(B) .
Иногда для этого используется следующая терминология: вероятность
событияAпри условии, что событиеB произошло.
Из определения условной вероятности вытекает формула вероятности
произведения событий(при условии, что условная вероятность определена):
P(AB) = P(A|B)P(B).
Замечание 2.5.1Теорема умножения может быть распространена на n
сомножителей:
P (A1A2A3 ·... ·An−1An) = P (A1) P (A2|A1) P (A3|A1A2)·... ·P (An|A1A2 ...A n−1) .
Это утверждение легко доказывается индукцией по числу сомножителей.
Из формулы условной вероятности легко получается так называемая
формула Байеса. Согласно определению условной вероятности, в случае, если
P(A) ̸= 0,
P(B|A) = P(BA)
P(A) = P(AB)
P(A) .
Если, кроме того,P(B) ̸= 0, то согласно теоремам умножения
P(AB) = P(A|B)P(B),
а тогда
P(B|A) = P(A|B)P(B)
P(A) .
17
2.6 Вычисление условной вероятности в случае
классического определения
Рассмотрим случайный эксперимент сn равновозможными исходами.
Пустьmисходов благоприятствуют событиюB, аkисходов благоприятству-
ют событиюAB. Тогда
P(B) = m
n,P(AB) = k
n,
P(A|B) = P(AB)
P(B) = k
m.
То есть для задач с равновозможными исходами вычислять условную веро-
ятность можно по формуле:
P(A|B) = k
m,
гдеk – количество благоприятных исходов дляAB, m – количество благо-
приятных исходов дляB.
Замечание 2.6.1Условная вероятностьP(A|B) – это такая же вероят-
ность (в данном случае классическая), заданная на новом пространстве эле-
ментарных событийΩ′ = B с событиямиA′ = AB ⊂Ω′. Все свойства
вероятности при этом сохраняются.
Пример 2.6.1Бросают игральную кость. Рассмотрим события:A =
{выпадение 3}, B = {выпадение нечетного числа}. Требуется найти
P(A|B).
Поскольку в задаче исходы равновозможны, можно применить форму-
лу вычисления условной вероятности для равновозможных событий. Коли-
чество благоприятных исходов для событияB – 3. Количество благопри-
ятных событий для произведения событийAB –1. ЗначитP(A|B) = 1/3.
2.7 Независимые события
Интуитивно, независимыми принято считать такие два события, для ко-
торых вероятность появления одного из них не зависит от того, происходит
ли другое событие. Однако есть и формальное определение.
ПустьΩ – пространство элементарных событий,A⊂Ω,B ⊂Ω.
Определение 2.7.1События A и B называются независимыми, если
P(AB) = P(A)P(B),
то есть вероятность произведения событий равна произведению вероят-
ностей.
18
Интересно сравнить формулы умножения вероятностей для зависимых
и независимых событий.
Для независимых событий:
P(AB) = P(A)P(B).
Для зависимых событий:
P(AB) = P(A|B)P(B),
если условные вероятности определены! Из этого сравнения немедленно сле-
дует, что для независимых событийP(A|B) = P(A). Написав аналогичные
формулы с условиемA, получимP(B|A) = P(B).
Полученные результаты вполне согласуются с нашей интуицией. Убе-
димся, что независимые события, действительно, существуют. Рассмотрим
задачу про колоду карт.
Пример 2.7.1Из колоды, содержащей 52 карты, выбирают од-
ну карту. Рассмотрим два события: A = {выпадение туза},
B = {выпадение карты червовой масти} Требуется доказать, что
событияA и B являются независимыми.
Общее количество исходов для эксперимента –52. Количество благо-
приятных исходов для событияA – 4, благоприятных исходов дляB – 13,
а для пересечения событийAB – всего1. Теперь легко вычисляются веро-
ятности для событий:
P(A) = 4
52,P(B) = 13
52,P(AB) = 1
52.
Откуда следует, чтоP(AB) = P(A)P(B). Значит, событияA и B явля-
ются независимыми.
2.8 Формула полной вероятности
Может так случиться, что вероятность некоторого событияA неизвест-
на, но известны, или легко вычисляются условные вероятностиP(A|Hi) для
всехHi некоторой полной группы событийHi. Более того, известны также
вероятностиP(Hi) для всехi. В этом случае можно вычислить вероятность
P(A) по формуле полной вероятности:
P(A) = P(H1)P(A|H1) + ··· + P(Hn)P(A|Hn),
гдеH1,H2,...,H n – полная группа событий иP(Hi) ̸= 0, i= 0,1,...,n
Заметим, что события полной группы часто интерпретируют как гипо-
тезы, а их вероятности называют априорными вероятностями гипотез. Из
19
определения полной группы и свойств вероятности следует, что сумма апри-
орных вероятностей гипотез равна единице. То есть всегда
n∑
i=1
P (Hi) = 1.
ПриэтомусловнуювероятностьP(A|Hi) вформулеполнойвероятноститрак-
туют как вероятность событияA, если верна гипотезаHi.
Формула полной вероятности дает возможность решать многие задачи,
связанные с вычислением вероятностей. Убедимся в этом на конкретных за-
дачах.
Пример 2.8.1Для компьютерных классов была закуплена партия мони-
торов. Партия содержит45% мониторов, изготовленных первым произ-
водителем,30% – вторым производителем и25% – третьим производи-
телем. Для первого производителя вероятность выпуска бракованного мо-
нитора равна0.05, для второго –0.01 и для третьего –0.04. Из партии
берется наудачу один монитор. Требуется найти вероятность того, что
этот монитор бракованный.
Рассмотрим события:
A= {выбранный монитор бракованный},
H1 = {выбранный монитор изготовлен первым производителем},
H2 = {выбранный монитор изготовлен вторым производителем},
H3 = {выбранный монитор изготовлен третьим производителем}.
Нам известно процентное соотношение поставленных мониторов от-
носительно производителей (45%, 30%, 25%). По ним легко вычисляются
априорные вероятности гипотезH1,H2 и H3:
P(H1) = 0.45,P(H2) = 0.30,P(H3) = 0.25,
Вероятность получить бракованный монитор при условии, что он вы-
пущен тем или иным производителем совпадает с заявленной вероятно-
стью брака от производителя, то есть:
P(A|H1) = 0.05,P(A|H2) = 0.01,P(A|H3) = 0.04.
Теперь, применяя формулу полной вероятности, получим:
P(A) = P(A|H1)P(H1) + P(A|H2)P(H2) + P(A|H3)P(H3) =
0.05 ·0.45 + 0.01 ·0.30 + 0.04 ·0.25 = 0.0355.
20
Часто в задачах удобно применять формулу полной вероятности вместе
с формулой Байеса. ПустьH1,H2,...,H n – полная группа событий. Тогда,
согласно формуле полной вероятности,
P(A) = P (A|H1) P (H1) + P (A|H2) P (H2) + ... + P (A|Hn) P (Hn)
Тогда, согласно формуле Байеса, вероятность гипотезыHi при условии, что
произошло событиеA, может быть вычислена, как
P (Hi|A) = P (A|Hi) P (Hi)
P(A) =
= P (A|Hi) P (Hi)
P (A|H1) P (H1) + P (A|H2) P (H2) + ... + P (A|Hn) P (Hn)
Пример 2.8.2Вернемся к рассмотренной задаче про мониторы. Предполо-
жим, что известно, что монитор бракованный (событиеA). Найдем ве-
роятность события, что его выпустил второй производитель. Итак, нам
нужно найтиP(H2|A). Согласно формуле Байеса,
P (H2|A) = P (A|H2) P (H2)
P(A) = 0.01 ·0.3
0.0355 ≈0.085.
2.9 Схема и формула Бернулли
Определение 2.9.1Схемой Бернулли называют последовательность ис-
пытаний, для которых выполнены следующие условия:
•каждое испытание имеет ровно два исхода, условно называемых успе-
хом и неудачей;
•результат очередного эксперимента не зависит от результатов
предыдущих экспериментов;
•вероятность успеха должна быть постоянной для всех испытаний.
Приведем пример серии экспериментов (испытаний), описываемой схе-
мой Бернулли.
Пример 2.9.1Игральную кость подбрасывают3 раза. События:A =
{выпадение6}, противоположное событие означает, что выпало число,
отличное от 6. Исход, благоприятствующий событиюA будем интерпре-
тировать как успех, а исход, благоприятствующий событиюA– неудачей.
ТогдаP(A) = 1
6 . Все три условия из определения схемы Бернулли выпол-
нены. Следовательно, мы имеем3 испытания Бернулли с вероятностью
успехаp = 1
6 .
21
Схема Бернулли интересна тем, что для нее достаточно просто можно
определить вероятность появленияmуспешных событий в последовательно-
сти изnиспытаний. В этом случае вероятность определяется с помощью, так
называемой, формулы Бернулли.
Рассмотрим схему Бернулли, состоящую изnиспытаний с вероятностью
успехаp. Обозначим черезPn(m) вероятность появленияm успехов вn ис-
пытаниях. Она может быть вычислена по следующей формуле, которая на-
зывается формулой Бернулли:
Pn(m) = Cm
n pmqn−m,
гдеn – число испытаний,m – количество успехов вn испытаниях,p – веро-
ятность наступления успешного события в отдельном испытании,q = 1 −p.
ЧислоCm
n называется числом сочетаний изnпоm, которое вычисляется
следующим образом:
Cm
n = n!
m!(n−m)!,
где
n! = 1 ·2 ·... ·(n−1) ·n,
0! = 1.
Пример 2.9.2Пусть эксперимент заключается в трехкратном подбрасы-
вании правильной монеты. Требуется найти вероятность того, что герб
выпадет ровно2 раза. События:
A= {выпадение герба при одном подбрасывании},
A= {выпадение решки при одном подбрасывании}.
Вероятность событияA:
P(A) = p = 1
2.
Будем интерпретировать исход, благоприятствующий событиюAкак
успех, а событиюA – как неудачу. Полагаем, что монета идеальная и ве-
роятность успешного события:P(A) = 1
2 . Итак, мы имеем3 испытания с
вероятностью успеха1
2 . Требуется найтиP3(2). По формуле Бернулли:
P3(2) = C2
3 p2q3−2 = 3 ·1
4 ·1
2 = 3
8.
Итак, вероятность того, что герб при трех бросаниях идеальной мо-
неты выпадет дважды, равна3
8 .
22
3 Случайные величины
Понятие случайной величины – одно из фундаментальных понятий тео-
рии вероятностей. Без него невозможно грамотно сформулировать задачи и
описать методы математической статистики как науки, на которую опирает-
ся прикладная статистика, собирающая, обрабатывающая и анализирующая
всевозможные данные. Знакомство со случайными величинами (с.в.) начнём
сдискретныхвеличин.Забегаявперёдотметим,чточастоименнодискретные
с.в. используют в статистике для интерпретации собранных количественных
данных.
3.1 Понятие дискретной случайной величины
Рассмотрим случайный эксперимент. Предположим, что его простран-
ство элементарных событий конечно:Ω = {ω1,ω2,ω3,...,ω n}.
Пусть на нём задана числовая функцияξ. Так как её аргументы – исходы
случайного эксперимента, то и значения будут случайны. В этом смыслеξ
– случайная величина, так как нельзя предсказать заранее, какое именно
значение она примет. Числаxi = ξ(ωi) будем называть реализациямиξ. Так
как по определению функции каждомуωi соответствует единственноеξ(ωi),
то множество значений этой функции также будет либо конечно, либо счётно.
Определение 3.1.1Случайной величиной называется функция, заданная
на пространстве элементарных событий и принимающая числовые значе-
ния.
Определение 3.1.2Случайная величина называется дискретной, если она
принимает конечное или счетное множество значений.
Замечание 3.1.1Отметим, что для обозначения случайных величин ча-
ще всего используют строчные греческие буквыξ,η,... .
Пример 3.1.1Например, если бросаем игральную кость, то случайной ве-
личиной может быть количество очков на выпавшей верхней грани. Если
бросаем одновременно2 кости, то сумма выпавших очков – тоже случай-
ная величина. В качестве случайной величины может быть рассмотрена
продолжительность случайного разговора, количество монет, оказавшихся
в кармане случайного прохожего и так далее.
3.2 Распределение случайной величины
Чтобы описать случайную величину, нужно не только перечислить ее
возможные значения, но и определить вероятности, с которыми она прини-
маетэтизначения.Рассмотримэкзамен,накоторомстудентунужноответить
23
на три вопроса. В таком примере случайной величиной может быть количе-
ство вопросов, на которые студент ответил правильно. Он может ответить
правильно на все вопросы, на два вопроса, только на один и вообще не дать
ни одного правильного ответа. То есть случайная величина может принимать
значения0,1,2,3. Для всех студентов, сдающих экзамен, набор значений бу-
дет одинаковым, но вероятность правильно ответить зависит от подготовки
студента, и соответственно, будет разной для разных студентов.
Определение 3.2.1Пусть ξ – дискретная случайная величина. Совокуп-
ность значений, которые может принимать эта случайная величина, и
вероятностей, с которыми она их принимает, называется законом распре-
деления случайной величиныξ, или просто распределением случайной вели-
чиныξ.
Распределение дискретной случайной величины часто записывают в
форме таблицы. Пустьx1,x2,...,x n – все возможные значения случайной
величиныξ, аpi = P(ξ = xi) – соответствующие вероятности(i= 1,2,...,n ).
Тогда распределениеξ можно записать так:
ξ x1 ... xn
P p1 ... pn
.
Замечание 3.2.1Под записьюP(ξ = xi) понимается вероятность собы-
тия, элементами которого являются те и только те элементарные ис-
ходы, при которых случайная величинаξ принимает значениеxi. Так как
в первой строке выписаны все возможные значения с.в., и эти значения
взаимоисключающие, то события, вероятности которых и естьP(ξ = xi)
образуют полную группу. Поэтому всегда
n∑
i=1
pi = 1.
Пример 3.2.1Давайте представим, что мы сложили в коробочку все ви-
ды монет по одной штуке – один рубль,2 рубля,5 рублей и10 рублей.
Сколько денег мы сможем получить, если наугад берем одну монетку. Со-
ставим распределение этой случайной величины.
ξ 1 2 5 10
P 1
4
1
4
1
4
1
4
.
Пример 3.2.2Теперь давайте представим, что у нас две коробочки, в
каждой из которых все виды монет по одной штуке. Сколько денег мы
сможем получить, если наугад берем по одной монете из каждой коробоч-
ки?
24
1 коробка / 2 коробка1 2 5 10
1 2 3 6 11
2 3 4 7 12
5 6 7 10 15
10 11 12 15 20
Составим распределения:
ξ 2 3 4 6 7 10 11 12 15 20
P 1
16
2
16
1
16
2
16
2
16
1
16
2
16
2
16
2
16
1
16
.
Почему вероятности различны? Дело в том, что сумма, равная2 по-
лучается при одном элементарном исходе:1+1 (из первой коробочки1 и из
второй – тоже1). Вероятность этого события равна по классической схе-
ме 1
16 . Сумма, равная3, получается при двух элементарных исходах:1 + 2
и 2 + 1. Соответственно вероятность этого события равна2
16 . Рассуждая
аналогично, получаем и остальные вероятности. Полезно проверить, что
их сумма равна1.
3.3 Распределение функции от дискретной слу-
чайной величины
Пусть имеется дискретная случайная величинаξ. Рассмотрим числовую
функцию f, преобразующую значение этой случайной величины. При этом
функцияf(ξ) – это тоже дискретная случайная величина. Закон её распреде-
ления можно найти, зная распределениеξ. Действительно, значенияf(ξ) по-
лучают подстановкой значенийxi с.в.ξв качестве аргумента функцииf. При
этом полученные значения сохраняют вероятности аргументовxi. Естествен-
но, что при совпадении значенийf от нескольких аргументов это значение
получает вероятность суммы вероятностей этих аргументов.
Пример 3.3.1Пусть распределение случайной величиныξ задано табли-
цей:
ξ −3 3 7
P 0.3 0.5 0.2 .
Рассмотрим линейную функциюf(ξ) = ξ+ 5. Найдем ее распределение
ξ+ 5 2 8 12
P 0.3 0.5 0.2 .
Рассмотрим квадратичную функциюf(ξ) = ξ2 Найдем ее распределение
25
ξ2 9 49
P 0.8 0.2 .
Отметим, что в дальнейшем мы не раз будем прибегать к преобразованиям
(чаще всего линейным) случайных величин.
3.4 Независимость двух дискретных случайных
величин
Пустьξ – это дискретная случайная величина со значениямиxi, η –
дискретная случайная величина со значениямиyi.
Определение 3.4.1Случайные величиныξ и η называются независимы-
ми, если для любых значенийxi, yi событияξ = xi и η= yi независимы, то
есть
P (ξ = xi,η = yi) = P (ξ = xi) ·P (η= yi) .
Пример 3.4.1Бросаем игральный кубик два раза. Количество очков, вы-
павших при втором броске, никак не зависит от количества очков, выпав-
шем при первом броске. Таким образом, если мы назовем случайной величи-
нойξ – количество очков, выпавшем при первом броске, аη – количество
очков, выпавшем при втором, то эти случайные величины являются неза-
висимыми.
Пример 3.4.2Рассмотрим коробочку, в которой монеты номиналом10
рублей,5 рублей,2 рубля и один рубль представлены по одной штуке. Вы-
таскиваем две монетки по очереди. Пустьξ – номинал монеты при первом
вытаскивании,η – при втором.
1. Если после первого вытаскивания монеты мы положим ее обратно,
то случайные величиныξ и η окажутся независимыми.
2. Если же мы не будем возвращать монету, вытащенную в первый раз,
обратно, то очевидно, что случайная величинаη будет зависеть от
ξ.
3.5 Числовые характеристики дискретных слу-
чайных величин
Рассмотрим основные характеристики дискретных случайных величин,
используемые в теории вероятностей. В дальнейшем мы будем пытаться оце-
нить эти теоретические характеристики на основе имеющихся эксперимен-
тальных данных.
26
3.5.1 Математическое ожидание
Пусть распределение случайной величиныξ задается таблицей:
ξ x1 ... xn
P p1 ... pn
.
Определение 3.5.1Математическим ожиданием случайной величиныξ
называется число
Eξ =
n∑
i=1
xipi.
Математическое ожидание часто называют средним значением. Под
средним значением обычно понимают среднее арифметическое (сумму зна-
чений делённую на количество значений).
Среднее арифметическое будет явно совпадать с математическим ожи-
данием, если всеpi = 1
n. Еслиpi = mi
n ,(∑n
i=1 mi = n), то чтобы получить из
математического ожидания /guillemotleft.cyrклассическое/guillemotright.cyr среднее арифметическое нужно
значениеслагаемогоxi взятьвсуммезначенийmi раз.Количествозначенийв
этом случае будет равноn. Таким образом, в формуле математического ожи-
дания вероятности играют роль /guillemotleft.cyrвеса/guillemotright.cyr, указывая насколько часто случайная
величина принимает соответствующее значение. Отметим, что математиче-
ское ожидание и называют также /guillemotleft.cyrцентром массы/guillemotright.cyr.
Пример 3.5.1Рассмотрим четыре случайные величины:
ξ1 2 3
P 0.5 0.5 .
ξ2 2 3
P 0.7 0.3 .
ξ3 2 5
P 0.9 0.1 .
ξ4 5 8
P 0.7 0.3 .
Заметим, что все заданные случайные величины принимают только
по два значения. При этом у первых двух совпадают принимаемые значе-
ния, но различны вероятности принять эти значения, а у второй и четвер-
той принимаемые значения различны, но совпадают вероятности принять
соответственно первые и вторые значения.
27
Вычислим их математические ожидания (сокращенно
/guillemotleft.cyrмат.ожидания/guillemotright.cyr)
Eξ1 = 2 ·0.5 + 3·0.5 = 2.5.
Eξ2 = 2 ·0.7 + 3·0.3 = 2.3.
Eξ3 = 2 ·0.9 + 5·0.1 = 2.3.
Eξ4 = 5 ·0.7 + 8·0.3 = 5.9.
Замечание 3.5.1Оказалось, что у первых двух случайных величин
мат.ожидание разное, хотя значения были одинаковыми, а второй и тре-
тьей мат.ожидание совпало, а значения и их вероятности были разны-
ми. Этот пример подтверждает, что математическое ожидание ха-
рактеризует значение случайной величины /guillemotleft.cyrв среднем/guillemotright.cyr и из равенства
мат.ожиданий не следует совпадение с.в. (то есть совпадение их законов
распределения).
Однако часто и знание среднего значения оказывается полезным. Рас-
смотрим несколько примеров.
Пример 3.5.2Составим ряд распределения случайной величины, задающей
количество времени, которое студент проводит в день социальных сетях.
Округлим время до целых часов. Предположим, что с вероятностью5
16 он
проводит там2 часа, с вероятностью1
8 – три, с вероятностью1
2 один
час и с вероятностью1
16 не использует соцсети совсем (когда по каким-то
причинам пропадает интернет).
ξ 0 1 2 3
P 1
16
1
2
5
16
1
8
.
ВычислимEξ этой случайной величины, то есть определим, сколько в
среднем студент тратит на общение в соцсетях.
Eξ = 0 · 1
16 + 1 ·1
2 + 2 · 5
16 + 3 ·1
8 = 1.5.
Замечание 3.5.2На основании знанияEξ нельзя утверждать, что в
какой-то конкретный день студент проведет в соцсетях ровно полтора ча-
са. Однако можно давать оценку за большой временной период. Например,
в год студент потратит на это увлекательное занятие356 ·1.5 = 547 .5
часов. Поделим на24 часа и получим – почти22 дня в год!
28
Пример 3.5.3Некая компания проводит лотерею, где победитель полу-
чает квартиру стоимостью4 млн рублей. Известно, что продано5 млн
билетов по500 рублей. В каком размере компания /guillemotleft.cyrнаживается/guillemotright.cyr на каж-
дом участнике? Пустьξ – случайная велична, показывающая количество
ушедших (или пришедших) денег. Но вспомним, что мы истратили500
рублей на каждый билет и учтём это при составлении закона распределе-
ния выигрыша.
ξ −500 3999500
P 4999999/5000000 1/5000000 .
Тогда
Eξ = −500 ·4999999/5000000 + 3999500·1/5000000 = −499.2.
Именно настолько в среднем станет беднее каждый участник лотереи.
3.5.2 Свойства математического ожидания
1. Для любого числаc
Ec= c.
Математическое ожидание постоянной равно этой постоянной.
2. Для любого числаc
E(cξ) = cEξ.
Постоянный множитель можно выносить за знак математического ожи-
дания.
3. Для любых случайных величинξ и η
E(ξ+ η) = Eξ+ Eη.
Математическое ожидание суммы равно сумме математических ожида-
ний.
Замечание 3.5.3Надо заметить, что кроме математического ожидания
для оценки случайной величины /guillemotleft.cyrв среднем/guillemotright.cyr используют и другие числовые
характеристики: медиану и моду. О них поговорим позже.
29
3.5.3 Дисперсия
Кроме математического ожидания рассмотрим еще одну важнейшую
числовую характеристику случайной величины: меру отклонения значений
этой с.в. от среднего, то есть от математического ожидания. Насколько су-
щественна эта характеристика станет ясно из следующих примеров.
Пример 3.5.4Рассмотрим 2 группы людей. Пусть случайные величиныξ1
и ξ2 – показывают рост случайного человека из соответствующей группы.
ξ1 182 184 186
P 1
4
1
2
1
4
.
ξ2 162 178 192 204
P 1
4
1
4
1
4
1
4
.
Рассмотрим законы распределения людей по росту в группе1 и группе
2. Как ни удивительно, матожидание, то есть рост /guillemotleft.cyrв среднем/guillemotright.cyr в этих
группах оказался одинаковым -184. Но мы видим, что группа1 однородна
по росту, а в группе2 большой разброс значений.
Пример 3.5.5Рассмотрим две группы студентов, только что сдавших
экзамен. Сравним их оценки. В одной группе это3,4,4,4,4, в другой –
2,3,4,5,5.
В обеих группах мат.ожидание будет3.8. Но первая группа более од-
нородна, а во второй большой разброс значений.
Замечание 3.5.4Для того, чтобы оценить однородность (или разброс,
рассеяние), вычисляют дисперсию. Именно она позволяет оценить, на-
сколько значения случайной величины приближены к её среднему значению.
Определение 3.5.2Дисперсией случайной величиныξ называется число
Dξ = E(ξ−Eξ)2.
Можно доказать, что
Dξ = Eξ2 −(Eξ)2.
Эту формулу часто применяют для нахождения дисперсии.
Пример 3.5.6Продолжение примера.Вычислим дисперсию для первой
группы студентов:
30
ξ1 3 4
P 1/5 4/5 .
ξ2
1 9 16
P 1/5 4/5 .
Eξ2
1 = 9 ·1/5 + 16·4/5 = 14.6.
Dξ1 = Eξ2
1 −(Eξ1)2 = 14.6 −(3.8)2 = 14.6 −14.44 = 0.16.
Вычислим дисперсию для второй группы.
ξ2 2 3 4 5
P 1/5 1/5 1/5 2/5 .
ξ2
2 4 9 16 25
P 1/5 1/5 1/5 2/5 .
Eξ2
2 = 4 ·1/5 + 9·1/5 + 16·1/5 + 25·2/5 = 15.8.
Dξ2 = Eξ2
2 −(Eξ2)2 = 15.8 −(3.8)2 = 15.8 −14.44 = 1.36.
Видно, что дисперсия (характеристика разброса) у второй группы больше.
3.5.4 Свойства дисперсии
1. Для любого числаc:
Dc= 0.
Дисперсия постоянной величины равна 0.
2. Для любого числаc
D(cξ) = c2Dξ.
Постоянный множитель можно вынести за знак дисперсии, возведя его
в квадрат.
3. Для любого числаc
D(c+ ξ) = Dξ.
Если к случайной величине добавить постоянную с, то дисперсия оста-
нется неизменной.
4. Если случайные величиныξ и η независимы, то
D(ξ±η) = Dξ+ Dη.
Если случайные величиныξ и η независимы, то дисперсия их сум-
мы(разности) равна сумме дисперсий.
31
В качестве линейной меры отклонения от среднего используют квадрат-
ный корень из дисперсии - среднее квадратическое отклонение.
Определение 3.5.3Числоσ = √Dξ называется средним квадратическим
отклонением случайной величиныξ. Среднее квадратическое отклонение
называют также стандартным отклонением.
32
