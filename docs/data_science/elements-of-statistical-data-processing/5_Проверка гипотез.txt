Содержание
1 Проверка статистических гипотез 2
1.1 А что такое гипотеза? . . . . . . . . . . . . . . . . . . . . . . . . 2
1.2 Критерий и его ошибки . . . . . . . . . . . . . . . . . . . . . . . 4
1.3 Уровень значимости и мощность . . . . . . . . . . . . . . . . . . 5
2 Критерии согласия 8
2.1 Понятие критерия согласия . . . . . . . . . . . . . . . . . . . . . 8
2.2 Критерий Колмогорова . . . . . . . . . . . . . . . . . . . . . . . 9
2.3 Проверка гипотезы однородности . . . . . . . . . . . . . . . . . . 11
2.4 Гипотезы о нормальном распределении . . . . . . . . . . . . . . 11
2.4.1 Совпадение средних двух нормальных выборок с равны-
ми дисперсиями . . . . . . . . . . . . . . . . . . . . . . . . 12
2.4.2 Совпадение дисперсий двух нормальных выборок . . . . 13
2.4.3 Гипотеза о среднем нормальной совокупности с извест-
ной дисперсией . . . . . . . . . . . . . . . . . . . . . . . . 13
2.4.4 Гипотеза о среднем нормальной совокупности с неиз-
вестной дисперсией . . . . . . . . . . . . . . . . . . . . . . 14
2.5 Резюме . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
1
1 Проверка статистических гипотез
1.1 А что такое гипотеза?
Здравствуйте, уважаемые слушатели. Вот мы и подошли к последней
лекции нашего курса – лекции, освещающей задачу проверки гипотез, реша-
емую методами математической статистикой.
При построении вероятностных моделей случайных экспериментов мы
то и дело выдвигаем какие-то предположения о генеральной совокупности:
о вероятности того или иного события, о типе распределения, о параметрах
этого распределения и так далее. Все эти предположения логично даже с точ-
ки зрения русского языка назвать гипотезами. Почему гипотезы? Да потому,
что верного ответа на момент наблюдения у нас нет, а вот гипотезы (или
предположения), которые хочется подтвердить или опровергнуть – есть.
Например, мы можем измерять объем продаж какого-то товара и хо-
тим проверить гипотезу, заключающуюся в том, что продажи в этом году, в
среднем, больше, чем в прошлом году. Просто сравнивать средние на больше-
меньше нельзя, так как результат мог быть случайным: могло случайно полу-
читься больше. Так что вопрос глубже, ведь гипотеза не о сравнении средних
двух выборок (то есть не о сравнении выборочных средних), а о сравнении
математических ожиданий двух генеральных совокупностей, распределение
и параметры которых нам неизвестны.
Можно привести и другой пример. Скажем, пусть вопрос /guillemotleft.cyrа кто сего-
дня готовит ужин?/guillemotright.cyr решается случайно, с помощью монетки. Конечно очень
важно, чтобы монетка была правильной (то есть давала справедливое реше-
ние) и выпадала как орлом, так и решкой с вероятностью, очень близкой к
0.5. Как это проверить? Например, можно бросить монетку100 раз и посчи-
тать, сколько раз выпал орел, а сколько – решка, и сравнить эти числа. Но
неужели мы когда-нибудь получим ровно50 орлов и ровно50 решек?
Скорее всего нет. Именно поэтому, наверное, если числа приблизительно
равны, то мы склонны сделать вывод в пользу того, что монетка правильная.
Но и тут есть подводные камни. Ведь не исключено, что такой результат
в серии экспериментов мог получиться и при использовании неправильной
монетки (скажем, с вероятностью выпадения орла равной0.3).
Наоборот, если выпало далекое от половины число гербов, то мы, скорее
всего, склонны сказать, что монетка неправильная. Но и тут нет уверенности,
что это так: ведь может быть всякое, эксперимент-то случаен. Так что и в
такой ситуации монета вполне может оказаться правильной.
Все дело в том, что по выборке конечного объема, как правило, без-
ошибочных выводов о распределении сделать нельзя, поэтому возможность
выбрать неверную гипотезу – то, с чем обязательно нужно считаться.
2
Вообще, говоря на вероятностном языке, последний описанный экспери-
мент (с монеткой) – это серия испытаний Бернулли с (неизвестной) вероятно-
стью успехаpв каждом испытании. Тогда гипотеза, которую мы проверяем,
может быть записана так:p= 0.5 (ну или, например,p∈(0.45,0.55), чтобы
позволить какой-никакой логичный брак).
Итак, давайте дадим определение гипотезы. Пусть дана выборкаX =
(X1,X2,...,X n) из некоторого распределенияP. Если не оговорено против-
ное, то мы будем считать, что все наблюдения (все случайные величины,
входящие в выборку), имеют одно и то же распределение. Оказывается, в ря-
де случаев это предположение нуждается в проверке! То же самое касается
и независимости.
Определение 1.1.1ГипотезойH называется произвольное предположе-
ние о распределении генеральной совокупностиξ.
Если же учесть только что сказанное замечание, гипотезойH пра-
вильнее назвать произвольное предположение о распределении наблюдений.
Давайте сразу же здесь введем понятия простой и сложной гипотез.
Определение 1.1.2ГипотезаH называется простой, если она указывает
только на одно распределениеH = {P= P1}. Иначе гипотезаH называется
сложнойH = {P ∈P}, гдеP – некоторое подмножество множества всех
распределений.
Часто, если гипотез всего две, то одну из них называют основной, а дру-
гую – альтернативой. Тут же важно отметить, что альтернатива, конечно, не
пересекается с основной гипотезой, но вовсе нее обязана быть дополнением
основной до всего семейства распределений.
Давайте приведем типичные примеры (или типичные постановки задач
проверки гипотез), чтобы проиллюстрировать сказанное.
Пример 1.1.1Осуществляется выбор из нескольких простых гипотез:
H1 = {P= P1}, H2 = {P= P2}, ...,Hk = {P= Pk}. Скажем,
H1 = {P= B1/2}, H2 = {P= U0,1}, H3 = {P= N2,4}.
Еще один классический пример.
Пример 1.1.2Имеется простая основная гипотеза и сложная альтерна-
тива: H1 = {P= P1}и H2 = {P∈ P}, гдеP – какое-то подмножество се-
мейства всех распределений, не содержащееP1. Например,H1 = {P= B0.5}
и H2 = {P= Bp, p< 0.5}.
Могут,конечно,какиосновнаягипотеза,такиальтернативабытьсложными,
например
3
Пример 1.1.3H1 = {P = Na,σ2 , a ∈ R,σ > 0} и H2 =
{гипотезаH1 неверна}.
Часто встречается и так называемая гипотеза однородности.
Пример 1.1.4Пусть дана выборкаX11,X12,...,X 1n1 из распределенияP1,
X21,X22,...,X 2n2 из распределенияP2 и так далееXk1,Xk2,...,X knk из рас-
пределенияPk. Проверяется сложная гипотезаH1 = {P1 = P2 = ... = Pk}
против сложной альтернативыH2 = {гипотезаH1 неверна}.
В последнем примере ставится важная задача – задача проверки того, берут-
ся ли выборки из одного и того же распределения, или нет. Эта задача очень
важна в реальной жизни, ведь очень важно понимать, какое именно распре-
деление мы изучаем по конкретной выборке, чтобы не получилось казусов
вроде: по случайно взятой выборке из роста детей в детском саду спрогнози-
ровать размер одежды игроков баскетбольной команды. Ну и так далее.
Хорошо, а как же понять, какая гипотеза лучше? Конечно, с помощью
выборки и так называемого критерия.
1.2 Критерий и его ошибки
Определение 1.2.1Пусть имеются гипотезыH1, H2, ..., Hk и выборка
X = (X1,...,X n). Тогда критерийδ= δ(X1,X2,...,X n) – это отображение
δ: Rn →{H1,H2,..., Hn}.
Итак, критерий – это функция от выборки, возвращающая одну из возмож-
ных гипотез. Бывают еще и так называемые рандомизированные критерии,
которые принимают каждую гипотезу с некоторой вероятностью, но о таких
критериях мы говорить не будем.
Конечно, как мы уже обсуждали ранее, критерий не всегда выдает вер-
ную гипотезу, потому что по выборке, по конечному числу наблюдений зна-
чений генеральной совокупности, обычно не удается получить о ней полной
информации. Именно поэтому возникают так называемые ошибки1,2 и так
далее родов. Мы, как правило, будем рассматривать две гипотезы: основную
и альтернативу, поэтому определение несколько упростим.
Определение 1.2.2Говорят, что произошла ошибка1 рода, если гипотеза
H1 отвергнута критерием, в то время как она верна. Говорят, что произо-
шла ошибка2 рода, если гипотезаH2 отвергнута критерием, в то время
как она верна.
Естественно, наряду с ошибками критерия, возникают и вероятности ошибок
1 и 2 родов. Давайте их определим. Итак, вероятность ошибки первого рода
– это
α1 = PH1 (δ(X) ̸= H1) =PH1 (δ(X) =H2),
4
а вероятность ошибки второго рода – это
α2 = PH2 (δ(X) ̸= H2) =PH2 (δ(X) =H1).
Отметим, что говоря, например, что гипотезаH1 верна, и вычисляяPH1 (·), мы
предполагаем, что распределение выборки именно такое, как и предполагает
гипотезаH1, и вычисляем вероятность в соответствии с этим распределением.
Аналогично сH2. Давайте приведем такой простой пример.
Пример 1.2.1Пусть наудачу взятое изделие некоторого производства
оказывается бракованным с вероятностьюp. Контроль продукции тоже
допускает ошибки: он бракует годное изделие с вероятностьюγ и пропус-
кает бракованное с вероятностьюε.
Для наудачу взятого изделия логично ввести две гипотезы:H1 =
{изделие годное}и H2 = {изделие бракованное}. Давайте найдем вероят-
ности ошибок первого и второго родов.
α1 = PH1 (δ= H2) =Pизделие годное(контроль забраковал изделие) =γ,
α2 = PH2 (δ= H1) =Pизделие бракованное(контроль пропустил изделие) =ε.
Итак, на данный момент неплохо бы сделать следующие выводы. Во-первых,
статистический критерий не говорит точно: верна или нет проверяемая гипо-
теза. Он лишь решает, противоречат или не противоречат выборочные дан-
ные выдвинутой гипотезе. Именно поэтому, разумнее говорить /guillemotleft.cyrотвергаем/guillemotright.cyr
и /guillemotleft.cyrне отвергаем/guillemotright.cyr гипотезу, вместо /guillemotleft.cyrотвергаем/guillemotright.cyr и /guillemotleft.cyrпринимаем/guillemotright.cyr (хотя послед-
няя терминология тоже очень популярна). Во-вторых, если есть одна основ-
ная гипотеза, а остальное – это нежелательные от нее отклонения, то вывод
/guillemotleft.cyrданные противоречат гипотезе/guillemotright.cyr куда весомее, чем вывод /guillemotleft.cyrданные не проти-
воречат гипотезе/guillemotright.cyr. Ну и в-третьих, нам никогда неизвестно, какая гипотеза
реально верна, а потому нужно считаться с вероятностями ошибок критерия.
Про последнее поговорим совсем чуть-чуть подробнее.
1.3 Уровень значимости и мощность
Давайте остановимся подробно только на случае, когда рассматривается
две простые гипотезы о распределении наблюдений:
H1 = {P= P1}, H2 = {P= P2}.
Любой критерийδ в этом случае на выборкеX = (X1,X2,...,X n) принимает
не более двух значений (ведь, напомним, критерийδ – это функция изRn в
{H1,H2}). Ну а тогда можно считать, что всеRn распадается на две частиS
и Rn \S, то есть
Rn = S∪(Rn \S) ,
5
и критерийδ в общем виде принимает вид
δ(X) =
{
H1, еслиX ∈Rn \S
H2, еслиX ∈S .
ОбластьS часто называют критической областью.
Определение 1.3.1Уровнем значимости критерияδ называют вероят-
ность ошибки первого родаα1:
α1 = α1(δ) =PH1 (δ̸= H1) =PH1 (δ= H2) =PH1 (X ∈S).
Итак, уровень значимости критерия – это вероятность того, что выборка
попадает в критическую область в условиях того, что верна гипотезаH1.
Вместе с уровнем значимости критерия часто рассматривают и такую харак-
теристику, как мощность.
Определение 1.3.2Мощностью критерияδ называют1 −α2, то есть
1 −α2 = 1−α2(δ) = 1−PH2 (δ̸= H2) =PH2 (δ= H2) =PH2 (X ∈S).
Итак, мощность критерия – это вероятность того, что выборка попадет
в критическую область при условиях того, что верна гипотезаH2.
Важноотметить,чтовероятностиошибокпервогоивторогородавычисляют-
ся при разных предположениях о распределении (верна гипотезаH1 или ги-
потезаH2), а потому никаких фиксированных соотношений вродеα1 = 1−α2
и иже с ними просто напросто не существует.
Ясно, что хочется: чтобы уровень значимости был как можно меньше,
ведь уровень значимости – это вероятность ошибки первого рода, а ошиб-
ки надо искоренять. Однако не менее важно увеличивать и мощность: ведь
чем больше мощность, тем меньше ошибка второго рода. К сожалению, на
практике следить за тем и другим параметрами одновременно не представля-
етсявозможнымиз-заотсутствияявнойфункциональнойзависимостимежду
мощностью и уровнем значимости. На практике классически выбирается до-
статочно маленький уровень значимости, а уж мощность оказывается такой,
какой оказывается, мы ее не выбираем.
Оказывается, что дело обстоит даже вот как. Уменьшение уровня зна-
чимости как правило ведет к уменьшению и мощности, то есть одновременно
уменьшить уровень значимости и увеличить мощность мы, как правило, не
можем. Ведь уменьшая ошибку первого рода, то есть уменьшая вероятность
PH1 (X ∈S), мы будем уменьшать критическую областьS, тем самым умень-
шая и мощность, равнуюPH2 (X ∈S), так что между мощностью и уровнем
6
значимости нужно сохранять некий компромисс. Покажем это и на таком
шуточном примере.
Пусть у нас есть выборка объема1 из нормального распределенияNa,1.
Рассмотрим две гипотезы:H1 : a= 0и H2 : a= 1и критерий
δ(X1) =
{
H1, X1 ≤d
H2, X1 >d .
Что такое ошибка первого рода? Это вероятность не отвергнуть гипотезуH2
в случае, когда верна гипотезаH1, то естьα = PH1 (δ= H2) = PH1 (X1 > d).
Что такое ошибка второго рода? Это вероятность не отвергнуть гипотезуH1
в случае, когда верна гипотезаH2, то естьPH2 (δ= H1) =PH2 (X1 ≤d).
На рисунке четко видно, что уменьшая вероятность ошибки первого рода
(α), автоматически возрастает вероятность ошибки второго рода, тем самым
уменьшается мощность критерия, и наоборот.
Рис. 1: Ошибки первого и второго рода
Еще раз отметим, что ошибку первого рода мы фиксируем, а ошибку
второго – нет. А это значит, что может быть вовсе не все равно, что рассмат-
ривать в качестве первой гипотезы, а что – в качестве альтернативы к ней.
Скажем, путь мы собираемся лететь на самолете, и у нас есть две гипотезы:
H1 = {самолет исправный}и H2 = {самолет неисправный}. При проверке
гипотезы возникает две ошибки: отвергнуть гипотезу, что самолет исправ-
ный, если самолет исправный (ошибка первого рода), и отвергнуть гипотезу,
что он неисправный, если он неисправный (ошибка второго рода). При таком
выборе гипотез мы контролируем ошибку события, которое, в худшем слу-
7
чае, принесет нам потерю денег за сданный билет, и совсем не контролируем
вероятность события, которое отвечает за возможную авиакатастрофу.
В такой ситуации, гипотезы стоит сформулировать иначе:H1 =
{самолет неисправный}и H2 = {самолет исправный}. Теперь мы будем кон-
тролировать вероятность события /guillemotleft.cyrотвергнуть гипотезу, что самолет неис-
правный, если самолет неисправный/guillemotright.cyr, сделаем ее, конечно, известной и очень
маленькой, и перестанем бояться возможной (с неизвестной вероятностью
происходящей) авиакатастрофы.
2 Критерии согласия
2.1 Понятие критерия согласия
Проверка гипотез – тема, заслуживающая не одной лекции, а целого
отдельного курса. Мы остановимся только на так называемых критериях со-
гласия и некоторых их обобщениях.
Определение 2.1.1Критериями согласия обычно называют критерии,
предназначенные для проверки простой гипотезыH1 = {P= P1}при слож-
ной альтернативеH2 = {гипотезаH1 неверна}.
Мы будем работать по следующему принципу. Пусть задана некоторая функ-
ция, показывающая отклонение эмпирического распределения (построенного
по выборкеX = (X1,X2,...,X n)) от теоретического, распределение которой
существенно разнится от того верна основная гипотеза или нет. Логично, что
в зависимости от значения этой /guillemotleft.cyrфункции/guillemotright.cyr отклонения, можно не отвергать
или отвергать основную гипотезу. Давайте попробуем сформулировать неко-
торый алгоритм.
1. Пусть удается задать некоторую функциюρ(X) такую, что:
•если гипотезаH1 верна, то
ρ(X)
d
−−−−→
n→+∞
Y ∼G,
гдеG– некоторое непрерывное распределение;
•если гипотезаH1 неверна, то
|ρ(X)|
P
−−−−→
n→+∞
∞.
2. Тогда для случайной величиныY, имеющей распределениеGнайдем по-
стояннуюC из условияε = P(|Y|≥ C). Построим критерийδ следующим
8
образом:
δ(X) =
{
H1, если|ρ(X)|<C
H2, если|ρ(X)|≥ C
Итак,построенныйкритерийработаетвотпокакомуправилу.Еслинаданной
выборке функция отклонения по абсолютному значению оказывается велика,
то выбор свидетельствует в пользу альтернативы, и наоборот.
Можно показать, что при увеличенииnуровень значимости нашего кри-
терия стремится кε, а мощность – к единице. Последнее понятие нуждается
в уточнении, ведь теперь альтернатива состоит не из одного распределения,
а из какого-то множества. В нашем случае это означает, что мощность для
каждого конкретного распределения из альтернативы стремится к единице.
Давайте теперь приведем конкретные примеры критериев и их примене-
ний.
2.2 Критерий Колмогорова
Одна из самых важных задач – по выборкеX = (X1,X2,...,X n) опре-
делить распределение генеральной совокупностиξ. Критерий Колмогорова и
позволяет это сделать в случае, когда функция распределения генеральной
совокупности непрерывна.
ПустьX = ( X1,X2,...,X n) – выборка из некоторого распределения
P. Проверяется гипотезаH1 = {P = P1}против сложной альтернативы
H2 = {P̸= P1}. Если предполагаемое распределениеP1 имеет непрерывную
функцию распределенияF1, то удобно пользоваться так называемым крите-
рием Колмогорова. Рассмотрим функцию отклонения
ρ(X) =√nsup
t
|F∗
n(t) −F1(t)|,
гдеF∗
n, как обычно, эмпирическая функция распределения, построенная по
выборкеX.
Покажем, что введенная функция удовлетворяет описанным выше усло-
виям, но для начала напомним теорему Колмогорова.
Теорема 2.2.1 (Колмогорова)ПустьX1,...,X n – выборка из генеральной
совокупностиξ с непрерывной функцией распределенияFξ. Тогда для эмпи-
рической функция распределенияF∗
n(t) выполняется
Yn = √n·sup
t∈R
|F∗
n(t) −Fξ(t)|
d
−−−−→
n→+∞
Y,
где случайная величинаY имеет распределение Колмогорова с функцией рас-
9
пределения
FY(t) =



+∞∑
i=−∞
(−1)ie−2i2t2
, t ≥0
0, t< 0
.
Итак, проведем проверку по пунктам. Пустьρ(X) = √nsup
t
|F∗
n(t) −F1(t)|,
тогда
•ЕслиH1 верна, то всеXi имеют распределениеP1, а тогда, по теореме
Колмогорова,ρ(X) по распределению сходится к случайной величине,
имеющей распределение Колмогорова.
•ЕслиH1 неверна, то все случайные величиныXi имеют некоторое рас-
пределениеP2, отличное отP1. Значит, согласно теореме Гливенко-
Кантелли,
F∗
n
P
−−−−→
n→+∞
F2
для каждогоy ∈R. Но так какP1 ̸= P2, то найдетсяt0, чтоF1(t0) ̸=
F2(t0), а значит
sup
t∈R
|F∗
n(t) −F1(t)|≥| F∗
n(t0) −F1(t0)|
P
−−−−→
n→+∞
|F2(t0) −F1(t0)|>0.
Но тогда
ρ(X) =√nsup
t∈R
|F∗
n(t) −F1(t)|
P
−−−−→
n→+∞
∞.
Как же осуществляется проверка гипотез? Пусть случайная величинаY име-
ет распределение с функцией распределения Колмогорова. Это распределе-
ние табулировано (таблицу можно найти в дополнительных материалах), так
что по заданномуε >0 легко найти такоеC, чтоε = P(Y ≥C), а тогда
Критерий Колмогорова выглядит так:
δ(X) =
{
H1, ρ(X) <C
H2, ρ(X) ≥C .
Пример применения критерия на конкретных данных с пошаговым алгорит-
мам приведен в опросе к данному фрагменту.
Кроме критерия Колмогорова, часто используют критерийχ2 Пирсона
как для проверки параметрической, так и непараметрической гипотез. Для
ознакомлением с этим критерием мы отправляем заинтересованного слуша-
теля к дополнительным материалам.
10
2.3 Проверка гипотезы однородности
Как мы не раз отмечали, часто, особенно при сборе данных, полезно
понимать: берутся ли данные из одного и того же распределения, или нет.
Скажем, подчиняется ли рост членов баскетбольной команды и рост детей в
детском саду одному и тому же распределению? Вероятно, нет, скажете вы.
Но ответ на поставленный вопрос не всегда так очевиден.
Итак, пусть даны две выборкиX = (X1,X2,...,X n) иY = (Y1,Y2,...,Y m)
из неизвестных распределенийPиG, соответственно. Будем проверять слож-
ную гипотезуH1 = {P= G}против альтернативыH2 = {H1 неверна}. Пред-
положим также, что распределенияPиGимеют непрерывные функции рас-
пределения.
Оказывается, что, по аналогии с критерием Колмогорова, резонно рас-
смотреть функцию отклонения вида
ρ(X,Y ) =
√ mn
m+ nsup
t∈R
|F∗
n(t) −G∗
m(t)|,
где функцияF∗
n(t) – эмпирическая функция распределения, построенная по
выборкеX, аG∗
m(t) – эмпирическая функция распределения, построенная по
выборкеY.
Оказывается справедливой следующая теорема
Теорема 2.3.1Если гипотезаH1 верна, то
ρ(X,Y )
d
−−−−−→
m,n→+∞
Y,
где случайная величинаY имеет распределение Колмогорова.
Аналогично предыдущему пункту, про данномуε найдем такоеC, что
ε= P(Y ≥C), тогда критерий Колмогорова-Смирнова имеет вид:
δ(X,Y ) =
{
H1, ρ(X,Y ) <C
H2, ρ(X,Y ) ≥C .
Пример применения критерия на конкретных данных с пошаговым алгорит-
мам приведен в опросе к данному фрагменту.
2.4 Гипотезы о нормальном распределении
Одно из самых важных распределений – нормальное распределение. Да-
вайте рассмотрим некоторые гипотезы (и, конечно, методы их проверки), ка-
сающиеся его параметров.
11
2.4.1 Совпадение средних двух нормальных выборок с равными
дисперсиями
Итак, пусть есть две независимые выборкиX = (X1,X2,...,X n) из рас-
пределенияNa1,σ2 и Y = (Y1,Y2,...,Y m) из распределенияNa2,σ2 , причем дис-
персияσ2 одинакова для обоих распределений, но, вообще говоря, неизвестна.
Особенно часто возникает необходимость проверить равенство средних двух
независимых выборок из нормальных распределений в медицине для выясне-
ния наличия или отсутствия действия препарата. Ясно, что данная задача –
частный случай задачи проверки однородности двух выборок. Оказывается,
что в случае, если дисперсии различны, то задача решается лишь в частных
случаях, о которых мы говорить не будем.
Итак, мы будем проверять гипотезуH1 = {a1 = a2}, используя случай-
ную величину
tn+m−2 =
√ nm
n+ m·
(
X−a1
)
−
(
Y −a2
)
√
(n−1)S2
0 (X)+(m−1)S2
0 (Y)
n+m−2
,
гдеS2
0 (X) – несмещенная выборочная дисперсия, пстроенная по выборкеX,
аS2
0 (Y) – по выборкеY.
Оказывается, справедлива следующая теорема.
Теорема 2.4.1Случайная величинаtn+m−2 имеет распределению Стью-
дентаTn+m−2 с(n+ m−2) степенями свободы.
Если гипотезаH1 верна, то резонно рассмотреть функцию отклонения
ρ(X,Y ) =
√ nm
n+ m· X−Y√
(n−1)S2
0 (X)+(m−1)S2
0 (Y)
n+m−2
,
которая, по только что сформулированной теореме имеет распределение
СтьюдентаTn+m−2, а значит критерий имеет смысл строить следующим об-
разом.
По заданномуε, найдем квантильC = τ1−ε/2 – (1 −ε/2) квантиль рас-
пределения СтьюдентаTn+m−2. Для такой квантили
P(|tn+m−2|>C ) =ε
и критерий Стьюдента имеет такой же вид, как и критерии согласия:
δ(X,Y ) =
{
H1, |ρ(X,Y )|<C
H2, |ρ(X,Y )|≥ C.
Пример применения критерия на конкретных данных с пошаговым алгорит-
мам приведен в опросе к данному фрагменту.
12
2.4.2 Совпадение дисперсий двух нормальных выборок
Естественно, даже если известно, что выборки получены из нормального
распределения, зачастую совершенно неизвестно: одинаковы у них дисперсии
или нет, и непонятно: можно ли применять только что описанный критерий
Стьюдента, или нет. Для проверки этого факта часто применяют так назы-
ваемый критерий Фишера.
Итак, пусть есть две независимые выборкиX = (X1,X2,...,X n) из рас-
пределенияNa1,σ2
1
и Y = (Y1,Y2,...,Y m) из распределенияNa2,σ2
2
. Проверяется
гипотезаH1 = {σ2
1 = σ2
2}.
Зададим функцию отклонения следующим образом:
ρ(X,Y ) =S2
0 (X)
S2
0 (Y)
Справедлива следующая теорема.
Теорема 2.4.2Если гипотезаH1 верна, тоρ(X,Y ) имеет распределение
ФишераFn−1,m−1 с(n−1,m −1) степенями свободы.
Справку о распределении Фишера можно найти в дополнительных материа-
лах.
Построим критерий Фишера. Пустьfε/2 иf1−ε/2 – соответсвующие кван-
тили распределения ФишераFn−1,m−1. Тогда критерий таков:
δ(X,Y ) =
{
H1, fε/2 ≤ρ(X,Y ) ≤f1−ε/2,
H2, иначе .
Пример применения критерия на конкретных данных с пошаговым алгорит-
мам приведен в опросе к данному фрагменту.
2.4.3 Гипотеза о среднем нормальной совокупности с известной
дисперсией
Пусть имеется выборка из нормального распределенияNa,σ2 с известной
дисперсиейσ2. Проверяется простая гипотезаH1 = {a= a0}против сложной
альтернативыH2 = {a̸= a0}.
Рассмотрим функцию отклонения
ρ(X) =√nX−a0
σ .
Ясно, что если гипотезаH1 верна, тоρ(X) имеет стандартное нормальное
распределение. Пустьε >0, тогда выберемC = τ1−ε/2 – квантиль уровня
13
(1 −ε/2) стандартного нормального распределения, а тогда
ε= PH1 (|ρ(X)|≥ C)
и критерий, как и все критерии согласия, выглядит так:
δ(X) =
{
H1, |ρ(X)|<C
H2, |ρ(X)|≥ C.
Пример применения критерия на конкретных данных с пошаговым алгорит-
мам приведен в опросе к данному фрагменту.
2.4.4 Гипотеза о среднем нормальной совокупности с неизвестной
дисперсией
Пусть теперь имеется выборка из нормального распределенияNa,σ2 с
неизвестной дисперсиейσ2. Проверяется простая гипотезаH1 = {a = a0}
против сложной альтернативыH2 = {a̸= a0}.
Рассмотрим функцию отклонения
ρ(X) =√nX−a0
S0(X) .
Ясно, что если гипотезаH1 верна, тоρ(X) имеет распределение Стьюдента
Tn−1. Пустьε >0, тогда выберемC = τ1−ε/2 – квантиль уровня(1 −ε/2)
распределенияTn−1, тогда
ε= PH1 (|ρ(X)|≥ C)
и критерий, как и все критерии согласия, выглядит так:
δ(X) =
{
H1, |ρ(X)|<C
H2, |ρ(X)|≥ C.
Пример применения критерия на конкретных данных с пошаговым алгорит-
мам приведен в опросе к данному фрагменту.
2.5 Резюме
Итак, в этой лекции мы рассмотрели лишь некоторые подходы к провер-
ке гипотез, и на этом наш курс подошел к концу. Можно еще много говорить
и про многомерные выборки (которых в нашем курсе мы не коснулись), и про
сравнение критериев, и про сравнение оценок: аппарат статистики очень бо-
гат и обширен. Все это, конечно, невозможно запихнуть в семестровый курс.
Но мы надеемся, что полученных в этом курсе базовых знаний, умений и
навыков хватит для освоения и тех специфических методов, которые исполь-
зуются в конкретно вашей предметной области. Удачи и до новых встреч!
14
