Содержание
1 Описательная статистика 2
1.1 Выборка и генеральная совокупность . . . . . . . . . . . . . . . 3
1.2 Эмпирическое распределение . . . . . . . . . . . . . . . . . . . . 4
1.3 Выборочные моменты . . . . . . . . . . . . . . . . . . . . . . . . 6
1.4 Медиана. Выборочная медиана. . . . . . . . . . . . . . . . . . . 10
1.5 Гистограмма, как оценка плотности . . . . . . . . . . . . . . . . 13
1.6 Многомерная выборка. Выборочная корреляция . . . . . . . . . 14
2 Оценивание параметров вероятностной модели 17
2.1 Наводящий пример . . . . . . . . . . . . . . . . . . . . . . . . . . 17
2.2 Оценки параметров некоторых стандартных распределений . . . 18
3 Закон больших чисел и свойства оценок 23
3.1 А что вообще такое оценка? . . . . . . . . . . . . . . . . . . . . . 23
3.2 Сходимость по вероятности и состоятельность . . . . . . . . . . 24
3.3 Закон больших чисел . . . . . . . . . . . . . . . . . . . . . . . . 25
3.4 Несмещенность оценок . . . . . . . . . . . . . . . . . . . . . . . . 27
4 Резюме 28
1 Описательная статистика
Здравствуйте, уважаемые слушатели. В предыдущих двух лекциях мы
познакомились с моделями реальных случайных явлений и процессов, кото-
рые могут быть изучены с помощью теории вероятностей, а также способами
их построения. Резюмируя, наверное можно сказать, что основная задача тео-
рии вероятностей – это прогноз, а именно: по построенной модели определить
вероятность интересующего события; распределение той или иной случайной
величины, системы случайных величин, их характеристики; распределение
процесса случайных величин, изменяющегося во времени и проч. Вроде бы в
теории все хорошо, не так ли? А на практике?
На практике нас часто ждет неизвестность, ведь обычно в результате
эксперимента мы наблюдаем только проявления некоторой закономерности, а
сама закономерность (или вероятностная модель этой закономерности) оста-
ется неизвестной. Так, мы можем измерить рост каждого ребенка в конкрет-
ной группе детского сада или в конкретно взятой волейбольной команде; мы
можем получить данные об изменении курса доллара за последний год, по-
смотрев банковские сводки; можем узнать статистику забитых голов неко-
торой команды на нескольких последних чемпионатах мира. Зачем? Какую
цель мы при этом преследуем?
Часто оказывается, что наша цель – получение каких-то сведений о (на
данный момент) неизвестном будущем. Так, рост детей в группе детского са-
да (то есть детей конкретного возраста) может помочь нам в выборе мебели:
ведь если взять чересчур высокие столы, то дети просто не смогут до них
дотянуться и за ними обедать, а если чересчур высокие стулья – не смогут
на них забраться. Анализируя изменение курса доллара, мы, конечно, хо-
тим знать: когда выгодно купить валюту, а когда продать, и цель этого ясна
– мы хотим получить максимальную прибыль. Статистика голов любимой
команды может помочь нам выиграть дружеский спор об исходе матча на
следующем чемпионате мира, и так далее.
На чем основаны наши надежды и ожидания при изучении прошлого?
Конечно, на каком-то повторении, на наличии закономерности, на том, что
в рассматриваемых ситуациях что-то да предопределено, на принципе: /guillemotleft.cyrесли
проводить эксперимент в одинаковых условиях, то и результат должен быть
одинаков/guillemotright.cyr, так хорошо известном из физики. Иными словами, мы надеемся,
что рассматриваемые случайные события подчиняются какой-то вероятност-
ной закономерности, которую мы, правда, не знаем. Но вот если узнаем, то
сразу сможем очень многое, ведь аппарат теории вероятностей изучен: мы
сможем вычислять вероятности тех или иных событий, сравнивать их, вы-
числять характеристики вроде среднего, разброса и многое-многое другое,
короче говоря, мы сможем прогнозировать и анализировать.
2
Выявление этих закономерностей (или отсутствия оных, что тоже очень
ценно), – и есть одна из основных задач математической статистики. Изуче-
нием различных методов математической статистики мы и займемся в сле-
дующих лекциях.
1.1 Выборка и генеральная совокупность
Давайте начнем, наверное, с самой непростой ситуации, которую мы уже
описали ранее, с ситуации, когда практически ничего неизвестно. Итак, у нас
есть некоторый набор собранных данных и больше ничего. Что мы можем
сделать, как это интерпретировать и толковать? Давайте начнем с такого
вот примера.
Пример 1.1.1Молодой человек Петя собрал данные о времени (в мину-
тах), на которое его девушка Даша опаздывала на свиданиях. Данные пред-
ставлены набором чисел через запятую (в виде числового вектора) и для
краткости обозначеныX:
X = (0,11,2,3,9,2,8,6,3.4,8,7.5,9,4,8,6).
Петя предполагает, что опоздания Даши хоть и носят случайных харак-
тер, но описываются какой-то случайной величинойξ, имеющей какое-то
неизвестное нам распределение.
Что же у нас есть? Согласно тому, что мы уже обсуждали в предыдущей
лекции, можно сказать, что перед нами не что иное, как выборка из некото-
рой генеральной совокупностиξ. Основная же цель Пети – это, по имеющейся
выборкеX понять, как ведет себя генеральная совокупностьξ, а затем на-
учиться прогнозировать и делать какие-то выводы об опозданиях Даши.
Напомним, что в прошлой лекции мы под выборкой понимали набор изn
чиселX = (x1,x2,...,x n). В нашем примере выборка состоит из15 элементов,
а Петя собрал данные, представленные в выборке, побывав на15 свиданиях с
Дашей. Но если бы он /guillemotleft.cyrобнулил счетчик/guillemotright.cyr и начал бы собирать данные заново,
то получил бы, скорее всего, другую выборку, хотя Даша-то не изменилась.
И как тут строить какую-то статистику, данные же все время меняются.
Дело в том, что ранее введенное нами определение выборки – это так
называемая выборка /guillemotleft.cyrпосле эксперимента/guillemotright.cyr. На самом же деле, чтобы строить
какую-то статистику, разумно принять и вот какое определение выборки.
Определение 1.1.1Пусть ξ – рассматриваемая нами случайная величи-
на. ВыборкойX = ( X1,X2,...,X n) называетсяn независимых случайных
величин, имеющих распределение такое же, как иξ.
Итак, говоря про выборку до конкретного эксперимента, мы будем по-
нимать под ней набор независимых случайных величин и обозначать, как
3
X = ( X1,X2,...,X n). Если же эксперимент произошел и перед нами набор
конкретных значений генеральной совокупности, то под выборкой мы будем
понимать числовой векторX = ( x1,x2,...,x n). В дальнейшем мы не будем
конкретизировать то, что мы понимаем под выборкой (числовой вектор или
вектор из случайных величин), это должно будет быть понятно из контекста.
1.2 Эмпирическое распределение
Итак, наша цель – узнать что-то о генеральной совокупностиξ. Разξ
– случайная величина, то, наверное, логично построить по выборке тоже
какую-то случайную величину, распределение которой и будет /guillemotleft.cyrприближать/guillemotright.cyr
истинное распределениеξ (а значит и будет приближать ее различные ха-
рактеристики, как математическое ожидание, дисперсию и прочее). Мы уже
подробно обсуждали в прошлой лекции, что хороший кандидат на роль /guillemotleft.cyrпри-
ближения/guillemotright.cyr – так называемая эмпирическая (то есть /guillemotleft.cyrопытная/guillemotright.cyr) случайная
величинаξ∗. Для удобства сейчас, и для приложений чуть позже, введем
следующее важное определение.
Определение 1.2.1Пусть имеется выборкаX = ( X1,X2,...,X n). Если
элементы выборки упорядочить по возрастанию, то новый набор случай-
ных величин, удовлетворяющий неравенствам
X(1) ≤X(2) ≤...≤X(n),
называется вариационным рядом.
Понятно, что, например,X(1) = min {X1,...,X n}, X(n) = max {X1,...,X n}.
Кроме того отметим, чтоk-ый член вариационного ряда часто называютk-
ой порядковой статистикой.
Сразу вернемся к нашему примеру. По выборке опозданий Даши легко
строится следующий вариационный ряд:
(0,2,2,3,3.4,4,6,6,7.5,8,8,8,9,9,11).
Вариационный ряд хорошо визуализирует небольшое количество данных и
уже дает нам какую-то /guillemotleft.cyrстатистику/guillemotright.cyr, ведь можно сразу сделать вывод, что
не опоздала Даша всего раз, дважды опоздала на две минуты, один раз на
три ну и так далее.
Не нужно думать, что вариационный ряд по конкретной выборке стро-
ится руками. Для этого в каждом инструменте, используемом при работе
с данными, есть функция упорядочивания. Например, вExcel для этого во
вкладке Данные реализована функция сортировки.
Имея вариационный ряд, удобно строить эмпирическое распределение
случайной величиныξ∗. Группируя одинаковые значения и приписывая им
4
вероятности, пропорциональные частоте встречи значения в выборке, полу-
чаем
ξ∗ 0 2 3 3.4 4 6 7.5 8 9 11
P 1
15
2
15
1
15
1
15
1
15
2
15
1
15
3
15
2
15
1
15
.
Эмпирическое распределение нам дает очень многое. Например, зная
эмпирическое распределение случайной величиныξ∗, можно построить эм-
пирическую функцию распределения – функцию распределенияξ∗. В нашем
случае она задается соотноешнием
F∗
n(t) =



0, t ≤0
1/15, 0 <t ≤2,
3/15, 2 <t ≤3,
4/15, 3 <t ≤3.4,
... ...,
14/15, 9 <t ≤11,
1, t> 11,
,
а ее график представлен на рисунке 1.
Рис. 1: Эмпирическая функция распределения, построенная по выборке
Теперь можно проводить какие-то элементарные оценки и предсказания.
Скажем, как оценить вероятность события, что купленные для Даши круас-
сан и стаканчик кофе не остынут? Иными словами, на языке вероятностей,
5
какова вероятность события, что девушка опоздает не более, чем на5 минут?
Это мы умеем вычислять:
P(ξ∗≤5) = F∗
n(5 + 0) = 6
15 = 0.4,
что, кстати, не так уж и много: надежнее, быть может, купить букет цветов,
чтобы уж точно порадовать подругу, ну или прихватить с собой термосумку.
Часто, однако, бывает достаточно оценить какие-то глобальные характе-
ристики генеральной совокупностиξ ( еще называемые мерами центральной
тенденции ) такие, как математическое ожиданиеEξ, дисперсиюDξ, средне-
квадратическое отклонениеσξ и так далее. Давайте научимся это делать.
1.3 Выборочные моменты
Итак, логично считать, что если распределение эмпирической случай-
ной величиныξ∗ приближает истинное распределение генеральной совокуп-
ностиξ, то и математическое ожидание, дисперсия и прочие характеристики
эмпирической случайной величины являются хорошими аналогами тех же
характеристик, но уже генеральной совокупности.
Так как в общем случае распределениеξ∗ задается таблицей
ξ∗ X1 X2 X3 ... Xn
P 1
n
1
n
1
n ... 1
n
,
где значение каждого элемента выборки равновероятно (снова, так как мы
не отдаем ни одному из них какого-либо предпочтения), то
Eξ∗= X1 ·1
n+ X2 ·1
n+ X3 ·1
n+ ...+ Xn ·1
n = X1 + X2 + X3 + ...+ Xn
n .
Что мы получили? А то, что математическое ожидание построенной слу-
чайной величины есть не что иное, как среднее арифметическое элементов
выборки. Именно поэтому эту характеристику даже назвали по-особому.
Определение 1.3.1Пусть дана выборкаX = ( X1,X2,...,X n). Величину,
равную среднему арифметическому элементов выборки, называют выбороч-
ным средним и обозначаютX. Иными словами,
X = X1 + X2 + ...+ Xn
n = 1
n
n∑
i=1
Xi.
Итак, еще раз, какой смысл несет в себе выборочное среднееX? Так как
распределениеξ∗приближает истинное распределениеξ, то и математическое
ожиданиеEξ∗ (которое и есть выборочное среднееX) приближает истинное
6
математическое ожиданиеEξ. Последнее же несет в себе простой смысл: это
среднее вероятностное значение случайной величиныξ.
Вернемся к примеру с опозданиями Даши. Выборочное среднее вычис-
ляется, как
X = 0 + 11 + 2 + 3 + 9 + 2 + 8 + 6 + 3.4 + 8 + 7.5 + 9 + 4 + 8 + 6
15 ≈5.793.
Что это значит? Это значит, что в среднем Пете приходится ждать Дашу
почти что6 минут. На рисунке 2 синие точки – это элементы выборки. Крас-
ная точка отвечает выборочному среднемуX. Видно, что красная точка не
совпадает ни с одним элементом выборки, но и правда располагается где-то
посередине.
Рис. 2: ВыборкаX и ее среднееX
Не нужно думать, что выборочное среднее нужно вычислять вручную.
В том же Excel есть функция СРЗНАЧ, аргументом которой являются те
числовые данные, среднее которых нужно вычислить.
По аналогичным причинам, дисперсия эмпирической случайной величи-
ны ξ∗ должна неплохо приближать истинную дисперсиюDξ. Согласно опре-
делению дисперсии и используя то, чтоEξ∗= X, получаем
Dξ∗= E (ξ∗−Eξ∗)2 = 1
n
n∑
i=1
(
Xi −X
)2
.
Дисперсию эмпирической случайной величины тоже выделяют особо.
7
Определение 1.3.2Пусть дана выборкаX = ( X1,X2,...,X n). Величину,
равную дисперсииDξ∗ эмпирической случайной величныξ∗, построенной по
выборкеX, называют выборочной дисперсией и обозначаютS2. Иными сло-
вами,
S2 = 1
n
n∑
i=1
(
Xi −X
)2
.
Обратим внимание на смысл выборочной дисперсииS2? Так как рас-
пределениеξ∗ приближает истинное распределениеξ, то и дисперсияDξ∗
(которая и есть выборочная дисперсияS2) приближает истинную дисперсию
Dξ. Последняя же несет в себе простой смысл: это средний квадрат разброса
значений случайной величиныξ от ее математического ожиданияEξ.
Рассмотрим все ту же выборку
X = (0,11,2,3,9,2,8,6,3.4,8,7.5,9,4,8,6).
Давайте посмотрим, насколько сильно отличаются в среднем опоздания Да-
ши. Легко понять, чтоS2 ≈9.625. На рисунке 3 элементы выборки изобра-
жены синими точками, красная точка – выборочное среднее, а красная линия
между зелеными точками показывает интервал
(
X−S,X+ S
)
.
Что такоеS? Это величина среднего разброса значений эмпирической слу-
чайной величины от среднего. Ее разумно рассматривать, как оценку сред-
неквадратического отклоненияσξ случайной величиныξ.
В нашем случае, как легко понять,S ≈3.1, так что разброс от средне-
го, равного, примерно,5.8, достаточно велик. Какой отсюда можно сделать
вывод? А такой, что Пете самому не стоит опаздывать больше, чем на где-то
две минуты, так как опоздания Даши носят весьма /guillemotleft.cyrразный/guillemotright.cyr характер, и он
может опоздать больше, чем она. Ну а если Даша опаздывает больше, чем
на9 минут, то можно начинать волноваться.
Замечание 1.3.1Отметим, что в статистике часто используется не
только введенная выше выборочная дисперсияS2, но и так называе-
мая несмещенная выборочная дисперсияS2
0, которая по выборкеX =
(X1,X2,...,X n) определяется, как
S2
0 = 1
n−1
n∑
i=1
(
Xi −X
)2
.
8
Рис. 3: ВыборкаX, ее выборочное среднееX и S
Несмещенная выборочная дисперсияS2
0 алгебраически отличается от вы-
борочной дисперсииS2 сомножителем перед суммой:1
n меняется на 1
n−1.
Благодаря этому наблюдению легко видеть, что
S2
0 = n
n−1S2
и, так как приn→+∞
lim
n→+∞
n
n−1 = 1,
то при больших объемах выборкиS2
0 и S2 практически не отличаются и
могут использоваться равноправно. На малых же объемах выборки пред-
почтительнее использоватьS2
0, так как она точнее. Почему это так, а
также что означает несмещенность, мы узнаем несколько позже.
В нашем примереS2
0 ≈10.312 и видно, что это значение достаточно сильно
(почти на0.8) отличается отS2.
Ровно по тем же соображениям, по которым при большихn оценкуS2
0
можно считать разумной оценкой дисперсии генеральной совокупностиξ, ве-
личинуS0 можно считать разумной оценкой среднеквадратического откло-
ненияσξ. В нашем случаеS0 ≈3.21.
Пример 1.3.1Рассмотрим еще один пример, иллюстрирующий отличие
S2 иS2
0 на синтетических выборках из генеральной совокупности, имеющей
известную дисперсию, равную9 (рисунок 4).
9
Рис. 4: СравнениеS2 и S2
0
Как можно видеть, на малых объемах выборки несмещенная дисперсия
S2
0 оказывается в среднем ближе к истинному значению дисперсии. Однако,
с ростом количества элементов выборки, различия междуS2 и S2
0 стано-
вятся все меньше и точки практически сливаются.
Выборочная дисперсия, как и многие другие характеристики, /guillemotleft.cyrвшиты/guillemotright.cyr в
большинствопакетовдляанализаданных.ВExcel естьфункцияДИСП.Гили
ДИСПРА, аргументом которой являются те числовые данные, выборочную
дисперсиюS2 которых нужно вычислить. Обратите внимание, что похожие
функции ДИСП.В и ДИСПА выдают несмещенную выборочную дисперсию
S2
0.
1.4 Медиана. Выборочная медиана.
Сейчас нам придется немного отключиться от статистики, и совсем нена-
долго окунуться в вероятностный аппарат, а именно – изучить еще одну веро-
ятностную характеристику случайной величины, называемую медианой. Да-
вайте сначала дадим строгое определение новому для нас понятию, а потом
поясним ее смысл, а также сравним с математическим ожиданием.
Определение 1.4.1Числоmed ξ называется медианой случайной величи-
ны ξ, если
P(ξ ≤med ξ) ≥1
2 и P(ξ ≥med ξ) ≥1
2.
10
По сути своей медиана – это такое число, что случайная величина как мини-
мум с вероятностью1
2 не больше и не меньше нее. Похоже на математическое
ожидание, не так ли? На самом деле не все так просто. Например оказы-
вается, что медиана всегда существует, но не всегда является единственной.
Почему? Давайте подумаем и проиллюстрируем это таким простым приме-
ром.
Пример 1.4.1Пусть эксперимент заключается в подбрасывании правиль-
ной монеты. Тогда распределение случайной величиныξ, дающей единицу,
если выпал орел, и ноль, если решка, задается следующей таблицей
ξ 0 1
P 1
2
1
2
.
Ясно, что любое числоmed ξ из диапазона[0,1] служит медианой случай-
ной величиныξ, ведь
P(ξ ≤med ξ) ≥1
2 и P(ξ ≥med ξ) ≥1
2.
Почему так случилось? Потому, что в данном случае исходы равновозможны
и медиана, грубо говоря, /guillemotleft.cyrне понимает/guillemotright.cyr, что выбрать.
А чему в данном случае равно математическое ожидание? Легко прове-
рить, что оно равно
Eξ = 0 ·1
2 + 1 ·1
2 = 1
2.
Чаще всего, если медиана не единственна (а значит этих медиан сразу целый
отрезок), то в качестве медианы берут середину получившегося отрезка. В
нашем случаеmed ξ совпадает с математическим ожиданием и равна1
2. Так
бывает не всегда.
Пример 1.4.2Рассмотрим такой простой пример. Предположим, что
имеется некоторая фирма, в которой работает100 человек, один из ко-
торых начальник. Заработная плата начальника равна101000 долларов в
месяц, а заработная плата каждого работника равна1000 долларов в месяц.
Пусть случайная величинаξ (или генеральная совокупность) – зарплата
работника, тогда эмпирическое распределение, построенное по данной нам
выборке, может быть задано, как
ξ∗ 1000 101000
P 99
100
1
100
Легко понять, что математическое ожидание случайной величиныξ∗ рав-
но
Eξ∗= 1000 · 99
100 + 101000 · 1
100 = 2000,
11
то есть средняя зарплата равна2000 долларов в месяц. В то же время,
медианаmed ξ∗ равна1000 и медианная зарплата равна1000.
Ясно, что в этом примере гораздо более /guillemotleft.cyrчестной/guillemotright.cyr оценкой средней
зарплаты является медиана, нежели математическое ожидание, из-за
такого сильного выброса в заработной плате начальника.
Итак,сновамысленноповторяяаргументы,приводимыенамиранее,ска-
жем, что медианаmed ξ∗ должна хорошо приближать истинную медиану
med ξ, а потому примем следующее определение.
Определение 1.4.2Пусть дана выборкаX = (X1,X2,...,X n). Выборочной
медианойˆmed ξ генеральной совокупностиξ называется медиана выбороч-
ной случайной величины, то есть
ˆmed ξ = med ξ∗.
Имея выборкуX = (X1,X2,...,X n), и построенный по ней вариационный ряд
X(1) ≤X(2) ≤...≤X(n),
выборочная медиана легко может быть найдена из соотношений
ˆmed ξ =
{
X([n/2]+1), n нечетно,
X([n/2])+X([n/2]+1)
2 , n четно,
где[x] обозначают целую часть отx. Например,[2.7] = 2, [4.2] = 4.
А как найти медиану по выборке (или по вариационному пряду)? По
вариационному ряду выборочная медиана ищется следующим образом. Она
равна серединному элементу вариационного ряда, если он определен одно-
значно (то есть еслиn нечетно), и полусумме серединных элементов, еслиn
четно.
Возвращаясь к примеру с опозданиями Даши получим, что, согласно
вариационному ряду
(0,2,2,3,3.4,4,6,6,7.5,8,8,8,9,9,11),
выборочная медиана равнаX([15/2]+1) = X(8) = 6 . Это значит, что Даша с
/guillemotleft.cyrодинаковыми/guillemotright.cyr (в нашем приближении) вероятностями опаздывает как ме-
нее, чем на6 минут, так и более. Напомним, что выборочное среднееX было
равно примерно5.8, так что в нашем примере полученные параметры близ-
ки, а значит предполагаемое распределение генеральной совокупностиξ до-
статочно симметрично относительно как математического ожидания, так и
близкой к нему медианы.
12
Еще раз особо отметим, что медиана, по сравнению с выборочным сред-
ним, устойчива к выбросам. Предположим, что Петя случайно отвлекся и
приписал лишний ноль к очередному измерению, тем самым вместо5 минут-
ного опоздания записал значение в50 минут. Тогда новый вариационный ряд
будет содержать уже16 членов:
(0,2,2,3,3.4,4,6,6,7.5,8,8,8,9,9,11,50),
а выборочное среднееX окажется примерно равнымX = 8.566 и будет отли-
чаться от предыдущего значения примерно на2.8. А вот новая выборочная
медианаˆmed ξ будет равнаˆmed ξ = 6.75 и отличается от предыдущего зна-
чения всего на0.75.
Замечание 1.4.1Выбросы в данных, как показывает практика, – это до-
статочно частое явление. Иногда может барахлить прибор, записываю-
щий измерения, могут возникать редкие аномалии (как невнимательность
Пети), влияющие на эксперимент. Все это портит прогнозы, если появ-
ляется с заядлой периодичностью, потому устойчивые (или робастные)
оценки характеристик оказываются очень полезными.
Теперь что касается конкретного счета. Большинство пакетов анализа
данных умеют вычислять медиану. ВExcel это может быть сделано посред-
ством функции МЕДИАНА, аргументом которой выступает вся выборка.
1.5 Гистограмма, как оценка плотности
Напомним, что наша цель – узнать что-то о генеральной совокупности
ξ. При этом случайная величинаξ может быть и непрерывной. А что очень
хотелось бы знать о непрерывной случайной величине? Ну, наверное, ее плот-
ность. Эмпирическим аналогом плотности является так называемая гисто-
грамма.
Гистограмма строится достаточно просто. На первом этапе определяется
множество значений выборки. Используя вариационный ряд, это множество
значений будет отрезком
A= [X(1),X(n)].
Далее этот отрезок делят на некоторое количество непересекающихся отрез-
ков, интервалов, полуинтервалов. Затем подсчитывают количество значений,
попавших в каждый такой промежуток.
ПустьA1,...,A k –этиотрезки,одинаковойдлиныl.Пустьνj –количество
элементов выборки, попавших в отрезокAj, n =
k∑
j=1
νj. Заменим истинную
13
плотность на промежуткеAj длиныl прямоугольником высотыhj = νj
nl. За-
метим, что сумма площадей всех прямоугольников равна1, а это значит, что
полученная неотрицательная функция может трактоваться, как плотность
распределения некоторой случайной величины. Действительно, площадьSj
j-ого прямоугольника равна
Sj = hj ·l= νj
nl ·l= νj
n,
а тогда суммарная площадь построенных прямоугольников равна
k∑
j=1
Sj =
k∑
j=1
νj
n = 1
n
k∑
j=1
νj = 1.
Таким образом построенная ступенчатая фигура, являющаяся объединением
прямоугольников, называется гистограммой.
Пример 1.5.1Снова рассмотрим выборку, собранную Петей, из нашего
примера. Напомним, что вариационный ряд имеет вид
(0,2,2,3,3.4,4,6,6,7.5,8,8,8,9,9,11).
Разобьем для начала отрезок[0,11] наn= 4 части одинаковой длины (l =
2.75), тем самым получим множества
A1 = [0,2.75), A2 = [2.75,5.5), A3 = [5.5,8.25), A4 = [8.25,11].
В множествоA1 попадает 3 элемента выборки, значитν1 = 3. Аналогич-
ными рассуждениями получаем, чтоν2 = 3, ν3 = 6, ν4 = 3. Гистограмма,
отвечающая такому разбиению, представлена на рисунке 5. Если взять
n= 5, то картина меняется, см. рисунок 6.
Замечание 1.5.1Большинство пакетов по обработке данных поддержи-
вают построение гистограмм. В частности вExcel это можно сделать
при помощи пакета анализа данных или посредством встроенной функции
ЧАСТОТА().
1.6 Многомерная выборка. Выборочная корре-
ляция
Предположим теперь, что мы наблюдаем не одну, а несколько случай-
ных величин. Эта ситуация не менее жизненна, чем те, что мы рассматривали
ранее. Один из самых интересных вопросов – есть ли какая-то зависимость
14
Рис. 5: Гистограмма приn= 4
Рис. 6: Гистограмма приn= 5
между наблюдаемыми значениями выборки? Как мы знаем, индикатором за-
висимости в теории вероятностей выступают ковариация и коэффициент кор-
реляции. Давайте определим их выборочные аналоги, но для начала введем
понятие многомерной выборки.
15
Итак, пусть генеральная совокупность – это случайный вектор⃗ξ =
(ξ1,ξ2), состоящий из двух компонент (для простоты). Тогда, аналогично то-
му, как было сделано в одномерном случае, резонно ввести следующее опре-
деление.
Определение 1.6.1Двумерной выборкой (X,Y ) =
((X1,Y1),(X2,Y2),..., (Xn,Yn)) объемаn называется набор изn незави-
симых одинаково распределенных пар случайных величин(Xi,Yi), каждая
из которых имеет такое же совместное распределение, как и пара
⃗ξ = (ξ1,ξ2).
Напомним, что так как ковариация двух случайных величинξ1 и ξ2 опреде-
ляется, как
cov(ξ1,ξ2) = E(ξ1 −Eξ1)(ξ2 −Eξ2) = E(ξ1ξ2) −Eξ1Eξ2,
то логично принять следующее определение.
Определение 1.6.2Выборочной ковариацией, построенной по выборке
(X,Y ) = ((X1,Y1),(X2,Y2),..., (Xn,Yn)), называется
k(X,Y ) = 1
n
n∑
i=1
(Xi −X)(Yi −Y).
Часто вводят в рассмотрение и несмещенную выборочную ковариацию, кото-
рая определяется из соотношения
k0(X,Y ) = 1
n−1
n∑
i=1
(Xi −X)(Yi −Y).
Мотивировка для рассмотрения несмещенной выборочной ковариации ничем
не отличается от мотивировки для рассмотрения несмещенной выборочной
дисперсии: при большихnони ведут себя одинаково, а при маленьких ошибка
у несмещенной оценки меньше. Об этом подробнее мы еще будем говорить в
дальнейшем.
Для вычисления ковариации вExcel предусмотрены две функции: КО-
ВАРИАЦИЯ.В для несмещенной ковариации и КОВАРИАЦИЯ.Г – для сме-
щенной.
Для рассмотрения зависимости интереснее получить так называемую
выборочную корреляцию. Так как корреляцияξ1 и ξ2 определяется, как
ρ(ξ1,ξ2) = cov(ξ1,ξ2)
σξ1σξ2
,
то выборочная корреляция определяется следующим образом.
16
Определение 1.6.3Выборочной корреляцией, построенной по выборке
(X,Y ) = ((X1,Y1),(X2,Y2),..., (Xn,Yn)), называют величину
r(X,Y ) = k(X,Y )
SXSY
= k0(X,Y )
S0XS0Y
,
гдеS2
X,S2
Y – смещенные выборочные дисперсии, аS2
0X,S2
0Y – несмещенные
выборочные дисперсии, построенные по выборкамX = (X1,X2,...,X n) иY =
(Y1,Y2,...,Y n), соответственно.
Пример 1.6.1Среднемесячная заработная плата (тыс. руб.) в Ленинград-
ской области в 2010-2011 годах составила по отраслям.
Отрасль ЖКХ ЗдравоохранениеОбразованиеИТ
2010 год 13.1 9.2 10.2 23.6
2011 год 16.2 11.6 13 28.8
.
Найдем несмещенную ковариацию при помощиExcel. Для этого используем
соответствующую функцию КОВАРИАЦИЯ.В.
k0(X,Y ) ≈51.6.
Для нахождения коэффициента корреляции используем соответствующую
функцию КОРРЕЛ.
r(X,Y ) ≈0.99
2 Оценивание параметров вероятностной модели
2.1 Наводящий пример
Ситуация, которую мы только что рассматривали, то есть ситуация, ко-
гда ничего (кроме выборки) неизвестно, наверное, самая плохая, но не един-
ственная. Давайте рассмотрим такой модельный пример.
Предположим, что заядлый посетитель тира производит10 выстрелов
по мишени из одного и того же пистолета. Выборка результатов стрельбы,
где1 отвечает попаданию, а0 – промаху, такова:
(1,0,0,1,0,1,0,0,1,1).
Конечно, можно считать, что кроме выборки никакой другой информации
нет, но можно рассуждать и иначе. Наверное, нетрудно понять, что каждый
эксперимент (которых проводилось всего10) имеет всего два исхода: попал и
17
не попал, и вероятность благоприятного исхода в каждом испытании одина-
кова и равнаp(ведь раз посетитель постоянный, то глаз у него должен быть
/guillemotleft.cyrнаметан/guillemotright.cyr, пристрелян, и так далее). Значит, можно допустить, что случай-
ная величина, показывающая результат эксперимента, имеет распределение
БернуллиBp с неизвестным параметромp.
А что это нам дает? А дает вот что. Если мы сможем оценитьp, ис-
пользуя данную нам выборку, то мы сразу получим вероятностную модель
эксперимента, а это, как мы не раз говорили, очень много. Но как же оценить
p? Оказывается, мы для этого уже все подготовили, смотрите.
Пустьξ ∼Bp, тогдаEξ = p. Но хорошей оценкой математического ожи-
данияEξявляетсявыборочноесреднееX,значит,вестимо,егоможносчитать
и оценкойˆpпараметраp. Итак,
ˆp= X = 0.5
Теперь можно и прогнозировать.
2.2 Оценки параметров некоторых стандартных
распределений
Итак, давайте конспективно приведем оценки параметров некоторых
стандартных распределений. Чтобы подчеркнуть, что вычисленная нами по
выборке величина является оценкой, мы над ней будем ставить крышку.
1.РассмотримраспределениеБернуллиBp.Таккакматематическоеожи-
даниеEξ случайной величиныξ, имеющей распределение Бернулли, равноp,
то
ˆp= X.
Проведем численный эксперимент на синтетических выборках разного
объема из распределения Бернулли с параметромp = 0 .6. Как видно из
рисунка 7, с ростом числаn выборочное среднее все лучше приближает ис-
тинное значение параметраp= 0.6
2. Рассмотрим биномиальное распределениеBin(m,p) с неизвестными
параметрамиm,p. Мы знаем, что математическое ожиданиеEξ случайной
величины, имеющей биномиальное распределение, равноmp, а дисперсия
Dξ = mp(1 −p). Тогда (учитывая, что оценка математического ожидания
– этоX, а оценка дисперсии –S2 ), решая систему,
{
mp= X
mp(1 −p) = S2
приходим к оценкам
ˆp= 1 −S2
X, ˆm= X
2
X−S2 .
18
Рис. 7: ЗависимостьX от объема выборки
Если использовать для оценки дисперсии несмещенную выборочную диспер-
сиюS2
0, то
ˆp= 1 −S2
0
X, ˆm= X
2
X−S2
0
.
На самом деле, так какm – натуральное число, то в качестве оценки стоит
брать ближайшее целое число к тому, что получается по формулам, приве-
денным выше.
В случае, еслиmизвестно, формулы упрощаются и
ˆp= X
m.
Если же известноp, то
ˆm= X
p
и в качестве оценки стоит снова брать ближайшее целое число.
Пример оценок значенияp, построенных по выборкам из биномиально-
го распределения с параметромp = 0.6, представлен на рисунке 8. Можно
убедиться, что если известен параметрm, то оценка параметраpполучается
более точной, чем в случае, когда неизвестно ничего.
3. Рассмотрим распределение ПуассонаΠλ с неизвестным параметром
λ> 0. Так как математическое ожиданиеEξ случайной величины, имеющей
19
Рис. 8: Зависимостьˆpот объема выборки
распределение Пуассона, равноλ, то
ˆλ= X.
Пример оценок значенияλ, построенных по выборкам из распределения
Пуассона с параметромλ= 1, представлен на рисунке 9.
20
Рис. 9: Зависимостьˆλот объема выборки
4. Рассмотрим равномерное распределениеUa,b с неизвестными парамет-
рамиa<b . Оказывается, что оценку этих параметров выгоднее всего произ-
водить, используя1-ую иn-ую порядковые статистики, а именно:
ˆa= X(1), ˆb= X(n).
Пример оценок значенийa,b, построенных по выборкам из биномиального
распределения с параметрaмиa = 0 ,b = 10 , представлен на рисунке 10.
Можно заметить, что оценки достаточно хорошо справляются со своей зада-
чей.
5. Рассмотрим показательное распределениеExpλ с неизвестным пара-
метромλ >0. Так как математическое ожиданиеEξ случайной величины,
имеющей показательное распределение, равно1
λ, то
1
ˆλ
= X ⇒ˆλ= 1
X.
Пример оценок значенияλ, построенных по выборкам из экспоненциального
распределения с параметромλ= 1
3, представлен на рисунке 11.
6. Рассмотрим нормальное распределениеNa,σ2 с неизвестными парамет-
рамиa,σ2. Так как математическое ожиданиеEξ случайной величины, име-
ющей нормальное распределение, равноa, а дисперсияDξ равнаσ2, то
ˆa= X, ˆσ2 = S2 или ˆσ2 = S2
0.
21
Рис. 10: Зависимостьˆa,ˆbот объема выборки
Рис. 11: Зависимостьˆλот объема выборки
Примероценокзначенийa,σ2,построенныхповыборкамизнормального
распределения с параметрамиa= 2,σ2 = 9, представлен на рисунке 11.
Пример представлен на рисунке 12.
Популярные пакеты обработки и анализа данных позволяют генериро-
22
Рис. 12: Зависимостьˆa, ˆσ2 от объема выборки
вать выборки из известных распределений с заданными параметрами. Напри-
мер, вExcel это можно реализовать, используя надстройку /guillemotleft.cyrАнализ данных/guillemotright.cyr.
3 Закон больших чисел и свойства оценок
Итак, мы изучили практическое применение введенного аппарата, но до
сих пор у нас нет никаких формальных доказательств того, что все расска-
занное нами выше и правда работает. Смешно сказать, но мы, то и дело
употребляя термин /guillemotleft.cyrоценка/guillemotright.cyr, ни разу даже не ввели соответствующего опре-
деления: а что такое оценка? Более того, говоря, что какая-то выборочная
характеристика приближает истинную, мы тоже ни разу не конкретизирова-
ли: а в каком смыcле приближает? Давайте попробуем разобраться.
3.1 А что вообще такое оценка?
Итак, начнем с того, а что такое оценка. Пусть имеется выборкаX =
(X1,X2,...,X n) из генеральной совокупностиξ, а θ – некоторый параметр,
который характеризует (или присущ) распределению случайной величиныξ.
Так, в качествеθ может выступать математическое ожиданиеEξ, дисперсия
Dξ, медианаmed ξ и так далее. Параметрθможет быть и каким-то более об-
щим параметром распределения. Скажем, можно рассматривать семейство
распределенийU0,θ, и тогдаθ– это не самая явная характеристика генераль-
23
ной совокупности (на самом делеθ= 2Eξ, подумайте почему).
Определение 3.1.1Оценкой параметраθ называется произвольная функ-
цияˆθ, зависящая от выборкиX, то есть
ˆθ= ˆθ(X1,X2,...,X n).
Отметим также, чтоˆθ– это случайная величина, так как она является функ-
цией от случайных величин(X1,X2,...,X n).
Все оценки, которые мы вводили ранее, ровно-таки и были функциями
от выборки, смотрите:
1. Выборочное среднееX – это средне арифметическое элементов выборки:
X = X1 + X2 + ...+ Xn
n .
2. Выборочная дисперсияS2 и несмещенная выборочная дисперсияS2
0 – более
хитрые функции, но тоже зависящие только лишь от выборки:
S2 = 1
n
n∑
i=1
(
Xi −X
)2
, S 2
0 = 1
n−1
n∑
i=1
(
Xi −X
)2
и так далее.
Однако достаточно очевидно, что не всякая функция от выборки явля-
ется /guillemotleft.cyrхорошей/guillemotright.cyr оценкой рассматриваемого параметра. Например, в качестве
оценкиˆθ можно взять тождественный ноль:ˆθ ≡0. Такая функция вполне
подходит под определение, но является ли она разумной оценкой?
Конечно, разумная оценка – это та, которая, как мы уже не раз повто-
ряли, приближает истинное значение параметра. А что значит приближает?
Чтобы дать четкое определение, нам потребуется ввести понятие сходимости
по вероятности.
3.2 Сходимость по вероятности и состоятель-
ность
Итак, рассмотрим последовательность случайных величинξn.
Определение 3.2.1Говорят, что последовательность случайных величин
ξn сходится по вероятности к случайной величинеξ, если
∀ε> 0 ⇒ P (|ξn −ξ|≥ ε) −−−−→
n→+∞
0.
Обозначают сходимость по вероятности следующим образом:
ξn
P
−−−−→
n→+∞
ξ.
24
Как можно пояснить это определение? На самом деле оно не зря выглядит пу-
гающим,ведьдляпониманияоносовсемнетривиально.Утверждение,данное
в определении, можно формулировать для себя так: с ростомn вероятность
события, чтоξn хоть как-то отличается отξ, стремится к нулю.
Резонно задать и еще один вопрос: а при чем тут последовательность?
Посмотрите, любая оценкаˆθ– это тоже последовательность, ведь она зависит
от объема выборкиn:
ˆθ= ˆθ(X1,X2,...,X n).
Скажем, посмотрите на выборочное среднееX:
X = X1 + X2 + ...+ Xn
n .
Сразу видно, что в выражении для выборочного среднего отn зависит как
знаменатель, так и число слагаемых в числителе! Наверное, теперь можно
догадаться, какая оценка будет считаться хорошей? Конечно та, к которая по
вероятности будет сходиться к истинному значению параметра. Такие оценки
называются состоятельными.
Определение 3.2.2Оценкаˆθ = ˆθ(X1,X2,...,X n) называется состоятель-
ной оценкой параметраθ, если
ˆθ
P
−−−−→
n→+∞
θ.
Итак, состоятельность – понятное слово даже с точки зрения русского языка.
Ведь если с ростомn, то есть с ростом объема выборки, значения нашей
оценкинеприближаютистинногозначенияпараметра,тооценкаоказывается
крайне несостоятельной: ведь она просто-напросто не состоялась, как оценка.
За этой, казалось бы, игрой слов, на самом деле кроется достаточно большой
смысл, постарайтесь его уловить.
Хорошо, а как доказать состоятельность хотя бы одной из наших оценок?
В этом нам поможет так называемый закон больших чисел.
3.3 Закон больших чисел
Рассмотрим случайный эксперимент и некоторую случайную величину
ξ, которая наблюдается в ходе этого эксперимента. Предположим, что мате-
матическое ожидание этой случайной величины равноa.
Если повторять этот эксперимент большое количество раз, наблюдая за
ξ, то мы получим последовательность независимых одинаково распределен-
ных случайных величинξ1,ξ2,... с математическим ожиданиемa. Заранее
предсказать, какие значения будут принимать в ходе экспериментов случай-
ные величиныξi невозможно, так как эти значения зависят от случая. Одна-
ко, как показывает практика, среднее арифметическое значений случайных
25
величинξ1,ξ2,...,ξ n, полученных в результатеn экспериментов, приближа-
ется с ростомnк числуa. Этот эмпирический факт говорит о том, что пове-
дение суммы большого числа случайных величин становится в определённом
смысле закономерным.
Математическая формулировка явления носит название /guillemotleft.cyrЗакон больших
чисел/guillemotright.cyr (ЗБЧ).
Теорема 3.3.1 (Закон больших чисел в форме Хинчина)Пусть
имеется последовательностьξ1,ξ2,...,ξ n,... независимых и одинаково
распределенных случайных величин, имеющих математическое ожидание
a. Тогда
∀ε> 0 P
(⏐⏐⏐⏐
ξ1 + ξ2 + ...+ ξn
n −a
⏐⏐⏐⏐≥ε
)
−−−−→
n→+∞
0.
Итак, закон больших чисел утверждает, что в случае независимых и оди-
наково распределенных случайных величин, вероятность того, что их среднее
арифметическое отклоняется от математического ожидания, стремится к ну-
лю (по вероятности) с ростомn.
В введенных нами обозначениях это может быть записано, как
ξ1 + ξ2 + ...+ ξn
n
P
−−−−→
n→+∞
a= Eξi = Eξ1,
так как раз все случайные величины одинаково распределены, то они имеют
одно и то же математическое ожидание.
Именно на законе больших чисел основываются статистические методы
оценивания неизвестных параметров распределения.
Теорема 3.3.2 (Состоятельность выборочного среднего)Пусть су-
ществует математическое ожидание генеральной совокупностиEξ. Тогда
X – состоятельная оценкаEξ.
Доказательство.ПустьX = (X1,X2,...,X n) – выборка из генеральной со-
вокупностиξ. ТогдаX1,X2,... – последовательность независимых случайных
величин, имеющих такое же распределение, как иξ. По условию существует
математическое ожиданиеEξ, тогда, согласно закону больших чисел в форме
Хинчина,
X1 + X2 + ...+ Xn
n
P
−−−−→
n→+∞
Eξ.
□
Оказывается, что и все остальные введенные нами оценки: выборочная дис-
персия, несмещенная выборочная дисперсия, выборочная медиана, выбороч-
ная корреляция – состоятельные оценки соответствующих характеристик ге-
неральной совокупностиξ, а значит они и правда пригодны к использованию.
26
3.4 Несмещенность оценок
Последний долг, который у нас остался – это определить понятие несме-
щенности оценки.
Определение 3.4.1Оценкаˆθ= ˆθ(X1,X2,...,X n) называется несмещенной
оценкой параметраθ, если
Eˆθ= θ.
Иными словами, свойство несмещенности означает, что в среднем наша оцен-
ка совпадает с оцениваемым параметром, или, точнее, что /guillemotleft.cyrв среднем/guillemotright.cyr ее
значения совпадают со значением оцениваемого параметра.
Теорема 3.4.1Пусть существует математическое ожидание генераль-
ной совокупностиEξ. ТогдаX – несмещенная оценкаEξ.
Доказательство.ПустьX = (X1,X2,...,X n) – выборка из генеральной со-
вокупностиξ. ТогдаX1,X2,... – последовательность независимых случайных
величин, имеющих такое же распределение, как иξ. По свойству математи-
ческого ожидания,
EX = E
(X1 + X2 + ...+ Xn
n
)
= 1
n
n∑
i=1
EXi = 1
n
n∑
i=1
Eξ = nEξ
n = Eξ.
□
Оказывается, что несмещенная выборочная дисперсия, несмещенная выбо-
рочная ковариация и корреляция являются несмещенными оценками.
Выборочная дисперсия же – смещенная оценка. Можно показать, что в
предположении, что существует дисперсия генеральной совокупностиDξ,
ES2 = n−1
n Dξ.
На практике несмещенные оценки встречаются достаточно редко. Куда чаще
возникают так называемые асимптотически несмещенные оценки.
Определение 3.4.2Оценкаˆθ = ˆθ(X1,X2,...,X n) называется асимптоти-
чески несмещенной оценкой параметраθ, если
lim
n→+∞
Eˆθ= θ.
Выборочная дисперсия, очевидно, является асимптотически несмещенной
оценкой дисперсии генеральной совокупностиDξ, так как
lim
n→+∞
n−1
n = 1.
27
Отсюда и следуют те умозаключения, что мы приводили выше. Смещенные,
но асимптотически несмещенные оценки, хорошо работают на больших объ-
емах выборки. На маленьких же объемах они могут давать существенные
ошибки. На маленьких объемах предпочтительнее использовать несмещен-
ные оценки.
4 Резюме
Итак, в этой лекции мы узнали, как по выборке можно оценить мате-
матическое ожидание, дисперсию и плотность генеральной совокупности, на-
учились вычислять выборочную ковариацию и применять полученные оцен-
ки для оценок параметров распределений. Более того, мы попытались под-
крепить все наши эмпирические соображения некоторой теорией: разобра-
ли важность состоятельных оценок, поняли разницу между смещенными и
несмещенными оценками, а также важный принцип: где и какие оценки при-
менять. Однако осталась еще одна большая брешь, которую мы будем закры-
вать в следующей лекции: а как понять, что полученная нами оценка близка
к истинному значению параметра? Скажем, получив в качестве оценки ма-
тематического ожиданияX = 5, можем ли мы быть удовлетворены? Ведь,
поменяв выборку, мы получим какое-то другое значениеX. И какое из них
лучше? И далеко ли от них истинное?
С этими вопросами нам поможет разобраться так называемое интерваль-
ное оценивание, которое мы и будем рассматривать в следующей лекции.
28
