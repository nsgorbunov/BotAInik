Лекция 4
Линейная регрессия
Е. А. Соколов
ФКН ВШЭ
25 сентября 2021 г.
1 Регуляризация
Раньше мы обсуждали, что если матрица XT X не является обратимой, то с
оптимизацией среднеквадратичной ошибки могут возникнуть некоторые трудности.
Действительно, в ряде случаев (признаков больше чем объект ов, коррелирующие
признаки) оптимизационная задача Q(w) → min может иметь бесконечное число
решений, большинство которых являются переобученными и пл охо работают на те-
стовых данных. Покажем это.
Пусть в выборке есть линейно зависимые признаки. Это по опре делению озна-
чает , что существует такой вектор v, что для любого объекта x выполнено ⟨v, x ⟩ = 0.
Допустим, мы нашли оптимальный вектор весов w для линейного классификатора.
Но тогда классификаторы с векторами w +αv будут давать точно такие же ответы
на всех объектах, поскольку
⟨w + αv, x ⟩ = ⟨w, x ⟩+ α ⟨v, x ⟩  
=0
= ⟨w, x ⟩.
Это значит , что метод оптимизации может найти решение со ско лько угодно больши-
ми весами. Т акие решения не очень хороши, поскольку классиф икатор будет чувстви-
телен к крайне маленьким изменениям в признаках объекта, а з начит , переобучен.
Мы уже знаем, что переобучение нередко приводит к большим зн ачениям ко-
эффициентов. Чтобы решить проблему , добавим к функционалу регуляризатор, ко-
торый штрафует за слишком большую норму вектора весов:
Qα(w) =Q(w) +αR (w).
Наиболее распространенными являются L2 и L1-регуляризаторы:
R(w) =∥w∥2 =
d∑
i=1
w2
i ,
R(w) =∥w∥1 =
d∑
i=1
|wi|.
1
2
Коэффициент α называется параметром регуляризации и контролирует балан с
между подгонкой под обучающую выборку и штрафом за излишнюю сложность.
Разумеется, значение данного параметра следует подбирать под каждую задачу .
Отметим, что свободный коэффициент w0 нет смысла регуляризовывать /emdash.cyr ес-
ли мы будем штрафовать за его величину , то получится, что мы у читываем некие
априорные представления о близости целевой переменной к ну лю и отсутствии необ-
ходимости в учёте её смещения. Т акое предположение являетс я достаточно стран-
ным. Особенно об этом следует помнить, если в выборке есть ко нстантный признак
и коэффициент w0 обучается наряду с остальными весами; в этом случае следует
исключить слагаемое, соответствующее константному призн аку , из регуляризатора.
Квадратичный (или L2) регуляризатор достаточно прост в использовании в
отличие от L1-регуляризатора, у которого нет производной в нуле. При это м L1-
регуляризатор имеет интересную особенность: его использо вание приводит к зануле-
нию части весов. Позже мы подробно обсудим это явление.
Обратим внимание на вид решения при использовании L2-регуляризации вместе
со среднеквадратичной ошибкой. В этом случае формулу для оп тимального вектора
весов можно записать в явном виде:
w = (XT X + αI )− 1XT y.
Благодаря добавлению диагональной матрицы к XT X данная матрица оказывает-
ся положительно определённой, и поэтому её можно обратить. Т аким образом, при
использовании L2 регуляризации решение всегда будет единственным.
2 Гиперпараметры
В машинном обучении принято разделять подлежащие настройк е величины
на параметры и гиперпараметры. Параметрами называют величины, которые на-
страиваются по обучающей выборке /emdash.cyr например, веса в линейно й регрессии. К ги-
перпараметрам относят величины, которые контролируют сам процесс обучения и
не могут быть подобраны по обучающей выборке.
Хорошим примером гиперпараметра является коэффициент рег уляризации α .
Введение регуляризации мешает модели подгоняться под обуч ающие данные, и с
точки зрения среднеквадратичной ошибки выгодно всегда бра ть α = 0. Разумеет-
ся, такой выбор не будет оптимальным с точки зрения качества на новых данных,
и поэтому коэффициент регуляризации (как и другие гиперпар аметры) следует на-
страивать по отложенной выборке или с помощью кросс-валида ции.
При подборе гиперпараметров по кросс-валидации возникает проблема: мы ис-
пользуем отложенные данные, чтобы выбрать лучший набор гип ерпараметров. По
сути, отложенная выборка тоже становится обучающей, и пока затели качества на
ней перестают характеризовать обобщающую способность мод ели. В таких случаях
выборку , на которой настраиваются гиперпараметры, называ ют валидационной, и
при этом выделяют третий, тестовый набор данных, на которых оценивается каче-
ство итоговой модели.
3
Рис. 1. Линии уровня функционала качества, а также ограниче ния, задаваемые L2 и L1-
регуляризаторами.
3 Разреженные модели
В процессе обсуждения регуляризации мы упомянули, что испо льзование L1-
регуляризатора приводит к обнулению части весов в модели. О бсудим подробнее,
зачем это может понадобиться и почему так происходит .
Модели, в которых некоторые веса равны нулю, называют разреженными, по-
скольку прогноз в них зависит лишь от части признаков. Потре бность в таких моде-
лях можно возникнуть по многим причинам. Несколько примеро в:
1. Может быть заведомо известно, что релевантными являются не все признаки.
Очевидно, что признаки, которые не имеют отношения к задаче , надо исклю-
чать из данных, то есть производить отбор признаков . Есть много способов
решения этой задачи, и L1-регуляризация /emdash.cyr один из них.
2. К модели могут выдвигаться ограничения по скорости постр оения предсказа-
ний. В этом случае модель должна зависеть от небольшого коли чества наиболее
важных признаков, и тут тоже оказывается полезной L1-регуляризация.
3. В обучающей выборке объектов может быть существенно мень ше, чем призна-
ков (так называемая /guillemotleft.cyrпроблема N ≪ p/guillemotright.cyr). Поскольку параметров линейной
модели при этом тоже больше, чем объектов, задача обучения о казывается
некорректной /emdash.cyr решений много, и сложно выбрать из них то, кот орое обла-
дает хорошей обобщающей способностью. Решить эту проблему можно путём
внедрения в процесс обучения априорного знания о том, что це левая перемен-
ная зависит от небольшого количества признаков. Т акая моди фикация как раз
может быть сделана с помощью L1-регуляризатора.
Т еперь, когда мы представляем некоторые области применени я разреженных моде-
лей, попробуем понять, почему L1 регуляризатор позволяет их обучать. Этому есть
несколько объяснений.
Угловые точки. Можно показать, что если функционал Q(w) является выпуклым,
то задача безусловной минимизации функции Q(w) + α ∥w∥1 эквивалентна задаче
4
условной оптимизации
{ Q(w) → min
w
∥w∥1 ⩽ C
для некоторого C. На рис. 1 изображены линии уровня функционала Q(w), а также
множество, определяемое ограничением ∥w∥1 ⩽ C. Решение определяется точкой
пересечения допустимого множества с линией уровня, ближай шей к безусловному
минимуму . Из изображения можно предположить, что в большин стве случаев эта
точка будет лежать на одной из вершин ромба, что соответству ет решению с одной
зануленной компонентой.
Штрафы при малых весах. Предположим, что текущий вектор весов состоит из
двух элементов w = (1, ε ), где ε близко к нулю, и мы хотим немного изменить дан-
ный вектор по одной из координат . Найдём изменение L2- и L1-норм вектора при
уменьшении первой компоненты на некоторое положительное ч исло δ < ε :
∥w − (δ, 0)∥2
2= 1− 2δ + δ2 + ε2
∥w − (δ, 0)∥1 = 1− δ + ε
Вычислим то же самое для изменения второй компоненты:
∥w − (0, δ )∥2
2= 1− 2εδ + δ2 + ε2
∥w − (0, δ )∥1 = 1− δ + ε
Видно, что с точки зрения L2-нормы выгоднее уменьшать первую компонен-
ту , а для L1-нормы оба изменения равноценны. Т аким образом, при выборе L2-
регуляризации гораздо меньше шансов, что маленькие веса бу дут окончательно об-
нулены.
Проксимальный шаг .Проксимальные методы /emdash.cyr это класс методов оптимизации,
которые хорошо подходят для функционалов с негладкими слаг аемыми. Не будем
сейчас останавливаться на принципах их работы, а приведём л ишь формулу для
шага проксимального метода в применении к линейной регресс ии с квадратичным
функционалом ошибки и L1-регуляризатором:
w(k) = Sηα
(
w(k− 1) − η∇wF (w(k− 1))
)
,
где F (w) =∥Xw − y∥2 /emdash.cyr функционал ошибки без регуляризатора, η /emdash.cyr длина шага,
α /emdash.cyr коэффициент регуляризации, а функция Sηα(w) применяется к вектору весов
покомпонентно, и для одного элемента выглядит как
Sηα(wi) =





wi − ηα, w i > ηα
0, |wi| < ηα
wi + ηα, w i < −ηα
Из формулы видно, что если на данном шаге значение некоторог о веса не очень боль-
шое, то на следующем шаге этот вес будет обнулён, причём чем б ольше коэффициент
регуляризации, тем больше весов будут обнуляться.
5
Рис. 2. Траектория градиентного спуска на функционале при признаках разного масштаба.
4 Преобразования признаков
§4.1 Нелинейные признаки
С помощью линейной регрессии можно восстанавливать нелине йные зависимо-
сти, если провести преобразование признакового пространс тва:
x = (x1, . . . , x d) → ϕ (x) = (ϕ 1(x), . . . , ϕ m(x)).
Например, можно перейти к квадратичным признакам:
ϕ (x) = (x1, . . . , x d, x 2
1, . . . , x 2
d, x 1x2, . . . , x d− 1xd).
Линейная модель над новыми признаками уже сможет приближат ь любые квадра-
тичные закономерности. Аналогично можно работать и с полин омиальными призна-
ками более высоких порядков.
Возможны и другие преобразования:
• log xj /emdash.cyr для признаков с тяжёлыми хвостами
• exp(∥x − µ∥2/σ ) /emdash.cyr для измерения близости до некоторой точки
• sin(xj /T ) /emdash.cyr для задач с периодическими зависимостями
§4.2 Масштабирование
При обучении линейных моделей полезно масштабировать приз наки, то есть
приводить их к единой шкале. Разберёмся, зачем это нужно.
Рассмотрим функцию f1(x) = 1
2 x2
1+ 1
2 x2
2, выберем начальное приближение x(0) =
= (1, 1) и запустим из него градиентный спуск с параметром η = 1. Окажется, что
за один шаг мы сможем сразу попасть в точку минимума.
Т еперь /guillemotleft.cyrрастянем/guillemotright.cyr функцию вдоль одной из осей: f2(x) = 50x2
1+ 1
2 x2
2. При
таком же начальном приближении x(0) антиградиент на первой итерации будет ра-
вен (−100, −1), и попасть по нему в минимум уже невозможно /emdash.cyr более того, при
6
неаккуратном выборе длины шага можно очень далеко уйти от ми нимума. Пример
траектории градиентного спуска при такой форме функции мож но найти на рис. 2.
Аналогичная проблема возникает с функционалом ошибки в лин ейной регрес-
сии, если один из признаков существенно отличается по масшт абу от остальных.
Чтобы избежать этого, признаки следует масштабировать /emdash.cyr на пример, путём стан-
дартизации:
xij := xij − µj
σj
,
где µj = 1
ℓ
∑ ℓ
i=1 xij , σj = 1
ℓ
∑ ℓ
i=1(xij − µj)2. Или, например, можно масштабировать
признаки на отрезок [0, 1]:
xij := xij − mini xij
maxi xij − mini xij
.
