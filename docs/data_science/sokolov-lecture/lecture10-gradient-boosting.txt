Лекция 10
Градиентный бустинг
Е. А. Соколов
ФКН ВШЭ
16 ноября 2021 г.
Ранее мы изучили бэггинг и случайные леса /emdash.cyr подходы к построению компо-
зиций, которые независимо обучают каждый базовый алгоритм по некоторому под-
множеству обучающих данных. При этом возникает ощущение, ч то мы используем
возможности объединения алгоритмов не в полную силу , и можн о было бы строить
их так, чтобы каждая следующая модель исправляла ошибки пре дыдущих. Ниже мы
рассмотрим метод, который реализует эту идею /emdash.cyr градиентныйбустинг , предложен-
ный Фридманом [ 1]. Он работает для любых дифференцируемых функций потерь и
является одним из наиболее мощных и универсальных на сегодн яшний день.
1 Бустинг в задаче регрессии
Рассмотрим задачу минимизации квадратичного функционала :
1
2
ℓ∑
i=1
(a(xi) − yi)2 → min
a
Будем искать итоговый алгоритм в виде суммы базовых моделей (weak learners) bn(x):
aN (x) =
N∑
n=1
bn(x),
где базовые алгоритмы bn принадлежат некоторому семейству A.
Построим первый базовый алгоритм:
b1(x) := arg min
b∈A
1
2
ℓ∑
i=1
(b(xi) − yi)2
Решение такой задачи не представляет трудностей для многих семейств алгоритмов.
Т еперь мы можем посчитать остатки на каждом объекте /emdash.cyr расстояния от ответа
нашего алгоритма до истинного ответа:
s(1)
i= yi − b1(xi)
1
2
Если прибавить эти остатки к ответам построенного алгоритм а, то он не будет до-
пускать ошибок на обучающей выборке. Значит , будет разумно построить второй
алгоритм так, чтобы его ответы были как можно ближе к остатка м:
b2(x) := arg min
b∈A
1
2
ℓ∑
i=1
(b(xi) − s(1)
i)2
Каждый следующий алгоритм тоже будем настраивать на остатк и предыду-
щих:
s(N)
i = yi −
N− 1∑
n=1
bn(xi) =yi − aN− 1(xi), i = 1, . . . , ℓ ;
bN (x) := arg min
b∈A
1
2
ℓ∑
i=1
(b(xi) − s(N)
i )2
Описанный метод прост в реализации, хорошо работает и может быть найден во
многих библиотеках /emdash.cyr например, вscikit-learn.
Заметим, что остатки могут быть найдены как антиградиент фу нкции потерь
по ответу модели, посчитанный в точке ответа уже построенно й композиции:
s(N)
i = yi − aN− 1(xi) =− ∂
∂z
1
2(z − yi)2
⏐
⏐
⏐
⏐
z=aN− 1(xi)
Получается, что выбирается такой базовый алгоритм, которы й как можно сильнее
уменьшит ошибку композиции /emdash.cyr это свойство вытекает из его близости к антигради-
енту функционала на обучающей выборке. Попробуем разобрат ься с этим свойством
подробнее, а также попытаемся обобщить его на другие функци и потерь.
2 Градиентный бустинг
Пусть дана некоторая дифференцируемая функция потерь L(y, z ). Будем стро-
ить взвешенную сумму базовых алгоритмов:
aN (x) =
N∑
n=0
γnbn(x)
Заметим, что в композиции имеется начальный алгоритм b0(x). Как правило, коэф-
фициент γ0 при нем берут равным единице, а сам алгоритм выбирают очень п ростым,
например:
• нулевым b0(x) = 0;
• возвращающим самый популярный класс (в задачах классифика ции):
b0(x) = arg max
y∈ Y
ℓ∑
i=1
[yi = y]
3
• возвращающим средний ответ (в задачах регрессии):
b0(x) = 1
ℓ
ℓ∑
i=1
yi
Допустим, мы построили композицию aN− 1(x) из N − 1 алгоритма, и хотим вы-
брать следующий базовый алгоритм bN (x) так, чтобы как можно сильнее уменьшить
ошибку:
ℓ∑
i=1
L(yi, aN− 1(xi) +γN bN (xi)) → min
bN ,γN
Ответим в первую очередь на следующий вопрос: если бы в качес тве алгорит-
ма bN (x) мы могли выбрать совершенно любую функцию, то какие значени я ей сле-
довало бы принимать на объектах обучающей выборки? Иными сл овами, нам нужно
понять, какие числа s1, . . . , s ℓ надо выбрать для решения следующей задачи:
ℓ∑
i=1
L(yi, aN− 1(xi) +si) → min
s1,...,sℓ
Понятно, что можно требовать si = yi − aN− 1(xi), но такой подход никак не учи-
тывает особенностей функции потерь L(y, z ) и требует лишь точного совпадения
предсказаний и истинных ответов. Более разумно потребоват ь, чтобы сдвиг si был
противоположен производной функции потерь в точке z = aN− 1(xi):
si = − ∂L
∂z
⏐
⏐
⏐
⏐
z=aN− 1(xi)
В этом случае мы сдвинемся в сторону скорейшего убывания фун кции потерь. За-
метим, что вектор сдвигов s = (s1, . . . , s ℓ) совпадает с антиградиентом:
(
− ∂L
∂z
⏐
⏐
⏐
⏐
z=aN− 1(xi)
) ℓ
i=1
= −∇z
ℓ∑
i=1
L(yi, zi)
⏐
⏐
zi=aN− 1(xi)
При таком выборе сдвигов si мы, по сути, сделаем один шаг градиентного спуска,
двигаясь в сторону наискорейшего убывания ошибки на обучаю щей выборке. От-
метим, что речь идет о градиентном спуске в ℓ-мерном пространстве предсказаний
алгоритма на объектах обучающей выборки. Поскольку вектор сдвига будет свой на
каждой итерации, правильнее обозначать его как s(N)
i , но для простоты будем иногда
опускать верхний индекс.
Итак, мы поняли, какие значения новый алгоритм должен прини мать на объек-
тах обучающей выборки. По данным значениям в конечном числе точек необходимо
построить функцию, заданную на всем пространстве объектов . Это классическая за-
дача обучения с учителем, которую мы уже хорошо умеем решать . Один из самых
простых функционалов /emdash.cyr среднеквадратичная ошибка. Воспользуемся им для по-
иска базового алгоритма, приближающего градиент функции п отерь на обучающей
выборке:
bN (x) = arg min
b∈A
ℓ∑
i=1
(b(xi) − si)2
4
Отметим, что здесь мы оптимизируем квадратичную функцию по терь независимо от
функционала исходной задачи /emdash.cyr вся информация о функции потерь L находится в
антиградиенте si, а на данном шаге лишь решается задача аппроксимации функци и
по ℓ точкам. Разумеется, можно использовать и другие функциона лы, но средне-
квадратичной ошибки, как правило, оказывается достаточно . Ещё одна причина для
использования среднеквадратичной ошибки состоит в том, чт о от алгоритма требу-
ется как можно точнее приблизить направление наискорейшег о убывания функцио-
нала (то есть направление (si)i); совпадение направлений вполне логично оценивать
через косинус угла между ними, который напрямую связан со ср еднеквадратичной
ошибкой.
После того, как новый базовый алгоритм найден, можно подобр ать коэффици-
ент при нем по аналогии с наискорейшим градиентным спуском:
γN = arg min
γ∈ R
ℓ∑
i=1
L(yi, aN− 1(xi) +γbN (xi))
Описанный подход с аппроксимацией антиградиента базовыми алгоритмами и
называется градиентным бустингом. Данный метод представл яет собой поиск луч-
шей функции, восстанавливающей истинную зависимость отве тов от объектов, в про-
странстве всех возможных функций. Ищем мы данную функцию с п омощью /guillemotleft.cyrпсев-
доградиентного/guillemotright.cyr спуска /emdash.cyr каждый шаг делается вдоль направления, задаваемого
некоторым базовым алгоритмом. При этом сам базовый алгорит м выбирается так,
чтобы как можно лучше приближать антиградиент ошибки на обу чающей выборке.
3 Регуляризация
Сокращение шага.
На практике оказывается, что градиентный бустинг очень быс т-
ро строит композицию, ошибка которой на обучении выходит на асимптоту , после че-
го начинает настраиваться на шум и переобучаться. Это явлен ие можно объяснить
одной из двух причин:
• Если базовые алгоритмы очень простые (например, решающие д еревья неболь-
шой глубины), то они плохо приближают вектор антиградиента . По сути, до-
бавление такого базового алгоритма будет соответствовать шагу вдоль направ-
ления, сильно отличающегося от направления наискорейшего убывания. Соот-
ветственно, градиентный бустинг может свестись к случайно му блужданию в
пространстве.
• Если базовые алгоритмы сложные (например, глубокие решающ ие деревья),
то они способны за несколько шагов бустинга идеально подогн аться под обуча-
ющую выборку /emdash.cyr что, очевидно, будет являться переобучением, связанным с
излишней сложностью семейства алгоритмов.
Хорошо зарекомендовавшим себя способом решения данной про блемы является со-
кращение шага: вместо перехода в оптимальную точку в направлении антигра диента
делается укороченный шаг
aN (x) =aN− 1(x) +ηγN bN (x),
5
где η ∈ (0, 1] /emdash.cyr темп обучения [1]. Как правило, чем меньше темп обучения, тем луч-
ше качество итоговой композиции. Сокращение шага, по сути, позволяет понизить
доверие к направлению, восстановленному базовым алгоритм ом.
Т акже следует обратить внимание на число итераций градиент ного бустинга.
Хотя ошибка на обучении монотонно стремится к нулю, ошибка н а контроле, как
правило, начинает увеличиваться после определенной итера ции. Оптимальное число
итераций можно выбирать, например, по отложенной выборке и ли с помощью кросс-
валидации.
Стохастический градиентный бустинг .Еще одним способом улучшения качества
градиентного бустинга является внесение рандомизации в пр оцесс обучения базовых
алгоритмов [ 2]. А именно, алгоритм bN обучается не по всей выборке X, а лишь по ее
случайному подмножеству Xk ⊂ X. В этом случае понижается уровень шума в обу-
чении, а также повышается эффективность вычислений. Сущес твует рекомендация
брать подвыборки, размер которых вдвое меньше исходной выб орки.
4 Функции потерь
§4.1 Регрессия
При вещественном целевом векторе, как правило, используют квадратичную
функцию потерь, формулы для которой уже были приведены в раз деле 1. Другой
вариант /emdash.cyr модуль отклоненияL(y, z ) =|y − z|, для которого антиградиент вычисля-
ется по формуле
s(N)
i = − sign(aN− 1(xi) − yi).
§4.2 Классификация
В задаче классификации с двумя классами разумным выбором яв ляется ло-
гистическая функция потерь, с которой уже сталкивались при изучении линейных
методов:
L(y, z ) = log(1 + exp(−yz)).
Задача поиска базового алгоритма с ней принимает вид
bN = arg min
b∈A
ℓ∑
i=1
(
b(xi) − yi
1 + exp(yiaN− 1(xi))
) 2
.
Логистическая функция потерь имеет интересную особенност ь, связанную со
взвешиванием объектов. Заметим, что ошибка на N-й итерации может быть записана
как
Q(aN ) =
ℓ∑
i=1
log (1 + exp(−yiaN (xi))) =
=
ℓ∑
i=1
log (1 + exp(−yiaN− 1(xi)) exp(−yiγN bN (xi))) .
6
Если отступ yiaN− 1(xi) на i-м объекте большой положительный, то данный объект
не будет вносить практически никакого вклада в ошибку , и мож ет быть исключен из
всех вычислений на текущей итерации без потерь. Т аким образ ом, величина
w(N)
i = exp(−yiaN− 1(xi))
может служить мерой важности объекта xi на N-й итерации градиентного бустинга.
5 Градиентный бустинг над деревьями
Считается, что градиентный бустинг над решающими деревьям и /emdash.cyr один
из самых универсальных и сильных методов машинного обучени я, известных на
сегодняшний день. В частности, на градиентном бустинге над деревьями осно-
ван MatrixNet /emdash.cyr алгоритм ранжирования компании Яндекс [3].
Вспомним, что решающее дерево разбивает все пространство н а непересекаю-
щиеся области, в каждой из которых его ответ равен константе :
bn(x) =
Jn∑
j=1
bnj [x ∈ Rj ],
где j = 1, . . . , J n /emdash.cyr индексы листьев,Rj /emdash.cyr соответствующие области разбиения,bnj /emdash.cyr
значения в листьях. Значит , на N-й итерации бустинга композиция обновляется как
aN (x) =aN− 1(x) +γN
JN∑
j=1
bNj [x ∈ Rj ] =aN− 1(x) +
JN∑
j=1
γN bNj [x ∈ Rj ].
Видно, что добавление в композицию одного дерева с JN листьями равносильно до-
бавлению JN базовых алгоритмов, представляющих собой предикаты вида [x ∈ Rj].
Если бы вместо общего коэффициента γN был свой коэффициент γNj при каждом
предикате, то мы могли бы его подобрать так, чтобы повысить к ачество композиции.
Если подбирать свой коэффициент γNj при каждом слагаемом, то потребность в bNj
отпадает , его можно просто убрать:
ℓ∑
i=1
L
(
yi, aN− 1(xi) +
JN∑
j=1
γNj [x ∈ Rj ]
)
→ min
{γNj }
JN
j=1
.
Поскольку области разбиения Rj не пересекаются, данная задача распадается на JN
независимых подзадач:
γNj = arg min
γ
∑
xi∈ Rj
L(yi, aN− 1(xi) +γ), j = 1, . . . , J N .
В некоторых случаях оптимальные коэффициенты могут быть на йдены анали-
тически /emdash.cyr например, для квадратичной и абсолютной ошибки.
Рассмотрим теперь логистическую функцию потерь. В этом слу чае нужно ре-
шить задачу
F (N)
j (γ) =
∑
xi∈ Rj
log (1 + exp (−yi(aN− 1(xi) +γ))) → min
γ
.
7
Данная задача может быть решена лишь с помощью итерационных методов, анали-
тической записи для оптимального γ не существует . Однако на практике обычно нет
необходимости искать точное решение /emdash.cyr оказывается достаточным сделать лишь
один шаг метода Ньютона-Рафсона из начального приближения γNj = 0. Можно
показать, что в этом случае
γNj = ∂F (N)
j (0)
∂γ
/
∂2F (N)
j (0)
∂γ2 = −
∑
xi∈ Rj
s(N)
i
/ ∑
xi∈ Rj
|s(N)
i |(1 − |s(N)
i |).
Смещение и разброс. В случайных лесах используются глубокие деревья, посколь-
ку от базовых алгоритмов требуется низкое смещение; разбро с же устраняется за
счёт усреднения ответов различных деревьев. Бустинг работ ает несколько иначе /emdash.cyr в
нём каждый следующий алгоритм целенаправленно понижает ош ибку композиции,
и даже при использовании простейших базовых моделей композ иция может оказать-
ся достаточно сложной. Более того, итоговая композиция впо лне может оказаться
переобученной при большом количестве базовых моделей. Это означает , что благо-
даря бустингу можно понизить смещение моделей, а разброс ли бо останется таким
же, либо увеличится. Из-за этого, как правило, в бустинге ис пользуются неглубо-
кие решающие деревья (3-6 уровней), которые обладают больш им смещением, но не
склонны к переобучению.
6 Взвешивание объектов
Одним из первых широко распространённых методов построени я компози-
ций является AdaBoost, в котором оптимизируется экспоненц иальная функция по-
терь L(y, z ) = e− yz . Благодаря её свойствам удаётся свести задачу поиска базов ого
алгоритма к минимизации доли неверных ответов с весами при о бъектах. Эти веса
возникают и в градиентном бустинге при использовании экспо ненциальной функции
потерь:
L(a, X) =
ℓ∑
i=1
exp
(
−yi
N∑
n=1
γnbn(xi)
)
.
Найдем компоненты ее антиградиента после (N − 1)-й итерации:
si = − ∂L(yi, z)
∂z
⏐
⏐
⏐
⏐
z=aN− 1(xi)
= yi exp
(
−yi
N− 1∑
n=1
γnbn(xi)
)

 
wi
.
Заметим, что антиградиент представляет собой ответ на объе кте, умноженный на его
вес. Если все веса будут равны единице, то следующий базовый классификатор будет
просто настраиваться на исходный целевой вектор (yi)ℓ
i=1; штраф за выдачу ответа,
противоположного правильному , будет равен 4 (поскольку при настройке базового
алгоритма используется квадратичная функция потерь). Есл и же какой-либо объект
будет иметь большой отступ, то его вес окажется близким к нул ю, и штраф за выдачу
любого ответа будет равен 1.
8
Отметим, что многие функционалы ошибки классификации выра жаются через
отступы объектов:
L(aN− 1, X ℓ) =
ℓ∑
i=1
L(aN− 1(xi), yi) =
ℓ∑
i=1
˜L(yiaN− 1(xi)).
В этом случае антиградиент принимает вид
si = yi
(
−∂ ˜L(yiaN− 1(xi))
∂aN− 1(xi)
)
  
wi
,
то есть тоже взвешивает ответы с помощью ошибки на них.
7 Влияние шума на обучение
Выше мы находили формулу для антиградиента при использован ии экспонен-
циальной функции потерь:
si = yi exp
(
−yi
N− 1∑
n=1
γnbn(xi)
)
  
wi
.
Заметим, что если отступ на объекте большой и отрицательный (что обычно наблю-
дается на шумовых объектах), то вес становится очень больши м, причем он никак не
ограничен сверху . В результате базовый классификатор буде т настраиваться исклю-
чительно на шумовые объекты, что может привести к неустойчи вости его ответов и
переобучению.
Рассмотрим теперь логистическую функцию потерь, которая т акже может ис-
пользоваться в задачах классификации:
L(a, Xℓ) =
ℓ∑
i=1
log (1 + exp (−yia(xi))) .
Найдем ее антиградиент после (N − 1)-го шага:
si = yi
1
1 + exp(yiaN− 1(xi))  
=w(N)
i
.
Т еперь веса ограничены сверху единицей. Если отступ на объе кте большой отрица-
тельный (то есть это выброс), то вес при нем будет близок к еди нице; если же отступ
на объекте близок к нулю (то есть это объект , на котором класс ификация неуверен-
ная, и нужно ее усиливать), то вес при нем будет примерно раве н 1/2. Т аким образом,
вес при шумовом объекте будет всего в два раза больше, чем вес при нормальных
объектах, что не должно сильно повлиять на процесс обучения .
9
8 Методы оптимизации второго порядка
(дополнительный материал)
Как мы выяснили выше, градиентный бустинг осуществляет градиентный спуск
в пространстве прогнозов алгоритма на обучающей выборке. З десь может возникнуть
вполне логичный вопрос: а почему бы не воспользоваться друг им, более эффектив-
ным методом оптимизации? Наиболее явными кандидатами явля ются методы опти-
мизации второго порядка /emdash.cyr например, метод Ньютона. При оптимизации числовой
функции Q(w) шаг в методе Ньютона осуществляется по формуле
w(n) = w(n− 1) − H− 1(w(n− 1))∇wQ(w(n− 1)),
где H(w) /emdash.cyr матрица вторых производных, которая также называется матрицей Г ессе.
Этим же подходом можно воспользоваться и в градиентном буст инге. Нам нуж-
но как можно сильнее уменьшить значение следующей функции п утем подбора сдви-
гов si:
Q(s) =
ℓ∑
i=1
L(yi, aN− 1(xi) +si)
Мы уже находили вектор градиента:
∇sQ(s) =g =
(
∂L
∂z
⏐
⏐
⏐
⏐
z=aN− 1(xi)
) ℓ
i=1
Заметим, что матрица вторых производных тут будет диагонал ьной, поскольку каж-
дая переменная si входит лишь в одно отдельное слагаемое:
H = diag
(
∂2L
∂z2
⏐
⏐
⏐
⏐
z=aN− 1(x1)
, . . . , ∂2L
∂z2
⏐
⏐
⏐
⏐
z=aN− 1(xℓ)
)
Мы здесь пользуемся функционалом, который представляет со бой сумму оши-
бок на всех объектах. Т акое представление подходит во многи х задачах, но не яв-
ляется максимально общим. Дело в том, что в некоторых ситуац иях необходимо
использовать функционалы, которые измеряют качество сорт ировки объектов алго-
ритмом /emdash.cyr это, иными словами, функционалы качества ранжирования. Их особен-
ность заключается как раз в том, что матрица вторых производ ной уже не будет
диагональной.
Зная градиент и матрицу Г ессе, мы можем выписать формулу для сдвигов s:
s = −H− 1g
Поскольку обращение матрицы является неустойчивой операц ией, правильнее будет
находить вектор сдвигов через систему линейных уравнений
Hs = −g
В случае с диагональной матрицей Г ессе данный подход сводит ся к домножению
каждой компоненты вектора антиградиента на некоторые коэф фициенты. В общем
10
же случае такой подход может оказаться слишком сложным, пос кольку при больших
размерах выборки матрица Г ессе будет получаться слишком бо льшой для эффектив-
ной работы. После того, как рассчитан вектор сдвигов, проце дура будет такой же,
как и раньше /emdash.cyr обучаем алгоритм на данные сдвиги, находим коэффициент при нем,
добавляем в композицию.
На похожей идее основан метод LogitBoost, который настраив ает композицию
с использованием логистической функции потерь, исходя из н есколько иных пред-
положений. Использование метода Ньютона приводит к тому , ч то базовый алгоритм
настраивается на взвешенный функционал, что может затрудн ять обучение. Более
того, формулы для весов получаются не вполне устойчивыми, и нередко в них про-
исходит деление на очень маленькое число. Чтобы избежать эт ого, вводится ряд
достаточно грубых эвристик.
Обратим внимание, что трюк с переподбором прогнозов в листь ях базовых ре-
шающих деревьев похож на применение метода Ньютона. Допуст им, мы как-то вы-
брали сдвиги si и обучили на них решающее дерево bn(x). После этого на объекте xi
обучающей выборки будет сделан сдвиг bn(xi). Сдвиги будут одинаковыми на тех
объектах, которые попали в один и тот же лист дерева. Если сде лать переподбор, то
сдвиги будут изменены так, чтобы как можно сильнее уменьшат ь исходный функ-
ционал ошибки. По сути, благодаря этому сдвиги подбираются индивидуально под
группы объектов, что близко к использованию методов второг о порядка с диагональ-
ной матрицей Г ессе /emdash.cyr там тоже выставляются индивидуальные коэффициенты при
компонентах сдвига.
Список литературы
[1] Friedman, Jerome H. (2001). Greedy Function Approximation: A Gradient Boostin g
Machine. // Annals of Statistics, 29(5), p. 1189–1232.
[2] Friedman, Jerome H. (1999). Stochastic Gradient Boosting. // Computational
Statistics and Data Analysis, 38, p. 367–378.
[3] Gulin, A., Karpovich, P. (2009). Greedy function optimization in learning to rank.
http://romip.ru/russir2009/slides/yandex/lecture.pdf
