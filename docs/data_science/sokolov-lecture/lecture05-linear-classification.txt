Лекция 5
Линейная классификация
Е. А. Соколов
ФКН ВШЭ
28 октября 2021 г.
1 Линейные модели классификации
Мы начнём с задачи бинарной классификации, а многоклассовы й случай об-
судим позже. Пусть X = Rd /emdash.cyr пространство объектов,Y = {−1, +1} /emdash.cyr множе-
ство допустимых ответов, X = {(xi, yi)}ℓ
i=1 /emdash.cyr обучающая выборка. Иногда мы будем
класс /guillemotleft.cyr+1/guillemotright.cyr называть положительным, а класс /guillemotleft.cyr−1/guillemotright.cyr /emdash.cyr отрицательным.
Линейная модель классификации определяется следующим образом:
a(x) = sign (⟨w, x⟩+ w0) = sign
( d∑
j=1
wjxj + w0
)
,
где w ∈ Rd /emdash.cyr вектор весов,w0 ∈ R /emdash.cyr сдвиг (bias). Заметим, что функцияsign(z)
может выдавать ноль при z = 0, но в множество ответов ноль не входит . Во-первых,
можем понадеяться, что нулевое значение линейной модели /emdash.cyr настолько редкое со-
бытие, что нам не придётся иметь с этим дело. Во-вторых, може м считать, что если
модель выдала ноль, то она не может выбрать класс и отказывае тся от классифика-
ции /emdash.cyr что-то вроде выдачи исключения.
Если не сказано иначе, мы будем считать, что среди признаков есть константа,
xd+1 = 1. В этом случае нет необходимости вводить сдвиг w0, и линейный классифи-
катор можно задавать как
a(x) = sign⟨w, x⟩.
Г еометрически линейный классификатор соответствует гипе рплоскости с век-
тором нормали w. Величина скалярного произведения ⟨w, x⟩ пропорциональна рас-
стоянию от гиперплоскости до точки x, а его знак показывает , с какой стороны от
гиперплоскости находится данная точка. Т аким образом, лин ейный классификатор
разделяет пространство на две части с помощью гиперплоскос ти, и при этом одно
полупространство относит к положительному классу , а друго е /emdash.cyr к отрицательному .
§1.1 Обучение линейных классификаторов
В задаче регрессии имеется континуум возможных ответов, и п ри таких усло-
виях достаточно странно требовать полного совпадения отве тов модели и истинных
1
2
ответов /emdash.cyr гораздо логичнее говорить об их близости. Более того, как мы выясни-
ли, попытка провести функцию через все обучающие точки легк о может привести к
переобучению. Способов посчитать близость двух чисел (про гноза и истинного отве-
та) достаточно много, и поэтому при обсуждении регрессии у н ас возникло большое
количество функционалов ошибки.
В случае с бинарной классификацией всё гораздо проще: у нас в сего два воз-
можных ответа алгоритма и, очевидно, мы хотим видеть как мож но больше пра-
вильных ответов. Соответствующий функционал называется долей правильных от-
ветов (accuracy):
Q(a, X) = 1
ℓ
ℓ∑
i=1
[a(xi) =yi].
Нам будет удобнее решать задачу минимизации, поэтому будем вместо этого исполь-
зовать долю неправильных ответов:
Q(a, X) = 1
ℓ
ℓ∑
i=1
[a(xi) ̸= yi] = 1
ℓ
ℓ∑
i=1
[sign⟨w, xi⟩ ̸= yi] → min
w
(1.1)
Этот функционал является дискретным относительно весов, и поэтому искать его
минимум с помощью градиентных методов мы не сможем. Более то го, у данного
функционала может быть много глобальных минимумов /emdash.cyr вполнеможет оказаться,
что существует много способов добиться оптимального колич ества ошибок. Чтобы
не пытаться решать все эти проблемы, попытаемся свести зада чу к минимизации
гладкого функционала.
Отступы. Заметим, что функционал ( 1.1) можно несколько видоизменить:
Q(a, X) = 1
ℓ
ℓ∑
i=1
[yi⟨w, xi⟩  
Mi
< 0] → min
w
Здесь возникла очень важная величина Mi = yi⟨w, xi⟩, называемая отсту-
пом (margin). Знак отступа говорит о корректности ответа класс ификатора (поло-
жительный отступ соответствует правильному ответу , отриц ательный /emdash.cyr неправиль-
ному), а его абсолютная величина характеризует степень уве ренности классифика-
тора в своём ответе. Напомним, что скалярное произведение ⟨w, x⟩ пропорционально
расстоянию от разделяющей гиперплоскости до объекта; соот ветственно, чем ближе
отступ к нулю, тем ближе объект к границе классов, тем ниже ув еренность в его
принадлежности.
Верхние оценки. Функционал ( 1.1) оценивает ошибку алгоритма на объекте x с
помощью пороговой функции потерь L(M) = [M < 0], где аргументом функции
является отступ M = y⟨w, x⟩. Оценим эту функцию сверху во всех точках M кроме,
может быть, небольшой полуокрестности левее нуля (см. рис. 1):
L(M) ⩽ ˜L(M).
3
−4 −2 0 2 4
0
1
2
3
4
5
6
/uni043F/uni043E/uni0440/uni043E/uni0433/uni043E/uni0432/uni0430/uni044F
/uni043B/uni043E/uni0433/uni0438/uni0441/uni0442/uni0438/uni0447е/uni0441/uni043A/uni0430/uni044F
ме/uni0442/uni043Eч /uni043E/uni043F/uni043E/uni0440/uni043D/uni044B/uni0445 /uni0432/uni0435/uni043A/uni0442/uni043E/uni0440/uni043E/uni0432
/uni044D/uni043A /uni043F/uni043E/uni043D/uni0435/uni043D/uni0446/uni0438/uni0430/uni043B/uni044C/uni043D/uni0430/uni044F
 /uni0438я/uni043C/uni043E/uni0438г/uni043D/uni0430/uni044F
/uni043F/uni0435/uni0440 /uni0435/uni043F/uni0442/uni0440/uni043E/uni043D л/uni043Eм/uni0435/uni043Dь/uni043B/uni0430/uni0442/uni0442/uni0430
Рис. 1. Верхние оценки на пороговую функцию потерь.
После этого можно получить верхнюю оценку на функционал ( 1.1):
Q(a, X) ⩽ 1
ℓ
ℓ∑
i=1
˜L(yi⟨w, xi⟩) → min
w
Если верхняя оценка ˜L(M) является гладкой, то и данная верхняя оценка будет
гладкой. В этом случае её можно будет минимизировать с помощ ью, например, гра-
диентного спуска. Если верхнюю оценку удастся приблизить к нулю, то и доля непра-
вильных ответов тоже будет близка к нулю.
Приведём несколько примеров верхних оценок:
1. ˜L(M) = log
(
1 +e− M )
/emdash.cyr логистическая функция потерь
2. ˜L(M) = (1− M)+ = max(0, 1 − M) /emdash.cyr кусочно-линейная функция потерь (ис-
пользуется в методе опорных векторов)
3. ˜L(M) = (−M)+ = max(0, −M) /emdash.cyr кусочно-линейная функция потерь (соответ-
ствует персептрону Розенблатта)
4. ˜L(M) =e− M /emdash.cyr экспоненциальная функция потерь
5. ˜L(M) = 2/(1 +eM ) /emdash.cyr сигмоидная функция потерь
Любая из них подойдёт для обучения линейного классификатор а. Позже мы подроб-
но изучим некоторые из них и выясним, какими свойствами они о бладают .
2 Метрики качества классификации
Выше мы разобрали способ сведения задачи обучения линейног о классификато-
ра к минимизации гладкого функционала. При этом часто возни кает необходимость
4
в изучении различных аспектов качества уже обученного клас сификатора. Обсудим
подробнее распространённые подходы к измерению качества т аких моделей.
Будем считать, что классификатор имеет вид a(x) = sign(b(x)−t) = 2[b(x) > t]−
− 1. Линейная модель имеет именно такую форму , если положить b(x) =⟨w, x⟩ и t =
= 0.
§2.1 Доля правильных ответов
Наиболее очевидной мерой качества в задаче классификации я вляется доля
правильных ответов (accuracy), которую мы уже упоминали:
accuracy(a, x) = 1
ℓ
ℓ∑
i=1
[a(xi) =yi].
Данная метрика, однако, имеет существенный недостаток. Ес ли взять порог t меньше
минимального значения прогноза b(x) на выборке или больше максимального значе-
ния, то доля правильных ответов будет равна доле положитель ных и отрицательных
ответов соответственно. Т аким образом, если в выборке 950 отрицательных и 50 по-
ложительных объектов, то при тривиальном пороге t = maxi b(xi) мы получим долю
правильных ответов 0.95. Это означает , что доля положительных ответов сама по
себе не несет никакой информации о качестве работы алгоритм а a(x), и вместе с
ней следует анализировать соотношение классов в выборке. Т акже полезно вместе
с долей правильных ответов вычислять базовую долю /emdash.cyr долю правильных ответов
алгоритма, всегда выдающего наиболее мощный класс.
Отметим, что при сравнении различных методов машинного обу чения принято
сообщать относительное уменьшение ошибки. Рассмотрим два алгоритма a1 и a2 с
долями правильных ответов r1 и r2 соответственно, причем r2 > r1. Относительным
уменьшением ошибки алгоритма a2 называется величина
(1 − r1) − (1 − r2)
1 − r1
.
Если доля ошибок была улучшена с 20% до 10%, то относительное улучшение со-
ставляет 50%. Если доля ошибок была улучшена с 50% до 25%, то относительное
улучшение также равно 50%, хотя данный прирост кажется более существенным.
Если же доля ошибок была улучшена с 0.1% до 0.01%, то относительное улучшение
составляет 90%, что совершенно не соответствует здравому смыслу .
§2.2 Матрица ошибок
Выше мы убедились, что в случае с несбалансированными класс ами одной до-
ли правильных ответов недостаточно /emdash.cyr необходима еще одна метрика качества. В
данном разделе мы рассмотрим другую, более информативную п ару критериев.
Введем сначала понятие матрицы ошибок. Это способ разбить о бъекты на че-
тыре категории в зависимости от комбинации истинного ответ а и ответа алгорит-
ма (см. таблицу 1). Через элементы этой матрицы можно, например, выразить до лю
правильных ответов:
accuracy = TP + TN
TP + FP + FN + TN .
5
y = 1 y = −1
a(x) = 1 T rue Positive (TP) False Positive (FP)
a(x) =−1 False negative (FN) T rue Negative (TN)
Т аблица 1. Матрица ошибок
Г ораздо более информативными критериями являются точность (precision)
и полнота (recall):
precision = TP
TP + FP ;
recall = TP
TP + FN .
Т очность показывает , какая доля объектов, выделенных клас сификатором как поло-
жительные, действительно является положительными. Полно та показывает , какая
часть положительных объектов была выделена классификатор ом.
Рассмотрим, например, задачу предсказания реакции клиент а банка на звонок
с предложением кредита. Ответ y = 1 означает , что клиент возьмет кредит после
рекламного звонка, ответ y = −1 /emdash.cyr что не возьмет . Соответственно, планируется
обзванивать только тех клиентов, для которых классификато р a(x) вернет ответ 1.
Если классификатор имеет высокую точность, то практически все клиенты, кото-
рым будет сделано предложение, откликнутся на него. Если кл ассификатор имеет
высокую полноту , то предложение будет сделано практически всем клиентам, ко-
торые готовы откликнуться на него. Как правило, можно регул ировать точность и
полноту , изменяя порог t в классификаторе a(x) = sign(b(x) − t) = 2[b(x) > t] − 1.
Если выбрать t большим, то классификатор будет относить к положительному клас-
су небольшое число объектов, что приведет к высокой точност и и низкой полноте.
По мере уменьшения t точность будет падать, а полнота увеличиваться. Конкретно е
значение порога выбирается согласно пожеланиям заказчика .
Отметим, что точность и полнота не зависят от соотношения ра змеров классов.
Даже если объектов положительного класса на порядки меньше , чем объектов отри-
цательного класса, данные показатели будут корректно отра жать качество работы
алгоритма.
Существует несколько способов получить один критерий каче ства на основе
точности и полноты. Один из них /emdash.cyr F-мера, гармоническое среднее точности и пол-
ноты:
F = 2 ∗ precision ∗ recall
precision + recall .
Среднее гармоническое обладает важным свойством /emdash.cyr оно близко к нулю, если хотя
бы один из аргументов близок к нулю. Именно поэтому оно являе тся более предпо-
чтительным, чем среднее арифметическое (если алгоритм буд ет относить все объ-
екты к положительному классу , то он будет иметь recall = 1 и precision ≪ 1, а их
среднее арифметическое будет больше 1/2, что недопустимо). Можно заметить, что
F-мера является сглаженной версией минимума из точности и п олноты (см. рис. 2
и 3). Отметим, что геометрическое среднее также похоже на сгла женный вариант
минимума, но при этом оно менее устойчиво к /guillemotleft.cyrвыбросам/guillemotright.cyr /emdash.cyr например, для точно-
сти 0.9 и полноты 0.1 гармоническое среднее будет равно 0.18 , а геометрическое 0.3.
6
0.0 0.2 0.4 0.6 0.8 1.0
precision
0.0
0.2
0.4
0.6
0.8
1.0recall
Рис. 2. Линии уровня для минимума из точности
и полноты.
0.0 0.2 0.4 0.6 0.8 1.0
precision
0.0
0.2
0.4
0.6
0.8
1.0recall
Рис. 3. Линии уровня для F-меры.
Другим агрегированным критерием является R-точность, или точка балан-
са (breakeven point). Она вычисляется как точность при тако м t, при котором полнота
равна точности:
R-precision = precision(sign(b(x) − t∗)),
t∗ = arg min
t
|precision(sign(b(x) − t)) − recall(sign(b(x) − t))| .
Можно показать, что R-точность равна точности при таком пор оге, при котором
количество отнесённых к положительному классу объектов ра вно количеству поло-
жительных объектов в выборке.
Часто встречаются задачи, в которых целевой признак по-пре жнему бинарный,
но при этом необходимо ранжировать объекты, а не просто пред сказывать их класс.
Например, в задаче предсказания реакции клиента можно выда вать сортированный
список, чтобы оператор мог в первую очередь позвонить клиен там с наибольшей
вероятностью положительного отклика. Поскольку многие ал горитмы возвращают
вещественный ответ b(x), который затем бинаризуется по порогу t, то можно про-
сто сортировать объекты по значению b(x). Для измерения качества ранжирования
нередко используют среднюю точность (average precision, AP):
AP = 1
ℓ+
ℓ∑
k=1
[y(k) = 1]precision@k,
где y(k) /emdash.cyr ответk-го по порядку объекта, ℓ+ /emdash.cyr число положительных объектов в
выборке, а precision @k /emdash.cyr точность среди первыхk в списке объектов. Если алго-
ритм b(x) так ранжирует объекты, что сначала идут все положительные, а затем
все отрицательные, то средняя точность будет равна единице ; соответственно, чем
сильнее положительные документы концентрируются в верхне й части списка, тем
ближе к единице будет данный показатель.
7
Связь точности, полноты и доли правильных ответов Выше мы отмечали, что
высокие значения доли правильных ответов вовсе не влекут за собой высокое каче-
ство работы классификатора, и ввели точность и полноту как с пособ решения этой
проблемы. Т ем не менее, при выборе точности и полноты в качес тве основных мет-
рик, следует соблюдать осторожность при выборе требований к их значениям /emdash.cyr как
мы увидим из примера, независимость данных метрик от соотно шения классов мо-
жет привести к неочевидным последствиям.
Рассмотрим задачу бинарной классификации с миллионом объе ктов ( ℓ =
= 1.000.000), где доля объектов первого класса составляет 1% (ℓ+ = 10.000). Мы
знаем, что доля правильных ответов будет вести себя не вполн е интуитивно на дан-
ной несбалансированной выборке, и поэтому выберем точност ь и полноту для из-
мерения качества классификаторов. Поскольку мы хотим реши ть задачу хорошо, то
введём требования, что и точность, и полнота должны быть не м енее 90%. Эти требо-
вания кажутся вполне разумными, если забыть о соотношении к лассов. Попробуем
теперь оценить, какая доля правильных ответов должна быть у классификатора,
удовлетворяющего нашим требованиям.
Всего в выборке 10.000 положительных объектов, и для достижения полно-
ты 90% мы должны отнести как минимум 9.000 к положительному классу . Полу-
чаем TP = 9000, FN = 1000. Т ак как точность тоже должна быть не меньше 90%,
получаем FP = 1000. Отсюда получаем, что доля правильных ответов должна быть
равна (1 − 2.000/1.000.000) = 99.8%! Это крайне высокий показатель, и его редко
удаётся достичь на таких выборках во многих предметных обла стях.
Lift. На практике часто возникают задачи, связанные с выбором под множества: вы-
деление лояльных клиентов банка, обнаружение уходящих пол ьзователей мобильно-
го оператора и т .д. Заказчика может интересовать вопрос, на сколько выгоднее рабо-
тать с этим подмножеством по сравнению со всем множеством. Е сли при рассылке
предложений о кредите клиентам из подмножества и всем клиен там будет получать-
ся одна и та же доля откликнувшихся, то подмножество не будет представлять осо-
бой ценности. Формально это измеряется с помощью прироста концентрации (lift),
который равен отношению точности к доле положительных объе ктов в выборке:
lift = precision
(TP + FN)/ℓ.
Эту величину можно интерпретировать как улучшение доли пол ожительных объек-
тов в данном подмножестве относительно доли в случайно выбр анном подмножестве
такого же размера.
§2.3 Area Under Curve
Выше мы изучили точность, полноту и F-меру , которые характе ризуют каче-
ство работы алгоритма a(x) = sign(b(x)−t) при конкретном выборе порога t. Однако
зачастую интерес представляет лишь вещественнозначный ал горитм b(x), а порог
будет выбираться позже в зависимости от требований к точнос ти и полноте. В та-
ком случае возникает потребность в измерении качества семе йства моделей {a(x) =
= sign(b(x) − t) | t ∈ R}.
8
Рис. 4. Пример ROC-кривой.
Можно измерять качество этого множества на основе качества лучшего (в
некотором смысле) алгоритма. Для этого подходит упомянута я ранее точка балан-
са (breakeven point). В идеальном семействе алгоритмов она будет равна единице,
поскольку найдется алгоритм со стопроцентной точностью и п олнотой. Данная мет-
рика, однако, основывается лишь на качестве одного алгорит ма, и не характеризует
вариативность семейства.
Широко используется такая интегральная метрика качества с емейства, как пло-
щадь под ROC-кривой (Area Under ROC Curve, AUC-ROC). Рассмотрим двумерное
пространство, одна из координат которого соответствует до ле неверно принятых объ-
ектов (False Positive Rate, FPR), а другая /emdash.cyr доле верно принятых объектов (T rue
Positive Rate, TPR):
FPR = FP
FP + TN ;
TPR = TP
TP + FN .
Каждый возможный выбор порога t соответствует точке в этом пространстве. Все-
го различных порогов имеется ℓ + 1. Максимальный порог tmax = maxi b(xi) даст
классификатор с TPR = 0, FPR = 0. Минимальный порог tmin = mini b(xi) − ε
даст TPR = 1 и FPR = 1. ROC-кривая /emdash.cyr это кривая с концами в точках(0, 0)
и (1, 1), которая последовательно соединяет точки, соответствующ ие порогам b(x(1))−
− ε, b(x(1)), b(x(2)), . . . , b(x(ℓ)) (см. рис. 4). Площадь под данной кривой называется
AUC-ROC, и принимает значения от 0 до 1. Если порог t может быть подобран так,
что алгоритм a(x) не будет допускать ошибок, то AUC-ROC будет равен единице;
если же b(x) ранжирует объекты случайным образом, то AUC-ROC будет близ ок
к 0.5.
9
Критерий AUC-ROC имеет большое число интерпретаций /emdash.cyr например, он ра-
вен вероятности того, что для случайно выбранных положител ьного объекта x+ и
отрицательного объекта x− будет выполнено 1 b(x+) > b(x− ).
Индекс Джини. В задачах кредитного скоринга вместо AUC-ROC часто использ у-
ется пропорциональная метрика, называемая индексом Джини (Gini index):
Gini = 2AUC − 1.
По сути это умноженная на два площадь между ROC-кривой и диаг ональю, соеди-
няющей точки (0, 0) и (1, 1).
Отметим, что переход от AUC к индексу Джини приводит к увелич ению отно-
сительных разниц. Если мы смогли улучшить AUC с 0.8 до 0.9, то это соответству-
ет относительному улучшению в 12.5%. В то же время соответствующие индексы
Джини были улучшены с 0.6 до 0.8, то есть на 33.3% /emdash.cyr относительное улучшение
повысилось почти в три раза!
Чувствительность к соотношению классов. Рассмотрим задачу выделения ма-
тематических статей из множества научных статей. Допустим , что всего имеет-
ся 1.000.100 статей, из которых лишь 100 относятся к математике. Если нам удастся
построить алгоритм a(x), идеально решающий задачу , то его TPR будет равен еди-
нице, а FPR /emdash.cyr нулю. Рассмотрим теперь плохой алгоритм, дающий положительный
ответ на 95 математических и 50.000 нематематических статьях. Т акой алгоритм со-
вершенно бесполезен, но при этом имеет TPR = 0.95 и FPR = 0.05, что крайне близко
к показателям идеального алгоритма.
Т аким образом, если положительный класс существенно меньш е по размеру , то
AUC-ROC может давать неадекватную оценку качества работы а лгоритма, посколь-
ку измеряет долю неверно принятых объектов относительно об щего числа отрица-
тельных. Т ак, алгоритм b(x), помещающий 100 релевантных документов на позиции
с 50.001-й по 50.101-ю, будет иметь AUC-ROC 0.95.
Precison-recall кривая. Избавиться от указанной проблемы с несбалансированными
классами можно, перейдя от ROC-кривой к Precision-Recall к ривой. Она определя-
ется аналогично ROC-кривой, только по осям откладываются н е FPR и TPR, а пол-
нота (по оси абсцисс) и точность (по оси ординат). Критерием качества семейства
алгоритмов выступает площадь под PR-кривой (AUC-PR). Данн ую величину можно
аппроксимировать следующим образом. Стартуем из точки (0, 1). Будем идти по ран-
жированной выборке, начиная с первого объекта; пусть текущ ий объект находится
на позиции k. Если он относится к классу /guillemotleft.cyr−1/guillemotright.cyr , то полнота не меняется, точность па-
дает /emdash.cyr соответственно, кривая опускается строго вниз. Еслиже объект относится к
классу /guillemotleft.cyr1/guillemotright.cyr , то полнота увеличивается на1/ℓ+, точность растет , и кривая поднимает-
ся вправо и вверх. Площадь под этим участком можно аппроксим ировать площадью
прямоугольника с высотой, равной precision @k и шириной 1/ℓ+. При таком способе
подсчета площадь под PR-кривой будет совпадать со средней т очностью:
AUC-PR = 1
ℓ+
ℓ∑
k=1
[yk = 1]precision@k.
1При условии, что прогнозы на всех объектах выборки попарно различны.
10
Отметим, что AUC-PR дает разумные результаты в рассмотренн ом выше при-
мере с классификацией статей. Т ак, при размещении 100 релевантных документов
на позициях 50.001-50.101 в ранжированном списке, AUC-PR будет равен 0.001.
Несмотря на указанные различия, между ROC- и PR-кривой имее тся тесная
связь. Т ак, можно показать, что если ROC-кривая одного алго ритма лежит полно-
стью над ROC-кривой другого алгоритма, то и PR-кривая одног о лежит над PR-
кривой другого [ 1].
Список литературы
[1] Davis J., Goadrich M. (2006). The Relationship Between Precision-Recall and ROC
Curves. // Proceedings of the 23rd International Conferenc e on Machine Learning,
Pittsburgh, P A.
