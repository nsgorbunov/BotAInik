Лекция 1
Введение в машинное обучение
Е. А. Соколов
ФКН ВШЭ
5 сентября 2021 г.
В последнее время стало появляться всё больше данных. Униве рситеты зна-
ют всё про своих студентов /emdash.cyr оценки и достижения за школьное время, выбранные
курсы, результаты всех сессий, стажировки и практики, темы курсовых, карьерный
путь после выпуска. Многое знают про своих клиентов банки, м обильные операторы,
страховые компании, авиаперевозчики. Автомобили и самолё ты порождают огром-
ное количество данных за каждую минуту работы. Что с этим все м делать? Можно
строить аналитику , следить за какими-нибудь падениями, пы таться найти законо-
мерности в поведении пользователей /emdash.cyr например, искать неэффективные тарифы
или неприбыльные направления. Но ещё нередко хочется испол ьзовать данные, что-
бы принимать решения /emdash.cyr кому какую страховку предлагать, когда и что менять в
самолёте, какие олимпиады учитывать при наборе студентов, какие страницы пока-
зывать конкретному пользователю в поисковой выдаче. Для эт их задач не существу-
ет точных решений, поскольку мы слишком мало понимаем в проц ессах, лежащих в
их основе, и не можем построить точную модель, как это делает ся, скажем, в физике.
Но зато у нас есть много данных с примерами правильных решени й! Мы уже знаем,
какая страховка подошла в прошлом каждому из клиентов, и кто из студентов смог
успешно завершить обучение. Т ак возникает машинное обучен ие, методы которого
пытаются строить модели на основе данных, а не исходя из пони мания природы. О
нём и пойдёт речь в нашем курсе.
1 Основные определения и постановки задач
Машинное обучение /emdash.cyr это наука, изучающая способы извлечения закономерно-
стей из ограниченного количества примеров. Есть ещё много б лизких направлений.
Например, к анализу данных можно отнести любую работу , связанную с извлечением
полезной информации из данных, даже если это извлечение дел ается методом при-
стального взгляда. Последнее время нередко говорят про искусственный интеллект,
но зачастую это оказывается лишь более красивым названием д ля результатов, по-
лученных методами машинного обучения. Впрочем, обсуждени е терминологии вряд
ли нам сильно поможет , поэтому лучше перейдём к конкретному примеру .
1
2
Представим, что нам принадлежит большая сеть ресторанов, и мы хотим от-
крыть в неком городе новое заведение 1. Мы нашли несколько точек в городе, где
есть возможность приобрести помещение и организовать там р есторан. Нам важно,
чтобы через определенное время он стал приносить прибыль /emdash.cyr точнее, хочется от-
крыть его в той точке, в которой прибыль окажется максимальн ой. Поставим задачу:
для каждого возможного размещения ресторана предсказать п рибыль, которую он
принесет в течение первого года.
Объектом мы будем называть то, для чего хотим сделать предсказание. В на-
шем случае это конкретная точка размещения ресторана. Обоз начать объект мы бу-
дем маленькой буквой x, а если их несколько, то будем добавлять нижние индексы.
Множество всех возможных точек размещения называется пространством объектов
и обозначается через X. Величина, которую мы хотим определять (т .е. прибыль ре-
сторана), называется ответом или целевой переменной, а множество ее значений /emdash.cyr
пространством ответов Y. В нашем случае пространство ответов является множе-
ством вещественных чисел: Y = R. Отдельные ответы будем обозначать маленькой
буквой y.
Мы не являемся специалистами в экономике, поэтому не можем с делать такие
прогнозы на основе своих экспертных знаний. У нас есть лишь п римеры /emdash.cyr посколь-
ку мы владеем целой сетью ресторанов, то имеем данные по дост аточно большому
числу ранее открытых ресторанов и по их прибыли в течение пер вого года. Каждый
такой пример называется обучающим, а вся их совокупность /emdash.cyrобучающей выбор-
кой, которая обозначается как X = {(x1, y1), . . . ,(xℓ, yℓ)}, где x1, . . . , xℓ /emdash.cyr обучающие
объекты, а ℓ /emdash.cyr их количество. Особенность обучающих объектов состоит в том, что
для них известны ответы y1, . . . , yℓ.
Отметим, что объекты /emdash.cyr это некие абстрактные сущности (точки размещения
ресторанов), которыми компьютеры не умеют оперировать нап рямую. Для дальней-
шего анализа нам понадобится описать объекты с помощью неко торого набора харак-
теристик, которые называются признаками (или факторами). Вектор всех признаков
объекта x называется признаковым описанием этого объекта. Далее мы будем отож-
дествлять объект и его признаковое описание. Признаки могу т быть очень разными:
бинарными, вещественными, категориальными (принимают зн ачения из неупорядо-
ченного множества), ординальными (принимают значения из у порядоченного мно-
жества), множествозначными (set-valued, значения являют ся подмножествами неко-
торого универсального множества). Признаки могут иметь сл ожную внутреннюю
структуру: так, в качестве признака для конкретного челове ка в задаче предсказа-
ния его годового дохода может служить фотография. Разумеет ся, фотографию мож-
но представить и как некоторое количество бинарных или веще ственных признаков,
каждый из которых кодирует соответствующий пиксель изобра жения. Однако, ра-
бота с изображением как с одной сложной структурой позволяе т вычислять по нему
различные фильтры, накладывать требование инвариантност и ответа к сдвигам и
т .д. На работе со сложными данными специализируется активн о развивающееся сей-
час глубинное обучение (deep learning).
В нашей задаче полезными могут оказаться признаки, связанн ые с демографи-
ей (средний возраст жителей ближайших кварталов, динамика изменения количества
жителей) или недвижимостью (например, средняя стоимость к вадратного метра в
1Задача по мотивам конкурса Restaurant Revenue Prediction: https://www.kaggle.com/c/
restaurant-revenue-prediction
3
окрестности, количество школ, магазинов, заправок, торго вых центров, банков по-
близости). Разработка признаков (feature engineering) дл я любой задачи является
одним из самых сложных и самых важных этапов анализа данных.
Описанная задача является примером задачи обучения с учителем (supervised
learning), а более конкретно задачей регрессии /emdash.cyr именно так называются задачи с
вещественной целевой переменной. Перечислим несколько др угих видов задач обу-
чения с учителем:
1. Y = {0, 1} /emdash.cyr бинарная классификация. Например, мы можем предсказывать,
кликнет ли пользователь по рекламному объявлению, вернет л и клиент кре-
дит в установленный срок, сдаст ли студент сессию, случится ли определенное
заболевание с пациентом (на основе, скажем, его генома).
2. Y = {1, . . . , K} /emdash.cyr многоклассовая (multi-class) классификация. Примером мо-
жет служить определение предметной области для научной ста тьи (математи-
ка, биология, психология и т .д.).
3. Y = {0, 1}K /emdash.cyr многоклассовая классификация с пересекающимися класса-
ми (multi-label classiﬁcation). Примером может служить за дача автоматическо-
го проставления тегов для ресторанов (логично, что рестора н может одновре-
менно иметь несколько тегов).
4. Частичное обучение (semi-supervised learning) /emdash.cyr задача, в которой для одной
части объектов обучающей выборки известны и признаки, и отв еты, а для дру-
гой только признаки. Т акие ситуации возникают , например, в медицинских
задачах, где получение ответа является крайне сложным (нап ример, требует
проведения дорогостоящего анализа).
Существует также обучение без учителя /emdash.cyr класс задач, где ответы неизвестны или
вообще не существуют , и требуется найти некоторые закономе рности в данных лишь
на основе признаковых описаний:
1. Кластеризация /emdash.cyr задача разделения объектов на группы, обладающие неко-
торыми свойствами. Примером может служить кластеризация д окументов из
электронной библиотеки или кластеризация абонентов мобил ьного оператора.
2. Оценивание плотности /emdash.cyr задача приближения распределения объектов. При-
мером может служить задача обнаружения аномалий, в которой на этапе обу-
чения известны лишь примеры /guillemotleft.cyrправильного/guillemotright.cyr поведения оборудования (или,
скажем, игроков на бирже), а в дальнейшем требуется обнаруж ивать случаи
некорректной работы (соответственно, незаконного поведе ния игроков). В та-
ких задачах сначала оценивается распределение /guillemotleft.cyrправильных/guillemotright.cyr объектов, а за-
тем аномальными объявляются все объекты, которых в рамках э того распре-
деления получают слишком низкую вероятность.
3. Визуализация /emdash.cyr задача изображения многомерных объектовв двумерном или
трехмерном пространстве таким образом, чтобы сохранялось как можно больше
зависимостей и отношений между ними.
4
4. Понижение размерности /emdash.cyr задача генерации таких новых признаков, что их
меньше, чем исходных, но при этом с их помощью задача решаетс я не хуже (или
с небольшими потерями качества, или лучше /emdash.cyr зависит от постановки). К этой
же категории относится задача построения латентных моделе й, где требуется
описать процесс генерации данных с помощью некоторого (как правило, неболь-
шого) набора скрытых переменных. Примерами являются задач и тематическо-
го моделирования и построения рекомендаций, которым будет посвящена часть
курса.
Бывают и более сложные постановки /emdash.cyr например, обучение с подкреплени-
ем (reinforcement learning), где алгоритм на каждом шаге на блюдает какую-то си-
туацию, выбирает одно из доступных ему действий, получает н екоторую награду и
корректирует свою стратегию. Задачей алгоритма при этом яв ляется максимизация
награды в некотором смысле. В такую постановку хорошо вписы вается, например,
задача создания беспилотного автомобиля: машина /guillemotleft.cyrвидит/guillemotright.cyr текущее окружение за
счёт сенсоров и должна решить, как сейчас повернуть руль, ка к сильно ускориться
или затормозить. При этом она должна приехать в конкретную т очку , не нарушая
правила, и согласно этим требованиям в каждый момент она пол учает некоторую
награду /emdash.cyr скажем, если она превысила допустимую скорость и отдалилась от точки
назначения, то награда будет очень низкой. Впрочем, задача обучения с подкреп-
лением очень непростая, и пока что построение беспилотных а втомобилей исключи-
тельно на таком подходе /emdash.cyr скорее исследовательский вопрос.
Вернемся к нашей задаче по предсказанию прибыли ресторана. Предположим,
что мы собрали обучающую выборку и изобрели некоторое колич ество признаков.
Результатом будет матрица /guillemotleft.cyrобъекты-признаки/guillemotright.cyrX ∈ Rℓ× d (ℓ /emdash.cyr число объектов,d /emdash.cyr
число признаков), в которой каждая строка содержит признак овое описание одно-
го из обучающих объектов. Т аким образом, строки в этой матри це соответствуют
объектам, а столбцы /emdash.cyr признакам. Отметим, что здесь имеет место небольшая тер-
минологическая путаница: буквой X мы обозначаем и обучающую выборку (которая
содержит в себе объекты и ответы), и матрицу /guillemotleft.cyrобъекты-признаки/guillemotright.cyr (которая содер-
жит в себе только объекты). Т ем не менее, из контекста всегда будет ясно, о чём
именно идёт речь.
Нашей задачей является построение функции a : X → Y, которая для любого
объекта будет предсказывать ответ . Т акая функция называет ся алгоритмом или мо-
делью. Понятно, что нам подойдет далеко не каждый алгоритм /emdash.cyr например, вряд
ли мы извлечем какую-то выгоду из алгоритма a(x) = 0, который предсказывает
нулевую прибыль для любого ресторана независимо от его приз наков. Чтобы фор-
мализовать соответствие алгоритма нашим ожиданиям, нужно ввести функционал
качества 2, измеряющий качество работы алгоритма. Если функционал ус троен так,
что его следует минимизировать, то логичнее называть его функционалом ошибки.
Крайне популярным функционалом в задаче регрессии являетс я среднеквадратич-
ная ошибка (mean squared error, MSE):
Q(a, X) = 1
ℓ
ℓ∑
i=1
(a(xi) − yi)2 .
2Достаточно часто употребляется термин /guillemotleft.cyrметрика качества/guillemotright.cyr, но он является не очень удачным,
поскольку вызывает лишние ассоциации с метриками, обсужда емыми в алгебре. Т ем не менее, мы
иногда будем использовать этот термин для разнообразия.
5
Чем более маленькое значение этого функционала дает алгори тм, тем он лучше. Дан-
ный функционал является очень удобным благодаря дифференц ируемости и просто-
те, но, как мы увидим дальше в курсе, обладает и большим колич еством недостатков.
В большинстве случаев функционалы представляют собой сумм у или среднее
значение ошибок на отдельных объектах обучающей выборки. Ф ункция, измеряющая
ошибку одного предсказания, называется функцией потерь L : Y× Y → R+ (в нашем
случае L(y, z) = (y − z)2). Аргументами функции потерь являются правильный ответ
на данном объекте и прогноз модели на нём же.
Заметим, что именно функционал ошибки будет определять во в сех дальнейших
рассуждениях, какой алгоритм является лучшим. Если функци онал выбран неудачно
и не соответствует бизнес-требованиям или особенностям да нных, то все дальнейшие
действия обречены на провал. Именно поэтому выбор функцион ала является крайне
важным этапом в решении любой задачи машинного обучения. Он не обязательно
должен обладать хорошими математическими свойствами (неп рерывность, выпук-
лость, дифференцируемость и т .д.), но обязан отражать все в ажные требования к
решению задачи.
Как только функционал ошибки зафиксирован, можно приступа ть к построе-
нию алгоритма a(x). Как правило, для этого фиксируют некоторое семейство алго-
ритмов A, и пытаются выбрать из него алгоритм, наилучший с точки зрен ия функ-
ционала 3. В машинном обучении было изобретено большое количество се мейств
алгоритмов, и, наверное, самым простым и самым тщательно из ученным среди них
является семейство линейных моделей, которые дают предсказание, равное линейной
комбинации признаков (с добавлением свободного коэффицие нта w0):
A = {a(x) =w0 + w1x1 + · · ·+ wdxd |w0, w1, . . . , wd ∈ R},
где через xi обозначается значение i-го признака у объекта x. Лучшая из таких
моделей может быть выбрана, например, путем минимизации MS E:
1
ℓ
ℓ∑
i=1
(
w0 +
d∑
j=1
wj xij − yi
) 2
→ min
w0,w1,...,wd
.
Через xij здесь обозначается значение j-го признака на i-м объекте. Процесс поиска
оптимального алгоритма называется обучением. Если модель a(x) дифференцируема
по параметрам w, то можно искать лучший набор параметров с помощью градиент -
ных методов /emdash.cyr стартовать из случайной точки и двигать параметры в сторону наи-
скорейшего убывания функционала ошибки (то есть в сторону а нтиградиента). Для
выпуклых функционалов такой метод найдёт глобальный миним ум; для невыпуклых
функционалов есть лишь гарантии сходимости к локальному ми нимуму . При этом
может возникнуть вопрос о том, как добиться сходимости к луч шему из локальных
минимумов, и подходить к нему можно по-разному /emdash.cyr например, с помощью вы-
бора грамотного начального приближения или через выбор бол ее сложного метода
оптимизации. В то же время дифференцируемые модели, поддаю щиеся оптимиза-
ции, по сути, представляют собой последовательность несло жных преобразований
3/guillemotleft.cyrПытаются выбрать/guillemotright.cyr /emdash.cyr потому что функционал может оказать слишком сложным, не позволя-
ющим сделать точный поиск глобального минимума. В этом случ ае часто ограничиваются поиском
локального экстремума.
6
данных, и не факт , что такие модели смогут заменить сложные с труктуры данных
или программы с ветвлениями и циклами. На сегодняшний день с уществует не так
много видов недифференцируемых моделей, поддающихся эффе ктивному обучению,
но среди них есть очень успешные примеры /emdash.cyr например, градиентный бустинг над
решающими деревьями.
Зачастую возникает потребность в предобработке данных до начала построения
модели. Здесь может идти речь о некотором ряде манипуляций:
• Некоторые модели хорошо работают только при выполнении опр еделенных тре-
бований. Т ак, при обучении линейных моделей важно, чтобы пр изнаки бы-
ли масштабированными, то есть измерялись в одной шкале. Примером спо-
соба нормировки данных является вычитание среднего и делен ие на дисперсию
каждого столбца в матрице /guillemotleft.cyrобъекты-признаки/guillemotright.cyr .
• Бывает , что в выборку попадают выбросы /emdash.cyr объекты, которые не являются
корректными примерами из-за неправильно посчитанных приз наков, ошибки
сбора данных или чего-то еще. Их наличие может сильно испорт ить модель.
• Некоторые признаки могут оказаться шумовыми, то есть не имеющими ника-
кого отношения к целевой переменной и к решаемой задаче. При мером, скорее
всего, может служить признак /guillemotleft.cyrфаза луны в день первого экзамена/guillemotright.cyr в задаче
предсказания успешности прохождения сессии студентом.
Как показывает практика, простейшая предобработка данных может радикально
улучшить качество итоговой модели.
Во время обучения модели очень важно следить за тем, чтобы не произошло пе-
реобучения (overﬁtting). Разберем это явление на примере. Допустим, ч то мы выбра-
ли очень богатое семейство алгоритмов, состоящее из всех во зможных функций: A =
= {a : X → Y}. В этом семействе всегда будет алгоритм, не допускающий ни о дной
ошибки на обучающей выборке, который просто запоминает ее:
a(x) =
{
yi, если x = xi,
0, если x /∈ X.
Очевидно, что такой алгоритм нас не устраивает , поскольку д ля любого нового ресто-
рана предскажет нулевую прибыль. Алгоритм оказался переобученным /emdash.cyr он слиш-
ком сильно подогнался под обучающую выборку , не выявив ника ких закономерностей
в ней. Существует ряд методов, направленных на борьбу с пере обучением, которые
мы будем обсуждать на следующих занятиях. Впрочем, одну из и дей мы можем
обсудить уже сейчас. В нашем примере переобучение возникло из-за большой слож-
ности семейства /emdash.cyr алгоритмом могла оказаться любая функция. Очевидно, что если
бы мы ограничили себя только линейными моделями, то итоговы й алгоритм уже не
смог бы запомнить всю выборку . Т аким образом, можно боротьс я с переобучением
путем контроля сложности семейства алгоритмов/emdash.cyr чем меньше у нас данных для
обучения, тем более простые семейства следует выбирать.
После того, как модель построена, нам нужно оценить, наскол ько хорошо она
будет работать на новых данных. Для этого, например, можно в самом начала от-
ложить часть обучающих объектов и не использовать их при пос троении модели.
Т огда можно будет измерить качество готовой модели на этой отложенной выборке,
7
получив тем самым оценку того, насколько она готова к работе на новых данных. Су-
ществуют и более сложный класс методов, называемый кросс-в алидацией, о котором
речь пойдет позже.
Итак, перечислим основные этапы решения задачи машинного о бучения:
1. Постановка задачи;
2. Выделение признаков;
3. Формирование выборки;
4. Выбор функционала ошибки;
5. Предобработка данных;
6. Построение модели;
7. Оценивание качества модели.
На самом деле, этим всё не заканчивается, и дальше построенн ую модель на-
до внедрить. Например, мы делали модель, предсказывающую для каждого к лиента
мобильного оператора, уйдёт ли он к конкурентам в ближайший месяц. Когда модель
готова, надо встроить её в инфраструктуру , чтобы она автома тически применялась
для каждого клиента, информация по потенциально уходящим к лиентам сама при-
ходила куда надо и сразу же использовалась для удержания. А е щё наверняка будут
определённые требования к быстродействию этой модели /emdash.cyr и этого тоже надо будет
добиться. Это большое направление, но оно выходит за рамки н ашего курса.
2 Немного примеров
Очевидно, что машинное обучение не следует применять везде , где требуется
построить зависимость одной переменной от набора других. Н апример, нет смысла
восстанавливать зависимость силы от массы и ускорения /emdash.cyr на эту задачу точный
ответ даёт второй закон Ньютона. Аналогично, нет смысла стр оить модель, которая
выбирает сортирующую перестановку для массива чисел /emdash.cyr это можно быстро и точно
сделать с помощью, например, сортировки слиянием.
Задача предсказания прибыли ресторана, которую мы разобра ли, хорошо под-
ходит для решения методами машинного обучения по ряду причи н:
• Нельзя вывести корректную формулу будущей прибыли из каких -либо знаний
об устройстве мира.
• Предсказываемая прибыль действительно зависит от признак ов, но при этом
вид зависимости достаточно сложный, и подобрать его вручну ю может быть
слишком трудно.
• Можно набрать достаточное количество примеров (т .е. объек тов с известны-
ми ответами), по которым можно оценить зависимость целевой переменной от
признаков.
8
Задачи такого типа встречаются часто, и машинное обучение и спользуется в
них достаточно широко /emdash.cyr собираются большие объёмы данных, формируются при-
знаки, которые потенциально могут влиять на целевую переме нную, и затем автома-
тически строится предсказывающая модель. К этому классу за дач относятся пред-
сказание дефолта (вернёт ли клиент кредит), предсказание о ттока (уйдёт ли клиент
к конкуренту), предсказание спроса на товары, построение р екомендаций (какой то-
вар может заинтересовать пользователя).
Машинное обучение может использоваться и по другим причина м. Рассмотрим
ещё несколько типов задач:
1. Бывает , что зависимость ответа от признаков вполне понят на, но при этом са-
мо построение ответа достаточно трудоёмко. Например, ферм ерам приходится
классифицировать огурцы по качеству 4. Критерии попадания в каждый класс
можно в той или иной степени формализовать, но при этом прове рять их для
каждого огурца получается не очень быстро. Методами машинн ого обучения
можно построить модель, которая будет автоматически извле кать информатив-
ные факторы из фотографии и определять класс. Если качество классифика-
ции будет высоким, то такая модель позволит существенно пов ысить эффек-
тивность работы.
2. Алгоритм решения некоторых задач невозможно записать, н о при этом люди
успешно справляются с этими задачами при наличии опыта. При мером может
служить управление процессом выплавки стали (опытные инже неры делают
это практически без ошибок, но при этом не существует формал ьного алгорит-
ма) или игра в го. Определять наиболее подходящий ход в го с по мощью пере-
бора невозможно, но лучшие игроки могут очень неплохо оцени ть выгоду того
или иного хода. С помощью машинного обучения можно по пример ам матчей
сформировать модель, оценивающую ходы /emdash.cyr как показал примералгоритма
AlphaGo, такой подход может давать достаточно неплохие рез ультаты.
4https://cloud.google.com/blog/big-data/2016/08/how-a-japanese-cucumber-farmer-is-
using-deep-learning-and-tensorflow
