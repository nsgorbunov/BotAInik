Лекция 9
Бэггинг , случайные леса и разложение ошибки
на смещение и разброс
Е. А. Соколов
ФКН ВШЭ
8 ноября 2021 г.
При обсуждении решающих деревьев мы упомянули, что они могу т восстанав-
ливать очень сложные закономерности, но при этом неустойчи вы к малейшим изме-
нениям в данных. Из-за этого сами по себе деревья не очень хор оши, но при этом,
как оказывается, при объединении в композицию они показывают очень хорошие
результаты. Одним из подходов к построению композиций явля ется бэггинг, кото-
рый независимо строит несколько моделей и усредняет их отве ты. На данной лекции
мы изучим инструмент , который поможет нам в анализе бэггинг а /emdash.cyr декомпозицию
ошибки на компоненты смещения и разброса (bias-variance de composition) /emdash.cyr а затем
перейдем к самим методам. Т акже существует другой подход к п остроению компо-
зиций, называемый бустингом, который строит модели последовательно, и каждая
следующая модель исправляет ошибки предыдущей. О таких мет одах речь пойдёт
уже на следующих лекциях.
1 Бутстрап
Рассмотрим простой пример построения композиции алгоритм ов. Пусть дана
конечная выборка X = (xi, yi) с вещественными ответами. Будем решать задачу
линейной регрессии. Сгенерируем подвыборку с помощью бутстрапа. Равномерно
возьмем из выборки ℓ объектов с возвращением. Отметим, что из-за возвращения
среди них окажутся повторы. Обозначим новую выборку через X1. Повторив про-
цедуру N раз, сгенерируем N подвыборок X1, . . . , X N . Обучим по каждой из них
линейную модель регрессии, получив базовые алгоритмы b1(x), . . . , b N (x).
Предположим, что существует истинная функция ответа для вс ех объек-
тов y(x), а также задано распределение на объектах p(x). В этом случае мы можем
записать ошибку каждой функции регрессии
εj(x) =bj (x) − y(x), j = 1, . . . , N,
и записать матожидание среднеквадратичной ошибки
Ex(bj (x) − y(x))2 = Exε2
j(x).
1
2
Средняя ошибка построенных функций регрессии имеет вид
E1 = 1
N
N∑
j=1
Exε2
j(x).
Предположим, что ошибки несмещены и некоррелированы:
Exεj(x) = 0;
Exεi(x)εj(x) = 0, i ̸= j.
Построим теперь новую функцию регрессии, которая будет уср еднять ответы
построенных нами функций:
a(x) = 1
N
N∑
j=1
bj (x).
Найдем ее среднеквадратичную ошибку:
EN = Ex
(
1
N
n∑
j=1
bj (x) − y(x)
) 2
=
= Ex
(
1
N
N∑
j=1
εj(x)
) 2
=
= 1
N2 Ex
( N∑
j=1
ε2
j(x) +
∑
i̸=j
εi(x)εj(x)

 
=0
)
=
= 1
N E1.
Т аким образом, усреднение ответов позволило уменьшить сре дний квадрат ошибки
в N раз!
Следует отметить, что рассмотренный нами пример не очень пр именим на прак-
тике, поскольку мы сделали предположение о некоррелирован ности ошибок, что ред-
ко выполняется. Если это предположение неверно, то уменьше ние ошибки оказыва-
ется не таким значительным. Позже мы рассмотрим более сложн ые методы объеди-
нения алгоритмов в композицию, которые позволяют добиться высокого качества в
реальных задачах.
2 Bias-Variance decomposition
Допустим, у нас есть некоторая выборка, на которой линейные методы работа-
ют лучше решающих деревьев с точки зрения ошибки на контроле . Почему это так?
Чем можно объяснить превосходство определенного метода об учения? Оказывается,
ошибка любой модели складывается из трех факторов: сложнос ти самой выборки,
сходства модели с истинной зависимостью ответов от объекто в в выборке, и богатства
3
семейства, из которого выбирается конкретная модель. Межд у этими факторами су-
ществует некоторый баланс, и уменьшение одного из них приво дит к увеличению
другого. Т акое разложение ошибки носит название разложени я на смещение и раз-
брос, и его формальным выводом мы сейчас займемся.
Пусть задана выборка X = (xi, yi)ℓ
i=1 с вещественными ответами yi ∈ R (рас-
сматриваем задачу регрессии). Будем считать, что на простр анстве всех объектов и
ответов X × Y существует распределение p(x, y), из которого сгенерирована выбор-
ка X и ответы на ней.
Рассмотрим квадратичную функцию потерь
L(y, a) =
(
y − a(x)
) 2
и соответствующий ей среднеквадратичный риск
R(a) =Ex,y
[ (
y − a(x)
) 2]
=
∫
X
∫
Y
p(x, y)
(
y − a(x)
) 2
dxdy.
Данный функционал усредняет ошибку модели в каждой точке пр остранства x и для
каждого возможного ответа y, причём вклад пары (x, y), по сути, пропорционален
вероятности получить её в выборке p(x, y). Разумеется, на практике мы не можем
вычислить данный функционал, поскольку распределение p(x, y) неизвестно. Т ем не
менее, в теории он позволяет измерить качество модели на все х возможных объектах,
а не только на обучающей выборке.
§2.1 Минимум среднеквадратичного риска
Покажем, что минимум среднеквадратичного риска достигает ся на функции,
возвращающей условное матожидание ответа при фиксированн ом объекте:
a∗(x) =E[y | x] =
∫
Y
yp(y | x)dy = arg min
a
R(a).
Преобразуем функцию потерь:
L(y, a(x)) = (y − a(x))2 = (y − E(y | x) +E(y | x) − a(x))2 =
= (y − E(y | x))2 + 2
(
y − E(y | x)
)(
E(y | x) − a(x)
)
+ (E(y | x) − a(x))2.
Подставляя ее в функционал среднеквадратичного риска, пол учаем:
R(a) =Ex,yL(y, a(x)) =
= Ex,y(y − E(y | x))2 + Ex,y(E(y | x) − a(x))2+
+ 2Ex,y
(
y − E(y | x)
)(
E(y | x) − a(x)
)
.
Разберемся сначала с последним слагаемым. Перейдём от мато жидания Ex,y[f(x, y)]
к цепочке матожиданий
ExEy[f(x, y) | x] =
∫
X
( ∫
Y
f(x, y)p(y | x)dy
)
p(x)dx
4
и заметим, что величина
(
E(y | x)−a(x)
)
не зависит от y, и поэтому ее можно вынести
за матожидание по y:
ExEy
[ (
y − E(y | x)
)(
E(y | x) − a(x)
)
| x
]
=
= Ex
( (
E(y | x) − a(x)
)
Ey
[ (
y − E(y | x)
)
| x
])
=
= Ex
( (
E(y | x) − a(x)
)(
E(y | x) − E(y | x)
) )
=
= 0
Получаем, что функционал среднеквадратичного риска имеет вид
R(a) =Ex,y(y − E(y | x))2 + Ex,y(E(y | x) − a(x))2.
От алгоритма a(x) зависит только второе слагаемое, и оно достигает своего мин иму-
ма, если a(x) =E(y | x). Т аким образом, оптимальная модель регрессии для квадра-
тичной функции потерь имеет вид
a∗(x) =E(y | x) =
∫
Y
yp(y | x)dy.
Иными словами, мы должны провести /guillemotleft.cyrвзвешенное голосование/guillemotright.cyr по всем возможным
ответам, причем вес ответа равен его апостериорной вероятн ости.
§2.2 Ошибка метода обучения
Для того, чтобы построить идеальную функцию регрессии, нео бходимо знать
распределение на объектах и ответах p(x, y), что, как правило, невозможно. На прак-
тике вместо этого выбирается некоторый метод обучения µ : (X × Y)ℓ → A , который
произвольной обучающей выборке ставит в соответствие неко торый алгоритм из се-
мейства A. В качестве меры качества метода обучения можно взять усред ненный
по всем выборкам среднеквадратичный риск алгоритма, выбра нного методом µ по
выборке:
L(µ) =EX
[
Ex,y
[ (
y − µ(X)(x)
) 2]]
= (2.1)
=
∫
(X×Y)ℓ
∫
X×Y
(
y − µ(X)(x)
) 2
p(x, y)
ℓ∏
i=1
p(xi, yi)dxdydx1dy1 . . . dx ℓdyℓ.
Здесь матожидание EX [·] берется по всем возможным выборкам {(x1, y1), . . . , (xℓ, yℓ)}
из распределения ∏ ℓ
i=1 p(xi, yi).
Обратим внимание, что результатом применения метода обуче ния µ(X) к вы-
борке X является модель, поэтому правильно писать µ(X)(x). Но это довольно гро-
моздкая запись, поэтому будем везде дальше писать просто µ(X), но не будем забы-
вать, что это функция, зависящая от объекта x.
Выше мы показали, что среднеквадратичный риск на фиксирова нной выбор-
ке X можно расписать как
Ex,y
[ (
y − µ(X)
) 2]
= Ex,y
[ (
y − E[y | x]
) 2]
+ Ex,y
[ (
E[y | x] − µ(X)
) 2]
.
5
Подставим это представление в ( 2.1):
L(µ) =EX
[
Ex,y
[ (
y − E[y | x]
) 2]
  
не зависит от X
+Ex,y
[ (
E[y | x] − µ(X)
) 2]]
=
= Ex,y
[ (
y − E[y | x]
) 2]
+ Ex,y
[
EX
[ (
E[y | x] − µ(X)
) 2]]
. (2.2)
Преобразуем второе слагаемое:
Ex,y
[
EX
[ (
E[y | x] − µ(X)
) 2]]
=
= Ex,y
[
EX
[ (
E[y | x] − EX
[
µ(X)
]
+ EX
[
µ(X)
]
− µ(X)
) 2]]
=
= Ex,y
[
EX
[ (
E[y | x] − EX
[
µ(X)
]) 2
  
не зависит от X
]]
+ Ex,y
[
EX
[ (
EX
[
µ(X)
]
− µ(X)
) 2]]
+
+ 2Ex,y
[
EX
[ (
E[y | x] − EX
[
µ(X)
])(
EX
[
µ(X)
]
− µ(X)
) ]]
. (2.3)
Покажем, что последнее слагаемое обращается в нуль:
EX
[ (
E[y | x] − EX
[
µ(X)
])(
EX
[
µ(X)
]
− µ(X)
) ]
=
=
(
E[y | x] − EX
[
µ(X)
])
EX
[
EX
[
µ(X)
]
− µ(X)
]
=
=
(
E[y | x] − EX
[
µ(X)
]) [
EX
[
µ(X)
]
− EX
[
µ(X)
] ]
=
= 0.
Учитывая это, подставим ( 2.3) в ( 2.2):
L(µ) =Ex,y
[ (
y − E[y | x]
) 2]
  
шум
+
+ Ex
[ (
EX
[
µ(X)
]
− E[y | x]
) 2]
  
смещение
+ Ex
[
EX
[ (
µ(X) − EX
[
µ(X)
]) 2]]
  
разброс
. (2.4)
Рассмотрим подробнее компоненты полученного разложения о шибки. Первая ком-
понента характеризует шум в данных и равна ошибке идеального алгоритма. Невоз-
можно построить алгоритм, имеющий меньшую среднеквадрати чную ошибку . Вто-
рая компонента характеризует смещение (bias) метода обучения, то есть отклоне-
ние среднего ответа обученного алгоритма от ответа идеальн ого алгоритма. Третья
компонента характеризует дисперсию (variance), то есть разброс ответов обученных
алгоритмов относительно среднего ответа.
Смещение показывает , насколько хорошо с помощью данных мет ода обучения
и семейства алгоритмов можно приблизить оптимальный алгор итм. Как правило,
смещение маленькое у сложных семейств (например, у деревье в) и большое у простых
семейств (например, линейных классификаторов). Дисперси я показывает , насколько
сильно может изменяться ответ обученного алгоритма в завис имости от выборки /emdash.cyr
иными словами, она характеризует чувствительность метода обучения к изменениям
6
Рис. 1. Иллюстрация сдвига и разброса для различных моделей.
в выборке. Как правило, простые семейства имеют маленькую д исперсию, а сложные
семейства /emdash.cyr большую дисперсию.
На рис. 1 изображены модели с различными сдвигом и разбросом. Модели изоб-
ражены синими точками, одна точка соответствует модели, об ученной по одной из
возможных обучающих выборок. Каждый круг характеризует ка чество модели /emdash.cyr
чем ближе точка к центру , тем меньше ошибок на контрольной вы борке достигает
данный алгоритм. Видно, что большой сдвиг соответствует то му , что в среднем точ-
ки не попадают в центр, то есть в среднем они не соответствуют лучшей модели.
Большой разброс означает , что модель может попасть по качес тву куда угодно /emdash.cyr
как в центр, так и в область с большой ошибкой.
Разложение для произвольной функции потерь. Разложение ошибки на три
компоненты, которое мы только что вывели, верно только для к вадратичной функ-
ции потерь. Существуют более общие формы этого разложения [ 2], которые состоят
из трёх компонент с аналогичным смыслом, поэтому можно утве рждать, что для
большинства распространённых функций потерь ошибка метод а обучения склады-
вается из шума, смещения и разброса; значит , и дальнейшие ра ссуждения про из-
менение этих компонент в композициях также можно обобщить н а другие функции
потерь (например, на индикатор ошибки классификации).
3 Бэггинг
Пусть имеется некоторый метод обучения µ(X). Построим на его основе ме-
тод ˜µ(X), который генерирует случайную подвыборку ˜X с помощью бутстрапа и
подает ее на вход метода µ: ˜µ(X) = µ( ˜X). Напомним, что бутстрап представля-
ет собой сэмплирование ℓ объектов из выборки с возвращением, в результате чего
некоторые объекты выбираются несколько раз, а некоторые /emdash.cyr ни разу . Помещение
7
нескольких копий одного объекта в бутстрапированную выбор ку соответствует вы-
ставлению веса при данном объекте /emdash.cyr соответствующее ему слагаемое несколько раз
войдет в функционал, и поэтому штраф за ошибку на нем будет бо льше.
В бэггинге (bagging, bootstrap aggregation)предлагается обучить некоторое чис-
ло алгоритмов bn(x) с помощью метода ˜µ, и построить итоговую композицию как
среднее данных базовых алгоритмов:
aN (x) = 1
N
N∑
n=1
bn(x) = 1
N
N∑
n=1
˜µ(X)(x).
Заметим, что в методе обучения для бэггинга появляется ещё о дин источник случай-
ности /emdash.cyr взятие подвыборки. Чтобы функционал качестваL(µ) был детерминиро-
ванным, мы будем далее считать, что матожидание EX [·] берётся не только по всем
обучающим выборкам X, но ещё и по всем возможным подвыборкам ˜X, получаемым
с помощью бутстрапа. Это вполне логичное обобщение, поскол ьку данное матожида-
ние вводится в функционал именно для учёта случайностей, св язанных с процедурой
обучения модели.
Найдём смещение из разложения ( 2.4) для бэггинга:
Ex,y
[(
EX
[ 1
N
N∑
n=1
˜µ(X)(x)
]
− E[y | x]
) 2]
=
= Ex,y
[( 1
N
N∑
n=1
EX [˜µ(X)(x)] − E[y | x]
) 2]
=
= Ex,y
[ (
EX
[
˜µ(X)(x)
]
− E[y | x]
) 2]
.
Мы получили, что смещение композиции, полученной с помощью бэггинга, совпада-
ет со смещением одного базового алгоритма. Т аким образом, б эггинг не ухудшает
смещенность модели.
Т еперь перейдём к разбросу . Запишем выражение для дисперси и композиции,
обученной с помощью бэггинга:
Ex,y
[
EX
[( 1
N
N∑
n=1
˜µ(X)(x) − EX
[ 1
N
N∑
n=1
˜µ(X)(x)
]) 2]]
.
Рассмотрим выражение, стоящее под матожиданиями:
( 1
N
N∑
n=1
˜µ(X)(x) − EX
[ 1
N
N∑
n=1
˜µ(X)(x)
]) 2
=
= 1
N2
( N∑
n=1
[
˜µ(X)(x) − EX
[
˜µ(X)(x)
] ]) 2
=
= 1
N2
N∑
n=1
(
˜µ(X)(x) − EX
[
˜µ(X)(x)
] ) 2
+
+ 1
N2
∑
n1̸=n2
(
˜µ(X)(x) − EX
[
˜µ(X)(x)
] )(
˜µ(X)(x) − EX
[
˜µ(X)(x)
] )
8
Алгоритм 3.1. Random Forest
1: для n = 1, . . . , N
2: Сгенерировать выборку ˜Xn с помощью бутстрэпа
3: Построить решающее дерево bn(x) по выборке ˜Xn:
• дерево строится, пока в каждом листе не окажется не более nmin объектов
• при каждом разбиении сначала выбирается m случайных признаков из p,
и оптимальное разделение ищется только среди них
4: Вернуть композицию aN (x) = 1
N
∑ N
n=1 bn(x)
Возьмем теперь матожидания от этого выражения, учитывая, ч то все базовые алго-
ритмы одинаково распределены относительно X:
Ex,y
[
EX
[ 1
N2
N∑
n=1
(
˜µ(X)(x) − EX
[
˜µ(X)(x)
] ) 2
+
+ 1
N2
∑
n1̸=n2
(
˜µ(X)(x) − EX
[
˜µ(X)(x)
] )(
˜µ(X)(x) − EX
[
˜µ(X)(x)
] )]]
=
= 1
N2 Ex,y
[
EX
[ N∑
n=1
(
˜µ(X)(x) − EX
[
˜µ(X)(x)
] ) 2]]
+
+ 1
N2 Ex,y
[
EX
[ ∑
n1̸=n2
(
˜µ(X)(x) − EX
[
˜µ(X)(x)
] )
×
×
(
˜µ(X)(x) − EX
[
˜µ(X)(x)
] )]]
=
= 1
N Ex,y
[
EX
[(
˜µ(X)(x) − EX
[
˜µ(X)(x)
] ) 2]]
+
+ N(N − 1)
N2 Ex,y
[
EX
[(
˜µ(X)(x) − EX
[
˜µ(X)(x)
] )
×
×
(
˜µ(X)(x) − EX
[
˜µ(X)(x)
] )]]
Первое слагаемое /emdash.cyr это дисперсия одного базового алгоритма, деленная на длину
композиции N. Второе /emdash.cyr ковариация между двумя базовыми алгоритмами. Мы ви-
дим, что если базовые алгоритмы некоррелированы, то диспер сия композиции в N
раз меньше дисперсии отдельных алгоритмов. Если же корреля ция имеет место, то
уменьшение дисперсии может быть гораздо менее существенны м.
§3.1 Случайные леса
Как мы выяснили, бэггинг позволяет объединить несмещенные , но чувствитель-
ные к обучающей выборке алгоритмы в несмещенную композицию с низкой диспер-
сией. Хорошим семейством базовых алгоритмов здесь являютс я решающие деревья /emdash.cyr
они достаточно сложны и могут достигать нулевой ошибки на лю бой выборке (сле-
довательно, имеют низкое смещение), но в то же время легко пе реобучаются.
9
Метод случайных лесов [3] основан на бэггинге над решающими деревьями, см.
алгоритм 3.1. Выше мы отметили, что бэггинг сильнее уменьшает дисперсию базовых
алгоритмов, если они слабо коррелированы. В случайных леса х корреляция между
деревьями понижается путем рандомизации по двум направлен иям: по объектам и
по признакам. Во-первых, каждое дерево обучается по бутстр апированной подвы-
борке. Во-вторых, в каждой вершине разбиение ищется по подм ножеству признаков.
Вспомним, что при построении дерева последовательно проис ходит разделение вер-
шин до тех пор, пока не будет достигнуто идеальное качество н а обучении. Каждая
вершина разбивает выборку по одному из признаков относител ьно некоторого поро-
га. В случайных лесах признак, по которому производится раз биение, выбирается не
из всех возможных признаков, а лишь из их случайного подмнож ества размера m.
Рекомендуется в задачах классификации брать m = ⌊
√
d⌋, а в задачах регрес-
сии /emdash.cyrm = ⌊d/3⌋, где d /emdash.cyr число признаков. Т акже рекомендуется в задачах клас-
сификации строить каждое дерево до тех пор, пока в каждом лис те не окажется по
одному объекту , а в задачах регрессии /emdash.cyr пока в каждом листе неокажется по пять
объектов.
Случайные леса /emdash.cyr один из самых сильных методов построения композиций. На
практике он может работать немного хуже градиентного бусти нга, но при этом он
гораздо более прост в реализации.
3.1.1 Out-of-Bag
Каждое дерево в случайном лесе обучается по подмножеству об ъектов. Это
значит , что те объекты, которые не вошли в бутстрапированну ю выборку Xn дере-
ва bn, по сути являются контрольными для данного дерева. Значит , мы можем для
каждого объекта xi найти деревья, которые были обучены без него, и вычислить по
их ответам out-of-bag-ошибку:
OOB =
ℓ∑
i=1
L
(
yi, 1∑ N
n=1[xi /∈ Xn]
N∑
n=1
[xi /∈ Xn]bn(xi)
)
,
где L(y, z ) /emdash.cyr функция потерь. Можно показать, что по мере увеличения числа де-
ревьев N данная оценка стремится к leave-one-out-оценке, но при это м существенно
проще для вычисления.
§3.2 Связь с метрическими методами
Случайные леса, по сути, осуществляют предсказание для объ екта на основе
меток похожих объектов из обучения. Схожесть объектов при э том тем выше, чем
чаще эти объекты оказываются в одном и том же листе дерева. По кажем это фор-
мально.
Рассмотрим задачу регрессии с квадратичной функцией потер ь. Пусть Tn(x) /emdash.cyr
номер листа n-го дерева из случайного леса, в который попадает объект x. Ответ
дерева на объекте x равен среднему ответу по всем обучающим объектам, которые
попали в лист Tn(x). Это можно записать как
bn(x) =
ℓ∑
i=1
wn(x, xi)yi,
10
где
wn(x, xi) = [Tn(x) =Tn(xi)]∑ ℓ
j=1[Tn(x) =Tn(xj )]
.
Т огда ответ композиции равен
aN (x) = 1
N
N∑
n=1
ℓ∑
i=1
wn(x, xi)yi =
ℓ∑
i=1
(
1
N
N∑
n=1
wn(x, xi)
)
yi.
Видно, что ответ случайного леса представляет собой сумму о тветов всех объектов
обучения с некоторыми весами, причём данные веса измеряют с ходство объектов x
и xi на основе того, сколько раз они оказались в одном и том же лист е. Т аким обра-
зом, случайный лес позволяет ввести некоторую функцию расс тояния на объектах.
Как мы узнаем позже, на этом принципе основан целый класс метрических мето-
дов, наиболее популярным представителем которых является метод k ближайших
соседей.
Отметим, что номер листа Tn(x), в который попал объект , сам по себе явля-
ется ценным признаком. Достаточно неплохо работает подход , в котором по выбор-
ке обучается композиция из небольшого числа деревьев с помо щью случайного ле-
са или градиентного бустинга, а затем к ней добавляются кате гориальные призна-
ки T1(x), T2(x), . . . , T N (x). Новые признаки являются результатом нелинейного раз-
биения пространства и несут в себе информацию о сходстве объ ектов.
Список литературы
[1] Hastie, T., Tibshirani, R., Friedman, J. (2001). The Elements of Statistical
Learning. // Springer, New Y ork.
[2] Domingos, Pedro (2000). A Uniﬁed Bias-V ariance Decomposition and its
Applications. // In Proc. 17th International Conf. on Machi ne Learning.
[3] Breiman, Leo (2001). Random Forests. // Machine Learning, 45(1), 5–32.
