Логистическая регрессия
Высшая Школа Цифровой Культуры
Университет ИТМО
dc@itmo.ru
Содержание
1 Логистическая регрессия 2
1.1 Введение. Генеративные и дискриминативные алгоритмы. . . . 2
1.2 Построение модели логистической регрессии . . . . . . . . . . . 4
1.3 Логистическая функция и алгоритм предсказания . . . . . . . . 6
1.4 Метод максимального правдоподобия (ММП) . . . . . . . . . . . 10
1.4.1 Наводящие соображения . . . . . . . . . . . . . . . . . . . 10
1.4.2 Сам метод максимального правдоподобия . . . . . . . . . 14
1.5 Нахождение параметров модели . . . . . . . . . . . . . . . . . . 15
1.6 Пример составления оптимизационной задачи . . . . . . . . . . 18
1.7 Отступ и «уверенность» классификации . . . . . . . . . . . . . . 19
1.8 Сравнение линейной и логистической регрессий . . . . . . . . . 23
2 Многоклассовая логистическая регрессия 24
2.1 Построение модели . . . . . . . . . . . . . . . . . . . . . . . . . . 24
2.2 Нахождение параметров модели . . . . . . . . . . . . . . . . . . 27
2.3 Пример трехклассовой классификации . . . . . . . . . . . . . . 28
3 F-мера и ROC-анализ 29
3.1 Матрица ошибок и 𝐹-мера . . . . . . . . . . . . . . . . . . . . . 29
3.2 ROC-кривая . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
4 Заключение 37
Высшая школа цифровой культуры Университет ИТМО
1 Логистическая регрессия
1.1 Введение. Генеративные и дискриминатив-
ные алгоритмы.
Здравствуйте, уважаемые слушатели. В этой лекции мы продолжим изу-
чение методов решения задачи классификации, а также познакомимся с еще
одним способом оценки качества алгоритма – с так называемым ROC анали-
зом.
Метод двухклассовой классификации, с описания которого мы начнем
нашу лекцию, называется логистической регрессией. Внимательный слуша-
тель, наверное, сразу встанет в ступор: при чем здесь регрессия? Ведь ре-
грессия – это одна задача, а классификация – совсем другая. Регрессия – это
задача предсказания числа (точнее – какой-то непрерывной переменной), а
классификация – задача предсказания класса (какой-то переменной, прини-
мающей, обычно, конечное число значений). Давайте проясним такую несо-
гласованность. На самом деле алгоритм двухклассовой логистической регрес-
сии выдает вероятность отнесения того или иного объекта к одному из двух
рассматриваемых классов. Вероятность – это число из диапазона[0, 1], то
есть непрерывная переменная, поэтому в названии и присутствует слово «ре-
грессия». В то же время, в зависимости от значения полученной вероятности,
наблюдению назначается тот или иной класс – вот и классификация. Так что,
как оказывается, несогласованности никакой и нет, хотя на первый взгляд
терминология и правда сбивает с толку.
Второй естественный вопрос, наверное, такой: мы же в предыдущей лек-
ции уже изучили наивный байесовский классификатор (кстати говоря, веро-
ятностный), зачем нам еще один, в чем их принципиальное отличие? Ока-
зывается, что отличие возникает уже в самом начале, в самом подходе к
построению вероятностной модели.
Снова начнем с постановки задачи. Пусть 𝑋 – это множество объек-
тов, каждый из которых описывается𝑝 признаками – случайными величина-
ми 𝑋1, 𝑋2, ..., 𝑋𝑝, и откликом𝑌 , который принимает значения из множества
{−1, 1}. Будем трактовать𝑋 ×𝑌 как вероятностное пространство с некото-
рым совместным распределением. Интересует нас, конечно, оценка вероят-
ности P(𝑌 = 1|𝑋1, 𝑋2, ..., 𝑋𝑝), ну или оценка противоположной вероятности
P(𝑌 = −1|𝑋1, 𝑋2, ..., 𝑋𝑝); понятно, что в случае двухклассовой классифика-
ции они связаны соотношением
P(𝑌 = 1|𝑋1, 𝑋2, ..., 𝑋𝑝) + P(𝑌 = −1|𝑋1, 𝑋2, ..., 𝑋𝑝) = 1.
При рассмотрении наивного байесовского классификатора мы, пользуясь
формулой Байеса, переходили к рассмотрению несколько других вероятно-
2
Высшая школа цифровой культуры Университет ИТМО
стей:
P(𝑌 |𝑋1, 𝑋2, ..., 𝑋𝑝) = P(𝑌, 𝑋1, 𝑋2, ..., 𝑋𝑝)
P(𝑋1, 𝑋2, ..., 𝑋𝑝) = P(𝑋1, 𝑋2, ..., 𝑋𝑝|𝑌 )P(𝑌 )
P(𝑋1, 𝑋2, ..., 𝑋𝑝) .
При классификации нового наблюдения мы, перебирая все возможные значе-
ния 𝑦 отклика 𝑌 (говоря по-взрослому, производяоценку апостериорного
максимума MAP (Maximum a posteriori estimation)), искали макси-
мум выражения
𝐹(𝑦) = P(𝑋1, 𝑋2, ..., 𝑋𝑝|𝑌 = 𝑦)P(𝑌 = 𝑦),
оценивая при этом вероятностиP(𝑌 ) и P(𝑋1, 𝑋2, ..., 𝑋𝑝|𝑌 ) на основе трени-
ровочных данных и предположении о наивности. Иными словами, смотря на
числители дробей парой строчек выше, можно сделать вывод, что мы моде-
лировали не что иное, как совместное распределениеP(𝑌, 𝑋1, 𝑋2, ..., 𝑋𝑝), на
основе которого и проводили классификацию.
Определение 1.1.1Алгоритмы, моделирующие совместное распределение
P(𝑌, 𝑋1, 𝑋2, ..., 𝑋𝑝), часто называютгенеративными.
В противовес генеративным алгоритмам, часто рассматривают так называе-
мые дискриминативные алгоритмы.
Определение 1.1.2Алгоритмы, непосредственно моделирующие
P(𝑌 |𝑋1, 𝑋2, ..., 𝑋𝑝), называютсядискриминативными.
Алгоритм логистической регрессии, о котором мы будем говорить далее, яв-
ляется дискриминативным. В его основе заложено следующее предположение
о (параметрическом) виде распределения условных вероятностей:
P(𝑌 = 1|𝑋1, 𝑋2, ..., 𝑋𝑝) = 1
1 + 𝑒−(𝜃0+𝜃1𝑋1+...𝜃𝑝𝑋𝑝) ,
где параметры алгоритма – коэффициенты𝜃0, 𝜃1, ..., 𝜃𝑝 – оцениваются, исходя
из тренировочного набора данных.
Отличие генеративных от дискриминативных моделей можно нефор-
мально пояснить на следующем примере. Предположим, что наша цель –
научиться отличать собак от кошек. Дискриминативная модель пытается в
𝑝-мерном пространстве признаковR𝑝 построить некоторую границу, разде-
ляющую (или почти разделяющую) тренировочные данные разных классов:
прямую, плоскость или многообразие более хитрой формы. Далее, для клас-
сификации новогонаблюдения, оказываетсядостаточнымпростоопределить:
с какой стороны от построенной границы находится новое наблюдение.
3
Высшая школа цифровой культуры Университет ИТМО
Генеративные же модели, как было сказано ранее, моделируют распре-
деления для каждого класса в отдельности. Например, в примере с кошками
и собаками, сначала, на основе тренировочных данных, строится модель «как
выглядит кошка», а потом модель «как выглядит собака». Далее, для клас-
сификации нового наблюдения, достаточно просто сравнить, чья модель ему
подходит больше: кошки или собаки. Вот и все отличие.
Что же, разобравшись с отличием в типах алгоритмов, перейдем к опи-
санию алгоритма логистической регрессии, но для начала поймем, из каких
соображений логично использовать соотношение для условной вероятности,
введенное выше:
P(𝑌 = 1|𝑋1, 𝑋2, ..., 𝑋𝑝) = 1
1 + 𝑒−(𝜃0+𝜃1𝑋1+...𝜃𝑝𝑋𝑝) .
1.2 Построение модели логистической регрес-
сии
Итак, согласно нашей постановке задачи, каждый объект, обладающий
набором предикторов 𝑋1, 𝑋2, ..., 𝑋𝑝, должен быть отнесен к одному из двух
классов: к классу «+1» или, условно, к положительному классу или к классу
«−1»–условно,отрицательномуклассу.Причем,какмыужеотмечалиранее,
понятно, что вероятности отнесения объекта к положительному классу
P+ = P(𝑌 = 1|𝑋1, 𝑋2, ..., 𝑋𝑝)
и к отрицательному классу
P−= P(𝑌 = −1|𝑋1, 𝑋2, ..., 𝑋𝑝)
связаны условием нормировки, то есть соотношением
P+ + P−= 1.
В итоге, если мы научимся оценивать вероятностьP+ попадания интересую-
щего нас объекта в положительный класс, то вероятность попадания проти-
воположный класс будет оцениваться выражениемP−= 1 −P+. Но как эти
оценки получить?
Замечание 1.2.1Отметим отдельно, что значенияP+ и, соответсвен-
но, P−, являются функциями от 𝑋1, 𝑋2, ..., 𝑋𝑝. Мы опускаем аргументы
функций лишь для краткости изложения.
Давайте теперь перейдем от вероятностей, которые измеряются в диапазоне
[0, 1], к так называемым шансам. Рассмотрим величинуP+ ∈[0, 1] – веро-
ятность отнесения объекта с предикторами𝑋1, 𝑋2, ..., 𝑋𝑝 к положительному
классу. ТогдаP− – вероятность противоположного события, то есть вероят-
ность отнесения того же самого объекта к отрицательному классу.
4
Высшая школа цифровой культуры Университет ИТМО
Определение 1.2.1Шансом отнесения объекта с предикторами
𝑋1, 𝑋2, ..., 𝑋𝑝 к положительному классу называется величина
odds+ = odds+(𝑋1, 𝑋2, ..., 𝑋𝑝) =
{︃P+
P−
, P−̸= 0
+∞, P−= 0 .
Например, если вероятностьP+ отнесения объекта к положительному классу
равна 0.8, то шанс составит4 : 1, так как
odds+ = 0.8
1 −0.8 = 4,
что вполне себе жизненно и интуитивно понятно, не так ли? Теперь давайте
ответим на следующий вопрос: а чем шанс лучше, чем вероятность? Дело тут
вот в чем: в отличие от вероятности, шанс принимает уже любые неотрица-
тельные значения, то есть
odds+ ∈[0, +∞].
Логарифмируя шанс, получим величину, которая теперь уже может прини-
мать любые значения из (расширенного) множества вещественных чисел
ln (odds+) = ln
(︂ P+
1 −P+
)︂
∈[−∞, +∞].
Итак, благодаря нашим достаточно нехитрым выкладкам, мы получили
непрерывную переменную, которая зависит от 𝑋1, 𝑋2, ..., 𝑋𝑝 и может при-
нимать любые значения из диапазона[−∞, +∞]. По сути дела, наша задача
плавно перетекла в задачу регрессии, которую мы умеем решать. Правда, тут
кроется некоторая проблема: мы не знаем значенияP+, поэтому и не знаем
ln (odds+). С другой стороны, если бы знали, то нечего было бы и оценивать.
Игнорируя на данный момент эту проблему, придем к уравнению регрессии
вида
ln
(︂ P+
1 −P+
)︂
= 𝜃0 + 𝜃1𝑋1 + 𝜃2𝑋2 + . . .+ 𝜃𝑝𝑋𝑝.
Естественно, на данный момент мы не знаем значений𝜃0, 𝜃1, ..., 𝜃𝑝.
Для удобства дальнейших выкладок, обозначим правую часть выраже-
ния заΨ, то есть
Ψ = Ψ(𝑋1, 𝑋2, ..., 𝑋𝑝) = 𝜃0 + 𝜃1𝑋1 + 𝜃2𝑋2 + . . .+ 𝜃𝑝𝑋𝑝
Из соотношения
ln
(︂ P+
1 −P+
)︂
= Ψ
5
Высшая школа цифровой культуры Университет ИТМО
выразим искомую вероятность P+. Беря экспоненты от обеих частей (или
потенцируя написанное равенство), придем к выражению
𝑒Ψ = P+
1 −P+
,
которое, в свою очередь, может быть переписано, как
(1 −P+) ·𝑒Ψ = P+,
откуда
P+ = 𝑒Ψ
1 + 𝑒Ψ .
Преобразовав последнюю дробь, придем к выражению
P+ = 1
𝑒−Ψ ·(1 + 𝑒Ψ) = 1
1 + 𝑒−Ψ = 1
1 + 𝑒−(𝜃0+𝜃1𝑋1+...+𝜃𝑝𝑋𝑝) .
Обратите внимание, это ровно-таки заявленное во введении параметрическое
семейство.
Замечание 1.2.2Еще раз отметим, что так какΨ, будучи приравненной
к ln (odds+), принимает значения в диапазоне[−∞, +∞], то𝑒−Ψ принима-
ет значения в диапазоне[0, +∞], а значитP+ ∈[0, 1].
1.3 Логистическая функция и алгоритм пред-
сказания
Прежде чем обсудить важный вопрос нахождения коэффициентов
𝜃0, 𝜃1, ..., 𝜃𝑝, чуть подробнее рассмотрим аналитическое выражение, получен-
ное для вероятностиP+. Оказывается, оно тесно связано с так называемой
логистической функцией или сигмоидой (logistic function or sigmoid function).
Определение 1.3.1Функция
𝜎(𝑥) = 1
1 + 𝑒−𝑥
называется логистической функцией или сигмоидой.
Наверное, многие из вас видят явное сходство выражений дляP+ и логисти-
ческой функции:
P+ = 1
1 + 𝑒−Ψ ←→𝜎(𝑥) = 1
1 + 𝑒−𝑥 .
Что можно извлечь из этого сходства? Для того, чтобы это понять, давайте
для начала сформулируем основные свойства сигмоиды.
6
Высшая школа цифровой культуры Университет ИТМО
Лемма 1.3.1Функция
𝜎(𝑥) = 1
1 + 𝑒−𝑥
обладает следующими свойствами:
1. 𝜎(𝑥) – возрастающая функция;
2. 𝜎(𝑥) – непрерывная наR функция;
3.
lim
𝑥→+∞
𝜎(𝑥) = 1, lim
𝑥→−∞
𝜎(𝑥) = 0.
4. 𝜎(𝑥) ограничена двумя горизонтальными асимптотами𝑦 = 0 и 𝑦 = 1.
Доказательство. Несмотря на то, что все написанные пункты достаточно
очевидны, мы все же дадим несколько пояснений. Начнем с первого пункта.
Так как функция𝑒𝑥 возрастает, то𝑒−𝑥 – убывает, функция1 +𝑒−𝑥 тоже убы-
вает, функция 1
𝑥 – убывает, а следовательно интересующая нас композиция
1
1+𝑒−𝑥 – возрастает.
Непрерывность написанной функции следует из непрерывности компо-
зиции элементарных функций на своей области определения.
Уравнения асимптот получаются из заявленных в третьем пункте пре-
делов
lim
𝑥→+∞
𝜎(𝑥) = 1, lim
𝑥→−∞
𝜎(𝑥) = 0,
которые, при желании, можно проверить, хотя бы по определению. □
График логистической функции приведен на рисунке 1. Из только что сфор-
мулированных свойств следует, что𝜎(𝑥) является функцией распределения
некоторой случайной величины𝜉, а значит
P+ = 𝜎 (Ψ) = P (𝜉 <Ψ) .
Замечание 1.3.1Из написанных свойств легко вывести следующий инте-
ресный (и, кстати, идейный) момент: «пограничная вероятность» отне-
сения объекта к классу «+1» (или «−1»), то есть вероятностьP+ = P−=
0.5, – это значение функции 𝜎(𝑥) в точке 0. В наших обозначениях это
условие равносильно тому, что
0 = Ψ = 𝜃0 + 𝜃1𝑋1 + ... + 𝜃𝑝𝑋𝑝.
Множество точек, удовлетворяющих написанному равенству, – это ги-
перплоскость (точка на прямойR1, прямая на плоскостиR2, плоскость в
7
Высшая школа цифровой культуры Университет ИТМО
Рис. 1: Логистическая кривая (сигмоида).
пространстве R3 и т.д.), лежащая в пространствеR𝑝 и делящая его на
две части. Эти части пространства имеет смысл трактовать следую-
щим образом: в одной из частей лежат точки, для которыхP+ > 0.5, то
есть точки, которые скорее относятся к положительному, нежели к от-
рицательному классу, а в другой – точки, для которыхP+ < 0.5 (или, что
то же самое,P−> 0.5), то есть точки, которые скорее относятся к от-
рицательному, нежели положительному классу. Неуверенность, которую
вы могли заметить в словах «скорее всего», и правда присутствует: мы
вскоре проясним этот момент.
В случае, когда граница двух классов является гиперплоскостью, клас-
сификатор называют линейным. Из всего сказанного можно сделать вывод,
что алгоритм логистической регрессии, по своей сути, является линейным
классификатором.
Сформулируем алгоритм предсказания класса нового объекта𝑧 с предикто-
рами (𝑧1, 𝑧2, ..., 𝑧𝑝) в случае, когда коэффициенты𝜃0, 𝜃1, ..., 𝜃𝑝 уже найдены.
1. Вычислить значениеΨ:
Ψ = 𝜃0 + 𝜃1𝑧1 + 𝜃2𝑧2 + . . .+ 𝜃𝑝𝑧𝑝.
2. Вычислить вероятностьP+:
P+ = 1
1 + 𝑒−Ψ .
8
Высшая школа цифровой культуры Университет ИТМО
3. Если P+ ≥0.5, то объекту𝑧 назначить класс «+1», иначе – класс «−1».
На этом месте полезно остановиться и задаться вопросом: почему «погранич-
ной» вероятностью является именно значение0.5? На самом деле, выбор этой
вероятности – вопрос очень неоднозначный. Например, при решении задачи
классификации писем на две категории: «спам» и «не спам», вряд ли целесо-
образно отправлять письмо в категорию «спам», если классификатор уверен
в этом лишь с вероятностью0.51. В этом случае может быть правильнее ис-
пользовать такое правило: если P+ ≥ 0.65, то объекту 𝑧 назначить класс
«+1» (отправить в спам), иначе – класс «−1» (отправить в папку входящие).
Или представьте, что мы исследуем самолет на надежность. Можно бы было
его выпускать в рейс, если бы классификатор сказал, что самолет надежен
с вероятностью0.75? Видимо, в вопросах с самолетом «пограничная» веро-
ятность должна быть серьезно больше, больше чем0.9. В реальных задачах
выбор этой вероятности часто отдается на откуп исследователю (или другим
методам машинного обучения, как, например, k-fold cross-validation).
Замечание 1.3.2На самом деле, приведенный алгоритм логистической
регрессии является алгоритмом, то есть отображением из пространства
признаков в множество классов, лишь в случае, когда задано правило при-
своения метки класса – когда выбрана вероятность, начиная с которой объ-
ект относят к классу «+1» (или, симметрично, к классу «−1»). Сама по
себе логистическая регрессия (грубо говоря – функцияP+) выдает число в
диапазоне [0, 1] и часто называется базовым алгоритмом. Правило, соглас-
но которому по выданной вероятности принимается решение об отнесе-
нии объекта к тому или иному классу, называется решающим правилом.
Итого, можно сделать вывод, что алгоритм логистической регрессии –
это композиция решающего правила и базового алгоритма логистической
регрессии.
Теперь применим алгоритм логистической регрессии к конкретным данным.
В качестве последних будут выступать данные статистики футбольного мат-
ча; всего имеется три предиктора: количество ударов в створ ворот (𝑋1),
процент владения мячом (𝑋2) и количество ударов в сторону ворот (𝑋3) в
течение матча; отклик𝑌 принимает всего два значения: значение1 соответ-
ствует победе команды в матче (или отнесению ее к классу «+1»), а значение
0 соответствует проигрышу или ничьей (отнесение к классу «−1»). На основе
тренировочных данных получены следующие значения параметров модели:
𝜃0 ≈−0.046, 𝜃 1 ≈0.541, 𝜃 2 ≈−0.014, 𝜃 3 ≈−0.132.
Классифицируем новый объект𝑧:
𝑧 = (1, 40, 3)
9
Высшая школа цифровой культуры Университет ИТМО
– команду, которая в течение матча1 раз ударила в створ ворот, владела
мячом 40 процентов игрового времени и нанесла3 удара в сторону ворот.
Согласно описанному алгоритму, вероятность победы в матче оказывается
равной
P+ = 1
1 + 𝑒−(𝜃0+𝜃1·1+𝜃2·40+𝜃3·3) ≈0.38,
значит, команда скорее проиграет, нежели выиграет.
Итак, в случае, когда параметры модели найдены, предсказание осу-
ществляется очень просто. Но как же найти эти параметры? Тут нам прихо-
дит на помощь метод максимального правдоподобия.
1.4 Метод максимального правдоподобия
(ММП)
Метод максимального правдоподобия – один из мощнейших статисти-
ческих методов, позволяющий получать по выборке оценки параметров се-
мейств вероятностных распределений. Многие из вас, скорее всего, знакомы
с этим методом. Однако в силу того, что он лежит в основе построения ал-
горитма логистической регрессии, мы считаем нужным все-таки подробно о
нем рассказать (хотя и лишь в необходимой для нас строгости и общности –
не в самой общей).
1.4.1 Наводящие соображения
Предположим, что проводится серия из𝑛 независимых одинаковых ис-
пытаний, вероятность успеха в каждом из которых равна𝑝 ∈(0, 1). Приме-
ром может служить стрельба по мишени или серия послематчевых пенальти.
Напомним, что в озвученных предположениях вероятность получить ровно
𝑘 ∈{0, 1, .., 𝑛}успехов в𝑛 испытаниях, то есть вероятность события𝐵(𝑛, 𝑘),
вычисляется по формуле Бернулли
P(𝐵(𝑛, 𝑘)) = 𝐶𝑘
𝑛𝑝𝑘(1 −𝑝)𝑛−𝑘,
где 𝐶𝑘
𝑛 – число сочетаний из𝑛 элементов по𝑘 элементов, равное
𝐶𝑘
𝑛 = 𝑛!
𝑘!(𝑛 −𝑘)!
Пусть, к примеру, проводится следующий эксперимент: серия из пяти ударов
по воротам с вероятностью успеха𝑝 (то есть с вероятностью забить мяч),
равной 0.7, при каждом ударе. Эксперимент проводился дважды (незави-
симо!), причем известно, что в первом эксперименте произошло два успеха
(забили два гола), а во втором – четыре (забили4 гола). Итого, перед на-
ми следующая выборка:𝑋1 = 2, 𝑋2 = 4. Какова же вероятность получить
10
Высшая школа цифровой культуры Университет ИТМО
такую выборку? В силу независимости, эта вероятность равна произведению
вероятностей соответствующих событий, каждая из которых вычисляется по
формуле Бернулли:
P (𝑋1 = 2, 𝑋2 = 4) = P(𝑋1 = 2) ·P(𝑋2 = 4) =
= P(𝐵(5, 2)) ·P(𝐵(5, 4)) = 𝐶2
5 ·0.72 ·(1 −0.7)3 ·𝐶4
5 ·0.74 ·(1 −0.7)1.
Проведя вычисления, получаем, что вероятность рассматриваемого события
невелика и примерно равна
P (𝑋1 = 2, 𝑋2 = 4) ≈0.048.
Очевидно, что все вычисления мы смогли провести лишь потому, что изна-
чально знали вероятность забития гола при каждом ударе по мячу. В реаль-
ности, конечно, все не так: обычно мы наблюдаем лишь какие-то проявления
нашей случайной величины – выборку из нее, а также, если нам везет, зна-
ем то параметрическое семейство вероятностных распределений, которому
она подчиняется. В то же время сами параметры этих распределений мы не
знаем! Поэтому ничего не остается, кроме как оценивать эти параметры по
выборке. Как? Конечно, пытаясь максимизировать вероятность тех значений,
которые мы наблюдаем.
Итак, продолжим рассмотрение нашего примера. Логично считать, что
случайная величина – количество забитых голов в серии из5 ударов, имеет
так называемое биномиальное распределение с параметрами𝑛 = 5 (количе-
ство испытаний) и неизвестным параметром𝑝 (вероятность успеха в каждом
испытании).Вэтомслучаевероятностьсобытия 𝐵(5, 𝑘) при𝑘 ∈{0, 1, 2, ...,5},
то есть события, что забито ровно𝑘 голов в серии из пяти ударов по воротам,
может быть вычислена по формуле Бернулли
P(𝐵(5, 𝑘)) = 𝐶𝑘
5 𝑝𝑘(1 −𝑝)5−𝑘.
Значение𝑝 – вероятность забития гола при ударе по воротам, нам неизвестна,
однако мы наблюдаем следующую выборку в результате двух независимых
экспериментов: 𝑋1 = 2, 𝑋2 = 4. Вероятность получить эту выборку, в силу
независимости экспериментов, может быть вычислена следующим образом:
𝑓 (𝑋1 = 2, 𝑋2 = 4, 𝑝) = P(𝑋1 = 2, 𝑋2 = 4) = P(𝑋1 = 2) ·P(𝑋2 = 4) =
= 𝐶2
5 ·𝑝2 ·(1 −𝑝)3 ·𝐶4
5 ·𝑝4 ·(1 −𝑝)1.
Перед нами – функция от𝑝, а нам хочется найти такое значение𝑝, при кото-
ром эта функция на отрезке[0, 1] примет свое наибольшее значение (именно
при таком значении𝑝 наша выборка будет наиболее вероятной). Найденное
11
Высшая школа цифровой культуры Университет ИТМО
значение 𝑝 и имеет смысл трактовать, как оценку истинного, нам неизвест-
ного значения.
Легко видеть, что концы отрезка – не те значения, которые нас интере-
суют, так как в точках0 и 1 рассматриваемая функция равна нулю. Поэтому
впредь будем считать, что𝑝 ∈(0, 1). Итак, перед нами классическая задача
математического анализа – задача нахождения точки, в которой заданная
функция принимает наибольшее значение на заданном множестве. Для ре-
шения этой задачи можно воспользоваться следующим достаточно вольным
алгоритмом.
1. Найти производную первого порядка.
2. Найти точки из области определения функции, в которых производная
либо обращается в ноль, либо не существует. Все эти точки называются
точками, подозрительными на экстремум.
3. Для проверки того, что точка, подозрительная на экстремум, являет-
ся точкой локального максимума, воспользоваться каким-нибудь доста-
точным условием. Например, точка, подозрительная на экстремум бу-
дет точкой локального максимума, если при переходе через нее произ-
водная меняет знак с плюса на минус.
4. Сравнить значения функции в найденных точках локального максиму-
ма со значениями на границах множества (если таковые есть), выбрать
наибольшее, а затем определить точку, в которой это наибольшее зна-
чение достигается.
Функция 𝑓 (𝑋1 = 2, 𝑋2 = 4, 𝑝), которую мы хотим максимизировать, пред-
ставляет собой произведение, что усложняет поиск производной, так как при-
ходится многократно применять правило дифференцирования произведения
функций, что, в свою очередь, довольно объемно. Для упрощения вычис-
лений ее можно прологарифмировать и максимизировать так называемую
логарифмическую функцию правдоподобия:
𝐿 (𝑋1 = 2, 𝑋2 = 4, 𝑝) = ln 𝑓 (𝑋1 = 2, 𝑋2 = 4, 𝑝) .
Так как логарифм – монотонная функция, то точки экстремума
функции 𝑓 (𝑋1 = 2, 𝑋2 = 4, 𝑝) перейдут в точки экстремума функции
𝐿 (𝑋1 = 2, 𝑋2 = 4, 𝑝), и наоборот. В итоге, после логарифмирования, произ-
ведение распадется в сумму логарифмов, и мы придем к окончательному
выражению вида
𝐿 (𝑋1 = 2, 𝑋2 = 4, 𝑝) = ln
(︀
𝐶2
5 ·𝑝2 ·(1 −𝑝)3 ·𝐶4
5 ·𝑝4 ·(1 −𝑝)1)︀
=
12
Высшая школа цифровой культуры Университет ИТМО
= ln 𝐶2
5 + ln𝐶4
5 + 6 ln𝑝 + 4 ln(1−𝑝).
Замечание 1.4.1Обратите внимание, что так как𝑝 ∈(0, 1), то все пре-
образования оказываются законными.
Итого, мы пришли к задаче поиска значения параметра𝑝 ∈(0, 1), максими-
зирующего логарифмическую функцию правдоподобия
𝐿 (𝑋1 = 2, 𝑋2 = 4, 𝑝) = ln(𝐶2
5 ·𝐶4
5 ) + 6 ln𝑝 + 4 ln(1−𝑝).
Для нахождения точек, подозрительных на экстремум, вычислим производ-
ную, она равна
(𝐿 (𝑋1 = 2, 𝑋2 = 4, 𝑝))′
𝑝 = 6
𝑝 − 4
1 −𝑝.
Приравняв производную к нулю, получим уравнение
6
𝑝 − 4
1 −𝑝 = 0,
откуда𝑝 = 0.6. Убедимся, что найденная точка – точка максимума. Для это-
Рис. 2: Интервалы возрастания и убывания функции𝐿.
го проверим знаки производной функции слева и справа от точки0.6. Как
видим, производная меняет свой знак с плюса на минус, а значит найден-
ное значение𝑝 = 0.6 – точка максимума. Итак, вероятность события, что в
первой серии из пяти ударов было забито два гола, а во второй – четыре,
максимальна при𝑝 = 0.6.
Для того чтобы найти значение вероятности события𝑋1 = 2, 𝑋2 = 4 при
найденном 𝑝 = 0.6, достаточно вычислить
𝑓(𝑋1 = 2, 𝑋2 = 4, 0.6) = 𝐶2
5 ·0.62 ·(1 −0.6)3 ·𝐶4
5 ·0.64 ·(1 −0.6)1 ≈0.06.
Итак, при найденном значении𝑝 вероятность события 𝑋1 = 2, 𝑋2 = 4 ста-
ла больше, чем при предыдущем, что и естественно, ведь мы нашли такое
значение 𝑝, которое максимизирует наши наблюдения: два успеха в первом
эксперименте и четыре во втором. Разобравшись в примере, перейдем к об-
щему описанию метода максимального правдоподобия.
13
Высшая школа цифровой культуры Университет ИТМО
1.4.2 Сам метод максимального правдоподобия
Пусть имеется выборка𝑋 объема 𝑛, элементы которой 𝑋1, 𝑋2, . . . , 𝑋𝑛
независимы, одинаково распределены и имеют некоторое распределение𝒫𝜃,
известным образом зависящее от параметра𝜃. Этот параметр может прини-
мать значения из какого-то множестваΘ, то есть𝜃 ∈Θ. Например, в только
что рассмотренном примере, семейство распределений – это семейство би-
номиальных распределений 𝒫𝜃 = Bin(5, 𝑝), зависящих от параметра𝜃 = 𝑝,
причем множество значенийΘ параметра 𝜃 – это отрезок[0, 1].
Метод максимального правдоподобия – один из статистических мето-
дов, который состоит в построении оценки этого параметра. Грубо говоря,
в качестве максимально правдоподобного значения𝜃 берут такое, что при𝑛
испытаниях максимизируется вероятность получения выборки𝑥1, 𝑥2, . . . , 𝑥𝑛,
полученной после эксперимента. Составим функцию
𝑓(𝑋, 𝜃) = P𝜃 (𝑋1 = 𝑥1, 𝑋2 = 𝑥2, . . . , 𝑋𝑛 = 𝑥𝑛) .
Понятно, что функция𝑓(𝑋, 𝜃) показывает вероятность события, что элемен-
ты выборки 𝑋1, 𝑋2, ..., 𝑋𝑛 равняются конкретным значениям 𝑥1, 𝑥2, . . . , 𝑥𝑛,
соответственно. Учитывая независимость элементов выборки𝑋1, 𝑋2, . . . , 𝑋𝑛,
мы можем перейти к произведению вероятностей:
𝑓(𝑋, 𝜃) = P𝜃 (𝑋1 = 𝑥1) ·P𝜃 (𝑋2 = 𝑥2) ·. . .·P𝜃 (𝑋𝑛 = 𝑥𝑛) .
Определение 1.4.1Функция
𝑓(𝑋, 𝜃) = P𝜃 (𝑋1 = 𝑥1) ·P𝜃 (𝑋2 = 𝑥2) ·. . .·P𝜃 (𝑋𝑛 = 𝑥𝑛)
называется функцией правдоподобия.
Определение 1.4.2Оценкой максимального правдоподобия (Maximum
likelihood estimate (MLE)) ̂︀𝜃 неизвестного параметра 𝜃 называется такое
значение ̂︀𝜃 ∈ Θ, при котором функция правдоподобия 𝑓(𝑋, 𝜃) достигает
максимума.
Более коротко, интересующая нас задача переписывается следующим обра-
зом:
̂︀𝜃 = Arg max
𝜃
𝑓(𝑋, 𝜃),
где 𝑓(𝑋, 𝜃) – функция правдоподобия. Снова подчеркнем, что само назва-
ние оператора говорит, что мы ищем аргумент (или аргументы, ведь их мо-
жет быть несколько), максимизирующий функцию, а не значение максимума
функции.
14
Высшая школа цифровой культуры Университет ИТМО
Замечание 1.4.2В принципе, аргументов 𝜃, на которых достигается
глобальный максимум функции 𝑓(𝑋, 𝜃), может быть несколько. В та-
ком случае в качестве оценки ̂︀𝜃 выбирается любой элемент множества
Arg max
𝜃
𝑓(𝑋, 𝜃).
Как уже было отмечено в примере, рассмотренном ранее, для вычис-
лительных удобств рассматривают не функцию правдоподобия𝑓(𝑋, 𝜃), а ее
логарифм – так называемую логарифмическую функцию правдоподобия.
Определение 1.4.3Пусть 𝑓(𝑋, 𝜃) – функция правдоподобия. Функция
𝐿(𝑋, 𝜃) = ln 𝑓(𝑋, 𝜃) = ln P𝜃 (𝑋1 = 𝑥1) + . . .+ lnP𝜃 (𝑋𝑛 = 𝑥𝑛) .
называется логарифмической функцией правдоподобия.
Так как логарифм – монотонная функция, то точки экстремума функции
𝑓(𝑋, 𝜃) будут и точками экстремума функцииln 𝑓(𝑋, 𝜃), и наоборот, а значит
наша задача может быть переписана в виде
̂︀𝜃 = Arg max
𝜃
𝐿(𝑋, 𝜃).
Теперь, изучив математическую суть вопроса, поговорим о применении рас-
смотренного аппарата к обучению алгоритма логистической регрессии.
1.5 Нахождение параметров модели
Итак, чтобы решить задачу нахождения неизвестных параметров моде-
ли, сначала вспомним наши исходные предположения. Мы предполагаем, что
вероятность отнесения объекта с предикторами𝑋1, 𝑋2, ..., 𝑋𝑝 к положитель-
ному классу «+1» задается выражением
P+ = P+(𝑋1, 𝑋2, ..., 𝑋𝑝) = 1
1 + 𝑒−(𝜃0+𝜃1𝑋1+𝜃2𝑋2+...+𝜃𝑝𝑋𝑝) .
Обозначив
Ψ = 𝜃0 + 𝜃1𝑋1 + ... + 𝜃𝑝𝑋𝑝,
выражение для вероятности переписывается, как
P+ = P+(𝑋1, 𝑋2, ..., 𝑋𝑝) = 1
1 + 𝑒−Ψ = 𝜎[Ψ], 𝜎 (𝑥) = 1
1 + 𝑒−𝑥 .
ВероятностьP−отнесения объекта к отрицательному классу «−1» тогда рав-
на
P−= P−(𝑋1, 𝑋2, ..., 𝑋𝑝) = 1 −P+ = 1 −𝜎[Ψ].
15
Высшая школа цифровой культуры Университет ИТМО
Простейшие алгебраически преобразования приводят нас к тому, что
P−= 1 −P+ = 1 − 1
1 + 𝑒−Ψ = 𝑒−Ψ
1 + 𝑒−Ψ = 1
1 + 𝑒Ψ .
Таким образом,
P−= P−(𝑋1, 𝑋2, ..., 𝑋𝑝) = 1
1 + 𝑒Ψ = 𝜎[−Ψ].
Итого, у нас есть пара соотношений:
P+ = P+(𝑋1, 𝑋2, ..., 𝑋𝑝) = 1
1 + 𝑒−Ψ = 𝜎[Ψ],
P−= P−(𝑋1, 𝑋2, ..., 𝑋𝑝) = 1
1 + 𝑒Ψ = 𝜎[−Ψ].
Пусть теперь нам дан тренировочный набор данных𝑋 = {𝑥1, 𝑥2, ..., 𝑥𝑛}объ-
ема 𝑛,
𝑥𝑖 = (𝑥𝑖1, 𝑥𝑖2, ..., 𝑥𝑖𝑝), 𝑖 ∈{1, 2, ..., 𝑛},
причем каждому объекту 𝑥𝑖 соответствует отклик 𝑦𝑖 ∈𝑌 = {−1, 1}. Для
удобства введем следующее обозначение:
𝑀(𝜃, 𝑥𝑖) = 𝑦𝑖(𝜃0 + 𝜃1𝑥𝑖1 + 𝜃2𝑥𝑖2 + ... + 𝜃𝑝𝑥𝑖𝑝).
Легко заметить, что если объект тренировочных данных относится к классу
«+1», то, так как𝑦𝑖 = 1,
𝜎 [𝑀(𝜃, 𝑥𝑖)] = 1
1 + 𝑒−(𝜃0+𝜃1𝑥𝑖1+𝜃2𝑥𝑖2+...+𝜃𝑝𝑥𝑖𝑝) = P+,
а если к классу «−1», то, так как𝑦𝑖 = −1,
𝜎 [𝑀(𝜃, 𝑥𝑖)] = 1
1 + 𝑒(𝜃0+𝜃1𝑥𝑖1+𝜃2𝑥𝑖2+...+𝜃𝑝𝑥𝑖𝑝) = P−.
Естественно, имея тренировочный набор данных, в откликах которого мы
уверены, все получившиеся вероятности должны быть настолько близкими
к единице, насколько это возможно. «Настраивать» указанную близость мы
можем,меняязначения 𝜃0, 𝜃1, ..., 𝜃𝑝.Ясно,чтодляэтогологичноиспользовать
метод максимального правдоподобия, описанный ранее. Функция правдопо-
добия в нашем случае перепишется следующим образом:
𝑓(𝑋, 𝜃) = 𝜎 [𝑀(𝜃, 𝑥1)] ·𝜎 [𝑀(𝜃, 𝑥2)] ·... ·𝜎 [𝑀(𝜃, 𝑥𝑛)] =
𝑛∏︁
𝑖=1
𝜎 [𝑀(𝜃, 𝑥𝑖)] .
16
Высшая школа цифровой культуры Университет ИТМО
Логарифмическая функция правдоподобия, которую, как и функцию прав-
доподобия, имеет смысл максимизировать, в этом случае примет следующий
вид:
𝐿(𝑋, 𝜃) =
𝑛∑︁
𝑖=1
ln (𝜎 [𝑀 (𝜃, 𝑥𝑖)]) .
Нас же интересует такой набор значений𝜃, что
𝜃 = Arg max
𝜃
𝐿(𝑋, 𝜃).
С другой стороны, используя свойства логарифмов, задача может быть пе-
реписана и следующим образом:
Arg max
𝜃
𝐿(𝑋, 𝜃) = Arg max
𝜃
𝑛∑︁
𝑖=1
ln (𝜎 [𝑀(𝜃, 𝑥𝑖]) =
= Arg max
𝜃
𝑛∑︁
𝑖=1
ln
(︁
1 + 𝑒−𝑀(𝜃,𝑥𝑖)
)︁−1
= Arg min
𝜃
𝑛∑︁
𝑖=1
ln
(︁
1 + 𝑒−𝑀(𝜃,𝑥𝑖)
)︁
,
так как максимизация функции
𝑛∑︁
𝑖=1
ln
(︁
1 + 𝑒−𝑀(𝜃,𝑥𝑖)
)︁−1
= −
𝑛∑︁
𝑖=1
ln
(︁
1 + 𝑒−𝑀(𝜃,𝑥𝑖)
)︁
– то же самое, что минимизация функции
logloss(𝑋, 𝜃) =
𝑛∑︁
𝑖=1
ln
(︁
1 + 𝑒−𝑀(𝜃,𝑥𝑖)
)︁
,
то есть той же самой функции, но без знака минус (формально – той же
самой функции, но домноженной на−1).
Определение 1.5.1Введенная выше функцияlogloss называется логисти-
ческой функцией ошибки (логистической функцией потерь).
Замечание 1.5.1Полезно отметить, что логистическая функция по-
терь – частный случай эмпирического риска
𝑄(𝑎, 𝐿, 𝑥1, 𝑥2...𝑥𝑛) = 1
𝑛
𝑛∑︁
𝑖=1
𝐿(𝑎, 𝑥𝑖),
17
Высшая школа цифровой культуры Университет ИТМО
где 𝐿(𝑎, 𝑥𝑖) – функция потерь, который обсуждался ранее. Чтобы в этом
убедиться, достаточно в качестве функции потерь рассмотреть следую-
щую функцию:
𝐿(𝑎, 𝑥) = 𝑛 ln
(︁
1 + 𝑒−𝑀(𝜃,𝑥)
)︁
.
Итого, как и ранее, мы ищем такой алгоритм, то есть подбираем такие
параметры 𝜃0, 𝜃1, ..., 𝜃𝑝, которые минимизируют эмпирический риск.
Написанная выше функция потерь вполне естественна, ведь чем ху-
же объект 𝑥 согласуется с откликом, тем больше значение функции
1 + 𝑒−𝑀(𝜃,𝑥), и тем больший вклад логарифм дает в копилку эмпирического
риска.
Минимизация полученной функции
logloss(𝑋, 𝜃) =
𝑛∑︁
𝑖=1
ln
(︁
1 + 𝑒−𝑀(𝜃,𝑥𝑖)
)︁
,
конечно, вручную уже не проводится. Обычно это делается численно мето-
дами вроде градиентного спуска, но на этом подробно мы останавливаться
не будем. Естественно, для решения задачи максимизации или минимизации,
можно воспользоваться инструментами моделирования или математически-
ми пакетами.
1.6 Пример составления оптимизационной зада-
чи
Рассмотрим последовательность действий, приводящих к постановке за-
дачи минимизации, описанной выше. Для начала рассмотрим урезанные дан-
ные по футбольной статистике, с которыми мы уже знакомы (с полной таб-
лицей можно ознакомиться в дополнительных материалах к лекции).
Победа или
проигрыш
Количество уда-
ров в створ ворот
Процент владе-
ния мячом
Количество
ударов в сто-
рону ворот
1 7 40 13
0 0 60 6
0 3 43 8
1 4 57 14
... ... ... ...
Для наглядности будем считать, что наши исходные данные – это данные из
таблицы, приведенной выше. Данные первого столбца отвечают откликам,
а данные столбцов со второго по четвертый – предикторам. Каждая строка
18
Высшая школа цифровой культуры Университет ИТМО
отвечает своему тренировочному данному. Во введенных обозначениях, наши
объекты таковы:
𝑥1 = (7, 40, 13), 𝑦 1 = 1,
𝑥2 = (0, 60, 6), 𝑦 2 = 0,
𝑥3 = (3, 43, 8), 𝑦 3 = 0,
𝑥4 = (4, 57, 14), 𝑦 4 = 1.
Поменяем значения класса0 на значения−1, чтоы работать в уже введенных
обозначениях. Тогда
𝑥1 = (7, 40, 13), 𝑦 1 = 1,
𝑥2 = (0, 60, 6), 𝑦 2 = −1,
𝑥3 = (3, 43, 8), 𝑦 3 = −1,
𝑥4 = (4, 57, 14), 𝑦 4 = 1.
Логистическая функция потерь переписывается в следующем виде:
logloss(𝑋, 𝜃) =
4∑︁
𝑖=1
ln
(︁
1 + 𝑒−𝑀(𝜃,𝑥𝑖)
)︁
=
4∑︁
𝑖=1
ln
(︁
1 + 𝑒−𝑦𝑖(𝜃0+𝜃1𝑥𝑖1+𝜃2𝑥𝑖2+𝜃3𝑥𝑖3)
)︁
Понятно, что при этом выражения на тренировочных данных для𝑀(𝜃, 𝑥𝑖)
таковы:
𝑀(𝜃, 𝑥1) = + (𝜃0 + 7 ·𝜃1 + 40 ·𝜃2 + 13 ·𝜃3),
𝑀(𝜃, 𝑥2) = −(𝜃0 + 0 ·𝜃1 + 60 ·𝜃2 + 6 ·𝜃3),
𝑀(𝜃, 𝑥3) = −(𝜃0 + 3 ·𝜃1 + 43 ·𝜃2 + 8 ·𝜃3),
𝑀(𝜃, 𝑥4) = + (𝜃0 + 4 ·𝜃1 + 57 ·𝜃2 + 14 ·𝜃3).
Полученная функцияlogloss(𝑋, 𝜃) является функцией четырех переменных,
которую нужно минимизировать. Пример численной минимизации приведен
в дополнительных материалах.
1.7 Отступ и «уверенность» классификации
Обратимся еще к одному примеру и обсудим некоторую геометрическую
интерпретацию классификации при помощи логистической регрессии. Мы
уже говорили, что в результате обучения модели мы получаем уравнение
гиперплоскости
𝜃0 + 𝜃1𝑋1 + ... + 𝜃𝑝𝑋𝑝 = 0,
которая,внекоторомсмысле,отделяетпредставителейодногоклассаотпред-
ставителей другого. В случае двух измерений гиперплоскость – это прямая
на плоскости, в случае трех – плоскость в пространстве, и так далее. Рассмот-
рим простейший пример, в котором, что понятно из наглядных соображений,
19
Высшая школа цифровой культуры Университет ИТМО
Рис. 3: Объекты интуитивно разделимы.
представители разных классов могут быть безошибочно разделены прямой
на два класса, рисунок 3. Обучая модель логистической регрессии на пред-
ставленных данных, приходим к следующему уравнению гиперплоскости:
1.07 + 1.65 ·𝑋1 −1.55 ·𝑋2 = 0,
На рисунке 4 видно, что данные и правда безошибочно разделились постро-
енной прямой. Важно отметить и следующее наблюдение: несмотря на то, что
мы уверены в тренировочных данных (с вероятностью1), некоторые данные
находятся ближе к разделяющей прямой, а некоторые – дальше от нее, и
ни для одного данного построенный классификатор не выдает вероятность,
равную 1. Понятно, что те точки, которые находятся ближе к прямой, клас-
сифицируются менее «уверенно»: вероятности отнесения что к одному, что
к другому классу близки к0.5 (хотя одна из них и превалирует, раз точки
не лежат на разделяющей прямой), а те, которые дальше от прямой – более
«уверенно».
Определение 1.7.1Ранее введенная величина
𝑀(𝜃, 𝑥𝑖) = 𝑦𝑖(𝜃0 + 𝜃1𝑥𝑖1 + ... + 𝜃𝑝𝑥𝑖𝑝)
называется отступом (margin) объекта𝑥𝑖.
В некотором смысле отступ показывает «степень погруженности» объекта
в класс: чем отступ больше, тем дальше находится объект от разделяющей
гиперплоскости и тем увереннее его классификация, и наоборот.
20
Высшая школа цифровой культуры Университет ИТМО
Рис. 4: Разделение объектов.
Замечание 1.7.1Отметим отдельно, что отступ𝑀(𝜃, 𝑥𝑖) отрицателен
тогда и только тогда, когда объект неправильно классифицирован нашим
алгоритмом. Имея тренировочный набор данных 𝑥1, 𝑥2, ..., 𝑥𝑛, число оши-
бочно классифицированных объектов алгоритмом логистической регрессии
можно записать через отступ следующим образом:
̃︀𝑄𝑙𝑜𝑔(𝑥1, 𝑥2, ..., 𝑥𝑛) =
𝑛∑︁
𝑖=1
I(𝑀(𝜃, 𝑥𝑖) < 0).
Логично искать параметры алгоритма таким образом, чтобы минимизи-
ровать ̃︀𝑄𝑙𝑜𝑔, однако минимизировать написанное выражение неудобно. В
то же время, так как
I(𝑀(𝜃, 𝑥𝑖) < 0) ≤log2
(︁
1 + 𝑒−𝑀(𝜃,𝑥𝑖)
)︁
,
то мы приходим к тому, что
̃︀𝑄𝑙𝑜𝑔(𝑥1, 𝑥2, ..., 𝑥𝑛) ≤
𝑛∑︁
𝑖=1
log2
(︁
1 + 𝑒−𝑀(𝜃,𝑥𝑖)
)︁
= ln 2
𝑛∑︁
𝑖=1
ln
(︁
1 + 𝑒−𝑀(𝜃,𝑥𝑖)
)︁
=
= ln 2·logloss(𝑋, 𝜃).
Итого, минимизируя логарифмичекую функцию потерь, мы автоматиче-
ски стараемся уменьшить и количество ошибок при классификации тре-
нировочного набора данных. Все очень взаимосвязано!
21
Высшая школа цифровой культуры Университет ИТМО
Пусть теперь у нас есть набор тестовых объектов:
𝐴 = (0, 2), 𝑦 𝐴 = 1,
𝐵 = (1, 2), 𝑦 𝐵 = −1,
𝐶 = (3.5, 4), 𝑦 𝐶 = 1,
𝐷 = (3, 0), 𝑦 𝐷 = −1.
Обратимся к рисунку 5, на котором эти точки уже отмечены. Цвет точек
соответствует исходному отклику (желтые точки относятся к классу «+1»,
а зеленые – к классу «−1»). Легко видеть, что объект𝐴 классифицирован
неправильно: его цвет отличен от цвета представителей класса, располагаю-
щихся в принадлежащей ему части плоскости. Это можно понять и аналити-
чески, используя отступ:
𝑀(𝜃, 𝐴) = 1 ·(1.07 + 1.65 ·0 −1.55 ·2) = −2.03 < 0.
Итого, классификатор ошибается на объекте𝐴 и относит тестовое наблюде-
ние к классу, отличному от истинного.
Объекты 𝐵 и 𝐶 находятся близко к разделяющей прямой, классифика-
тор неуверен в своем ответе, однако ответ все равно оказывается верным. Это
видно и аналитически:
𝑀(𝜃, 𝐵) = −1 ·(1.07 + 1.65 ·1 −1.55 ·2) = 0.38 > 0,
𝑀(𝜃, 𝐶) = 1 ·(1.07 + 1.65 ·3.5 −1.55 ·4) = 0.645 > 0
– значения хоть и маленькие, но положительные.
Объект 𝐷 находится на значительном расстоянии от прямой и, похоже,
является вбыросом. Это подтверждается и аналитически:
𝑀(𝜃, 𝐷) = −1 ·(1.07 + 1.65 ·3 −1.55 ·0) = −6.02 < 0.
22
Высшая школа цифровой культуры Университет ИТМО
Рис. 5: Классификация новых объектов.
1.8 Сравнение линейной и логистической ре-
грессий
Давайте посмотрим на существенную разницу в подходах линейной и ло-
гистической регрессии. Для этого возьмем в качестве предиктора, например,
уровень дохода некоторого человека, а в качестве отклика факт одобрения
банком кредита этому человеку. На рисунке 6 представлены наши обучающие
данные. По горизонтальной оси отложен размер дохода (в тысячах рублей в
месяц), а по вертикальной – факт получения кредита (единица означает, что
кредит одобрен – желтые точки, ноль, что не одобрен – зеленые точки). Легко
видеть, что при некотором «среднем» уровне дохода кредит иногда одобря-
ется, а иногда – нет. Обучение модели логистической регрессии приводит к
следующей сигмоиде, вы ее можете видеть на рисунке 7. Синим цветом на
том же рисунке изображен график линии регрессии.
Возьмем набор новых клиентов с доходом 35, 40, 60, 70, 80 ты-
сяч рублей и вычислим вероятности получения кредита. Они составят
0.11, 0.22, 0.89, 0.98, 0.99 для логистической регрессии. Линейная регрессия
дает вероятности0.32, 0.39, 0.67, 0.82, 0.96 (рисунки 7-8).
Какие выводы можно сделать? Да, в указанном примере классификация
прошла одинаково с точки зрения конечного результата, то есть обе моде-
ли одинаково указали на клиентов, которым кредит, скорее всего, не дадут
(предсказание меньше, чем0.5), и которым кредит одобрят. Однако можно
наблюдать следующее: при средних значениях предикторов (в примере – в
23
Высшая школа цифровой культуры Университет ИТМО
Рис. 6: Обучающие данные по выдаче кредитов.
районе 50 тыс.руб.) модели ведут себя по-разному. Так, в логистической ре-
грессии видно сильное изменение значений вероятности за счет изменения
выпуклости функции и ее стремительного роста при «средних» значениях
дохода, тогда как в линейной модели значения вероятностей изменяются с
одинаковой скоростью на всем диапазоне. С увеличением числа предикторов
(например, с рассмотрением возраста, пола, наличия недвижимости), эти ню-
ансы моделей будут давать значительный вклад при классификации.
Кроме того видно, что линейная регрессия даже на тренировочных дан-
ных дает странные результаты. Так, есть люди, для которых она выдает «ре-
зультат», меньший нуля, а есть – для которых выдает «результат» больший,
чем единица. И как это интерпретировать? Этот пример еще раз иллюстри-
рует одну из проблем использования линейной регрессии в задаче классифи-
кации: потеря нормировки.
2 Многоклассовая логистическая регрессия
2.1 Построение модели
Итак, мы разобрались с тем, как решать задачу двухклассовой класси-
фикации при помощи логистической регрессии. Но что, если классов больше,
чем2? Оказывается, что все написанное ранее можно обобщить. Пусть теперь
каждый объект, имеющий набор предикторов𝑋1, 𝑋2, ..., 𝑋𝑝, должен быть от-
несен к одному из𝑀 классов: 𝑌 = {1, 2, ..., 𝑀}. Будем приближать так на-
24
Высшая школа цифровой культуры Университет ИТМО
Рис. 7: Результаты логистической регрессии.
зываемые относительные шансы каждого класса своей линией регрессии. В
итоге придем к следующим(𝑀 −1) соотношениям:
ln P(𝑌 =1|𝑋1,𝑋2,...,𝑋𝑝))
P(𝑌 =𝑀|𝑋1,𝑋2,...,𝑋𝑝)) = 𝜃1
0 + 𝜃1
1𝑋1 + ... + 𝜃1
𝑝𝑋𝑝,
ln P(𝑌 =2|𝑋1,𝑋2,...,𝑋𝑝))
P(𝑌 =𝑀|𝑋1,𝑋2,...,𝑋𝑝)) = 𝜃2
0 + 𝜃2
1𝑋1 + ... + 𝜃2
𝑝𝑋𝑝,
...
ln P(𝑌 =𝑀−1|𝑋1,𝑋2,...,𝑋𝑝))
P(𝑌 =𝑀|𝑋1,𝑋2,...,𝑋𝑝)) = 𝜃𝑀−1
0 + 𝜃𝑀−1
1 𝑋1 + ... + 𝜃𝑀−1
𝑝 𝑋𝑝.
Мы видим, что в данной задаче нам нужно определить уже(𝑀 −1) ·𝑝 неиз-
вестных параметров. Прежде чем переходить к поиску этих параметров, сна-
чала получим аналитические выражения для вероятности отнесения нового
объекта к каждому из заявленных классов, диктуемые моделью. Обозначим
Ψ𝑖 = Ψ𝑖(𝑋1, 𝑋2, ..., 𝑋𝑝) = 𝜃𝑖
0 + 𝜃𝑖
1𝑋1 + ... + 𝜃𝑖
𝑝𝑋𝑝, 𝑖 ∈{1, 2, ..., 𝑀−1},
и добавим условие нормировки, чтобы получить вероятностное распределе-
ние. Тогда придем к следующей системе уравнений
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎩
ln P(𝑌 =1|𝑋1,𝑋2,...,𝑋𝑝))
P(𝑌 =𝑀|𝑋1,𝑋2,...,𝑋𝑝)) = Ψ1,
ln P(𝑌 =2|𝑋1,𝑋2,...,𝑋𝑝))
P(𝑌 =𝑀|𝑋1,𝑋2,...,𝑋𝑝)) = Ψ2,
. . . . . . . . . . . . . . . . . . . . . . . . . . .
ln P(𝑌 =𝑀−1|𝑋1,𝑋2,...,𝑋𝑝))
P(𝑌 =𝑀|𝑋1,𝑋2,...,𝑋𝑝)) = Ψ𝑀−1,
𝑀∑︀
𝑖=1
P(𝑌 = 𝑖|𝑋1, 𝑋2, ..., 𝑋𝑝) = 1.
,
25
Высшая школа цифровой культуры Университет ИТМО
Рис. 8: Результаты линейной регрессии.
решив которую, получим следующие аналитические выражения для вероят-
ностей:
P𝑘 = P(𝑌 = 𝑘|𝑋1, 𝑋2, ..., 𝑋𝑝) = 𝑒Ψ𝑘
1 +
𝑀−1∑︀
𝑖=1
𝑒Ψ𝑖
, 𝑘 ∈{1, 2, ..., 𝑀−1},
P𝑀 = P(𝑌 = 𝑀|𝑋1, 𝑋2, ..., 𝑋𝑝) = 1
1 +
𝑀−1∑︀
𝑖=1
𝑒Ψ𝑖
.
Сформулируем алгоритм предсказания класса нового объекта𝑧 с предикто-
рами(𝑧1, 𝑧2, ..., 𝑧𝑝) вслучае,когдакоэффициенты 𝜃𝑖
0, 𝜃𝑖
1, ..., 𝜃𝑖
𝑝,𝑖 ∈{1, 2, ..., 𝑀−
1}, уже найдены.
1. Вычислить значенияΨ𝑘, 𝑘 ∈{1, 2, ..., 𝑀−1}:
Ψ𝑘 = 𝜃𝑘
0 + 𝜃𝑘
1 𝑧1 + 𝜃𝑘
2 𝑧2 + . . .+ 𝜃𝑘
𝑝𝑧𝑝.
2. Вычислить вероятностиP𝑘,𝑘 ∈{1, 2, ..., 𝑀−1}, исходя из соотношений:
P𝑘 = 𝑒Ψ𝑘
1 +
𝑀−1∑︀
𝑖=1
𝑒Ψ𝑖
, 𝑘 ∈{1, 2, ..., 𝑀−1}
26
Высшая школа цифровой культуры Университет ИТМО
и вероятностьP𝑚, исходя из соотношений
P𝑀 = 1
1 +
𝑀−1∑︀
𝑖=1
𝑒Ψ𝑖
.
3. Назначить тестовому объекту любой класс из множества
Arg max
𝑦∈{1,2,...,𝑀}
P𝑦
Замечание 2.1.1Отметим отдельно, что последний пункт алгоритма
может быть изменен исследователем в зависимости от задачи. Аргумен-
тация остается точно такой же, какой и была в случае двухклассовой
классификации.
2.2 Нахождение параметров модели
Перейдем к краткому описанию способа нахождения неизвестных па-
раметров модели. Пусть нам дан тренировочный набор данных 𝑋 =
{𝑥1, 𝑥2, ..., 𝑥𝑛}объема 𝑛,
𝑥𝑖 = (𝑥𝑖1, 𝑥𝑖2, ..., 𝑥𝑖𝑝), 𝑖 ∈{1, 2, ..., 𝑛},
причем каждому объекту 𝑥𝑖 соответствует отклик 𝑦𝑖 ∈ 𝑌 = {1, 2, ..., 𝑀}.
Обозначим
P𝑘(𝑥𝑖) = 𝑒Ψ𝑘(𝑥𝑖1,𝑥𝑖2,...,𝑥𝑖𝑝)
1 +
𝑀−1∑︀
𝑖=1
𝑒Ψ𝑖(𝑥𝑖1,𝑥𝑖2,...,𝑥𝑖𝑝)
, 𝑘 ∈{1, 2, ..., 𝑀−1}
и
P𝑀 (𝑥𝑖) = 1
1 +
𝑀−1∑︀
𝑖=1
𝑒Ψ𝑖(𝑥𝑖1,𝑥𝑖2,...,𝑥𝑖𝑝)
.
Используя метод максимального правдоподобия, функция правдоподобия
примет вид:
𝑓(𝑋, 𝜃) = P𝑦1 (𝑥1) ·P𝑦2 (𝑥2) ·... ·P𝑦𝑛(𝑥𝑛) =
𝑛∏︁
𝑖=1
P𝑦𝑖(𝑥𝑖),
а логарифмическая функция правдоподобия перепишется в виде
𝐿(𝑥, 𝜃) = ln 𝑓(𝑋, 𝜃) =
𝑛∑︁
𝑖=1
ln P𝑦𝑖(𝑥𝑖).
27
Высшая школа цифровой культуры Университет ИТМО
Написанную функцию и нужно максимизировать, изменяя значения пара-
метров 𝜃𝑖
0, 𝜃𝑖
1, ..., 𝜃𝑖
𝑝, 𝑖 ∈ {1, 2, ..., 𝑀−1}. Мы не будем останавливаться на
пояснениях более детально, так как процесс максимизации сводится к приме-
нению тех или иных численных методов, и выходит за рамки нашего курса.
Напоследок отметим, что аналогично случаю двух классов, максимизация
логарифмической функции правдоподобия все так же ведет к минимизации
количества ошибок рассматриваемого алгоритма на тренировочных данных.
2.3 Пример трехклассовой классификации
Применим описанный алгоритм к уже знакомым данным о сладости и
хрусткости тех или иных классов продуктов. Каждый объект обладает двумя
предикторами 𝑋1 и 𝑋2 и относится к одному из𝑀 = 3 классов: 𝑌 = {1, 2, 3},
где 1 отвечает фруктам, 2 – овощам, а3 – протеинам. Как мы уже знаем,
данныехорошоразделимы,такчтомодельнаосновелогистическойрегрессии
должна показать себя хорошо.
Продукт Сладость Хруст Класс
банан 10 1 фрукт
апельсин 7 4 фрукт
виноград 8 3 фрукт
креветка 2 2 протеин
бекон 1 5 протеин
орехи 3 3 протеин
сыр 2 1 протеин
рыба 3 2 протеин
огурец 2 8 овощ
яблоко 9 8 фрукт
морковь 4 10 овощ
сельдерей 2 9 овощ
салат айсберг 3 7 овощ
груша 8 7 фрукт
Обучив алгоритм многоклассовой логистической регрессии средствами моде-
лирования на представленных данных, приходим к следующим выражениям
для Ψ1 и Ψ2 (с округленными коэффициентами):
Ψ1 = Ψ1(𝑋1, 𝑋2) = −5.561 + 10.786𝑋1 −9.976𝑋2
Ψ2 = Ψ2(𝑋1, 𝑋2) = −50.441 + 15.765𝑋1 −3.961𝑋2.
28
Высшая школа цифровой культуры Университет ИТМО
Для нахождения вероятности отнесения тестового объекта к тому или иному
классу воспользуемся выведенными ранее формулами:
P𝑘 (𝑥𝑖) = 𝑒Ψ𝑘(𝑥𝑖1,𝑥𝑖2,...,𝑥𝑖𝑝)
1 +
2∑︀
𝑖=1
𝑒Ψ𝑖(𝑥𝑖1,𝑥𝑖2,...,𝑥𝑖𝑝)
, 𝑘 ∈{1, 2},
P3 (𝑥𝑖) = 1
1 +
2∑︀
𝑖=1
𝑒Ψ𝑖(𝑥𝑖1,𝑥𝑖2,...,𝑥𝑖𝑝)
.
Для начала вычислим значенияΨ𝑘, 𝑘 ∈{1, 2}для нового объекта «Перец» с
предикторами (6, 9):
Ψ1 = Ψ1(6, 9) = −5.561 + 10.786 ·6 −9.976 ·9 ≈−29.012
Ψ2 = Ψ2(6, 9) = −50.441 + 15.765 ·6 −3.961 ·9 ≈8.495.
Тогда:
P1 = 𝑒Ψ1
1 + 𝑒Ψ1 + 𝑒Ψ2
≈0,
P2 = 𝑒Ψ2
1 + 𝑒Ψ1 + 𝑒Ψ2
≈1,
P3 = 1
1 + 𝑒Ψ1 + 𝑒Ψ2
≈0.
Из проведенных вычислений становится совершенно понятно, что обученный
алгоритм относит «Перец» к классу овощей чрезвычайно уверенно, с веро-
ятностью очень близкой к 1. На рисунке можно увидеть три области, на
которые построенный классификатор разделил все пространство признаков.
Все точки, лежащие в верхней светло-зеленой части классифицируются как
овощи, точки, находящиеся слева в желтой области – как протеины, а точки,
находящиеся в темно-зеленой области справа – как фрукты. Понятно, что
чем дальше объект расположен от образовавшихся границ, тем увереннее (то
есть с большей вероятностью) он будет классифицирован к тому или иному
классу.
3 F-мера и ROC-анализ
3.1 Матрица ошибок и𝐹-мера
ROC-кривая или кривая ошибок – кривая, которая наиболее часто ис-
пользуется для оценки результатов бинарной классификации в машинном
29
Высшая школа цифровой культуры Университет ИТМО
Рис. 9: Модель многомерное логистической регрессии.
обучении. Кривая ошибок показывает зависимость доли истинно положи-
тельных примеров от доли ложно положительных примеров. При этом пред-
полагается, что у классификатора имеется некоторый параметр, изменение
которого влияет на то или иное разбиение на эти два класса.
Для начала рассмотрим так называемую матрицу ошибок (confusion
matrix) – способ разделить объекты на4 группы в зависимости от комби-
нации истинного класса и ответа классификатора:
• TP (True Positives) – верно классифицированные объекты, исходно от-
носящиеся к классу «+1»;
• TN (True Negatives) – верно классифицированные объекты, исходно от-
носящиеся к классу «−1»;
• FN (False Negatives) – неверно классифицированные объекты, исходно
относящиеся к классу «+1» (ошибка I рода);
• FP (False Positives) – неверно классифицированные объекты, исходно
относящиеся к классу «−1» (ошибка II рода).
Обычно, конечно, оперируют не абсолютными показателями, а относи-
тельными – долями (rates), находящимися в диапазоне от0 до 1:
30
Высшая школа цифровой культуры Университет ИТМО
Матрица ошибок Исходный класс
+ –
Ответ классификатора + TP FP
– FN TN
• доля правильных ответов классификатора (иногда – точность):
Accuracy = 𝑇𝑃 + 𝑇𝑁
𝑇𝑃 + 𝐹𝑃 + 𝐹𝑁 + 𝑇𝑁 .
Эта величина показывает отношение количества верно классифициро-
ванных объектов к общему количеству классифицируемых объектов
и, грубо говоря, оценивает вероятность случайному объекту быть пра-
вильно классифицированным.
• доля истинно положительных примеров – True Positives Rate (TPR) или
Sensitivity (чувствительность) или Recall:
TPR = 𝑇𝑃
𝑇𝑃 + 𝐹𝑁 .
Эта величина показывает отношение количества верно классифициро-
ванных объектов, относящихся к классу «+1», к общему количеству
объектов класса «+1». Иными словами – это оценка вероятности, что
объект, относящийся к классу «+1» будет классифицирован корректно.
• доля ложно положительных примеров обозначается как – False Positives
Rate (FPR):
FPR = 𝐹𝑃
𝐹𝑃 + 𝑇𝑁 .
Величинапоказываетотношениеколичестваневерноклассифицирован-
ных объектов, относящихся к классу «−1», к общему количеству объек-
тов класса «−1», или оценивает вероятность, что объект, относящийся
к классу «−1», будет классифицирован неверно.
• Специфичность (Specificity) или True Negatives Rate (TNR):
TNR = 1 −FPR = 𝑇𝑁
𝑇𝑁 + 𝐹𝑃 .
Величина показывает отношение количества верно классифицирован-
ных объектов, относящихся к классу «−1», к общему количеству объ-
ектовкласса« −1»,илиоцениваетвероятность,чтообъект,относящийся
к классу «−1», будет классифицирован верно.
31
Высшая школа цифровой культуры Университет ИТМО
• Precision (точность):
Precision = 𝑇𝑃
𝑇𝑃 + 𝐹𝑃 .
Величина показывает, какая доля объектов, отнесенных классификато-
ром классу «+1», действительно относится к этому классу.
Часть из введенных понятий очень хорошо иллюстрируется на таком примере
из медицины. Пусть к положительному классу относятся пациенты, имеющие
заболевание, а к отрицательному – не имеющие. Чувствительный диагности-
ческий тест (с высокимTPR) – это тот, который правильно идентифицирует
пациентовсзаболеванием.Тоестьеслитестна 100% чувствителен(TPR = 1),
то он верно определит всех пациентов, у которых есть заболевание (то есть
всем болеющим скажет, что они больны). В то же время, он может записать
к заболевшим и тех, кто не болен. Высокочувствительный тест полезен для
исключения заболевания.
Специфичный диагностический тест (с высоким TNR) диагностирует
только доподлинно больных, то есть, если тест имеет100% специфичность
(TNR = 1), он будет верно идентифицировать пациентов, которые не имеют
заболевания, но может записать к здоровым и больных. Такой тест важен
при лечении пациентов с определенным заболеванием.
Естественно возникает вопрос, нет ли какого-то обобщающего критерия,
который может характеризовать качество построенной модели. Один из ни –
так называемая𝐹-мера (𝐹1-мера, 𝐹 score, 𝐹1 score) определяется следующим
соотношением:
𝐹 = 𝐹1 = 2 · Precision ·Recall
Precision + Recall.
Замечание 3.1.1𝐹-мера является средним гармоническим величин
Precision и Recall и заключена в диапазоне [0, 1]. Среднее гармоническое
обладает важным свойством: оно близко к нулю, если хотя бы один
аргументов близок к нулю. Поэтому оно является куда более предпочти-
тельным, чем, скажем, среднее арифметическое: если алгоритм относит
все объекты к положительному классу, тоRecall = 1 , а Precision, скорее
всего, будет небольшим. Но тогда среднее арифметическое будет больше,
чем 0.5, что, конечно, никуда не годится.
Вернемся к примеру по футбольной статистике, в котором мы уже обучили
модель и нашли значения𝜃:
𝜃0 = −0.046, 𝜃1 = 0.541, 𝜃2 = −0.014, 𝜃3 = −0.132.
Используем тестовый набор данных, представленный в таблице ниже, и со-
ставим матрицу ошибок.
32
Высшая школа цифровой культуры Университет ИТМО
Победа или
проигрыш
Количество
ударов в створ
Процент
владения мячом
Удары
по воротам
1 5 60 10
1 2 35 3
0 3 45 6
0 1 53 10
1 7 70 11
1 3 65 12
1 1 30 2
0 2 40 9
1 10 71 15
1 6 54 12
0 7 65 15
0 0 30 3
Для начала найдем вероятность победы для каждого набора данных. Так,
для команды, попавшей в створ ворот в5 из 10 случаев, и владевшей мячом
60 процентов игрового времени, вероятность победы составит:
P+ = 1
1 + 𝑒−(𝜃0+𝜃1·5+𝜃2·60+𝜃3·10) ≈0.588.
Но к какому классу мы отнесем этот объект, глядя на результат? Если порог
отсечения 0.5, то классу победивших, а если0.6, то к классу проигравших.
Найдем вероятности победы в матче для всех оставшихся тестовых данных и
поместимокругленныерезультатывтаблицу.Напрактикезначения,конечно,
лучше не округлять.
Вероятность
победы
0.588
0.520
0.517
0.186
0.743
0.285
0.446
0.337
0.886
0.671
0.666
0.307
33
Высшая школа цифровой культуры Университет ИТМО
В качестве порога отсечения выберем значение0.5 и назначим классы.
Вероятность
победы
Победа или
проигрыш (предсказание)
0.588 1
0.520 1
0.517 1
0.186 0
0.743 1
0.285 0
0.446 0
0.337 0
0.886 1
0.671 1
0.666 1
0.307 0
Легко сопоставить предсказанные классы с исходными. Как видим, они не
всегда одинаковы, а это значит, что модель ошибается.
Победа или
проигрыш
Вероятность
победы
Победа или
проигрыш (предсказание)
1 0.588 1
1 0.520 1
0 0.517 1
0 0.186 0
1 0.743 1
1 0.285 0
1 0.446 0
0 0.337 0
1 0.886 1
1 0.671 1
0 0.666 1
0 0.307 0
Теперь мы можем составить матрицу ошибок. Подсчитаем число команд, ко-
торые победили в матче как по исходным данным, так и по прогнозу модели,
таких команд пять. Аналогично подсчитаем число команд, проигравших в
матче как по исходным данным, так и по прогнозу, их три. Ошибок первого
ивторогородаподве.Тогдадоляистинноположительныхпримеровсоставит
TPR = 𝑇𝑃
𝑇𝑃 + 𝐹𝑁 = 5
5 + 2 ≈0.71,
34
Высшая школа цифровой культуры Университет ИТМО
Матрица ошибок Исходный класс
+ –
Прогноз + TP=5 FP=2
– FN=2 TN=3
а доля ложно положительных составит
FPR = 𝐹𝑃
𝑇𝑁 + 𝐹𝑃 = 2
3 + 2 = 0.4.
Кроме того,
𝐹1 ≈0.71,
что можно считать неплохим результатом.
3.2 ROC-кривая
Выше мы изучили точность, полноту и𝐹-меру – оценки качества работы
построенного алгоритма при фиксированном пороге отсечения. Однако часто
выбор порога отсечения после построения модели – и есть еще одна немало-
важная задача. Для ее решения часто бывает полезной такая интегральная
метрика качества, как𝑅𝑂𝐶-кривая. Она строится, как зависимостьTPR от
FPR. Для ее построения нужно вычислить соответствующие значения при
разных порогах отсечения.
Рис. 10: Кривая ошибок.
Существуютразличныеподходыкизменениюзначенийпорога.Егомож-
но менять от нуля до единицы с некоторым шагом, а можно в качестве его
35
Высшая школа цифровой культуры Университет ИТМО
значений брать полученные по модели вероятности, отсортированные по воз-
растанию.
В результате последнего, каждой паре значенийFPR𝑖, TPR𝑖 соответству-
ет точка на плоскости, соседние точки соединяются отрезками прямых. Так
как при переходе через следующее значение вероятности меняется только
один результат классификации, то скачок происходит либо вверх, либо впра-
во, а фигура получается ступенчатой (рисунок 10). Например, значению ве-
роятности 0.588, соответствует доля истинно положительных примеров0.2 и
доля ложно положительных примеров0.429. Точки с координатами(0, 0) и
(1, 1) всегда отмечаются и являются началом и концом кривой.
В идеальной вселенной, кривая проходит через верхний левый угол, где
процент истинно положительных случаев составляет 100%. Поэтому, чем
больше выгнута ROC-кривая, тем более точным является прогнозирование
результатов модели. Оценка модели может быть получена непосредственно
вычислением площади под𝑅𝑂𝐶-кривой. Показатель обозначается как𝐴𝑈𝐶
(Area Under Curve – площадь под кривой) или𝐴𝑈𝐶 −𝑅𝑂𝐶. Так как получив-
шаяся фигура является ступенчатой, ее площадь может быть легко вычисле-
на как сумма площадей прямоугольников на основе значенийTPR𝑖, FPR𝑖.
В зависимости от значений𝐴𝑈𝐶 , на практике часто оценивают качество
модели следующим образом: отличное, если𝐴𝑈𝐶 ∈(0.9, 1]; хорошее, если
𝐴𝑈𝐶 ∈(0.7, 0.9]; среднее, если𝐴𝑈𝐶 ∈(0.60.7]; неудовлетворительное, если
𝐴𝑈𝐶 ∈(0.5, 0.6].
Как же найти оптимальное значение порога отсечения? Оптимальным
значением порога, будет точка пересечения графика чувствительности и спе-
цифичности. График строится аналогично случаю𝑅𝑂𝐶-кривой, только те-
перь на одной плоскости строится зависимость чувствительности от порога,
и специфичности от порога (рисунок 11). Для рассматриваемого примера это
значение составит около0.52. Еще раз отметим, что на практике значения
вероятностей и прочих величин не стоит округлять.
Порог мало отличается от рассмотренного ранее, да и объем данных
невелик, однако матрица ошибок уже будет другой:
Матрица ошибок Исходный класс
+ –
Прогноз + TP=4 FP=1
– FN=3 TN=4
При таком пороге отсечения доля истинно положительных примеров со-
ставит0.571 идоляложноположительныхпримеров 0.2.Тоестьмодельстала
лучше отсекать отрицательные данные за счет увеличения ее специфичности.
Таким образом, цель ROC-анализа заключается в том, чтобы подобрать
такое значение точки отсечения, которое позволит модели с наибольшей точ-
36
Высшая школа цифровой культуры Университет ИТМО
Рис. 11: Определение порога отсечения.
ностью распознавать положительные или отрицательные исходы и выда-
вать наименьшее количество ложноположительных или ложноотрицатель-
ных ошибок.
4 Заключение
Итак, в этой лекции мы познакомились с еще одним вероятностным алго-
ритмом многоклассовой классификации – с логистической регрессией. Кроме
того, мы изучили различные методы оценки качества построенного класси-
фикатора. На сегодня все, до новых встреч!
37
